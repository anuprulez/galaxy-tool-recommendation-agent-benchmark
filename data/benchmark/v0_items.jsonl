{"id": "vgp_workflow_training-q01", "tutorial_id": "topics/assembly/tutorials/vgp_workflow_training", "query": "I have PacBio HiFi reads and Illumina Hi-C reads from a genome assembly experiment, and I want to perform genome profile analysis. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "assembly", "tutorial_title": "Using the VGP workflows to assemble a vertebrate genome with HiFi and Hi-C data", "datasets": ["HiFi data", "Hi-C forward reads", "Hi-C reverse reads"], "dataset_paths": ["HiFi data", "Hi-C forward reads", "Hi-C reverse reads"], "dataset_count": 3, "context_summary": "The {VGP}, a project of the {G10K} Consortium, aims to generate high-quality, near error-free, gap-free, chromosome-level, haplotype-phased, annotated reference genome assemblies for every vertebrate species ({% cite Rhie2021 %}). The VGP has developed a fully automated *de-novo* genome assembly pipeline, which uses a combination of three different technologies: Pacbio {HiFi}, {Hi-C} data, and (optionally) Bionano optical map data. The pipeline consists of nine distinct workflows. This tutorial provides a quick example of how to run these workflows for one particular scenario, which is, based on our experience, the most common: assembling genomes using {HiFi} Reads combined with {Hi-C} data (both generated from the same individual).", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "vgp_workflow_training-q02", "tutorial_id": "topics/assembly/tutorials/vgp_workflow_training", "query": "I have a set of PacBio HiFi reads and Illumina Hi-C reads, and I want to perform Hi-C scaffolding. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "assembly", "tutorial_title": "Using the VGP workflows to assemble a vertebrate genome with HiFi and Hi-C data", "datasets": ["usable hap1 gfa", "Hi-C forward reads", "Hi-C reverse reads"], "dataset_paths": ["usable hap1 gfa", "Hi-C forward reads", "Hi-C reverse reads"], "dataset_count": 3, "context_summary": "The {VGP}, a project of the {G10K} Consortium, aims to generate high-quality, near error-free, gap-free, chromosome-level, haplotype-phased, annotated reference genome assemblies for every vertebrate species ({% cite Rhie2021 %}). The VGP has developed a fully automated *de-novo* genome assembly pipeline, which uses a combination of three different technologies: Pacbio {HiFi}, {Hi-C} data, and (optionally) Bionano optical map data. The pipeline consists of nine distinct workflows. This tutorial provides a quick example of how to run these workflows for one particular scenario, which is, based on our experience, the most common: assembling genomes using {HiFi} Reads combined with {Hi-C} data (both generated from the same individual).", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "earth_system-q01", "tutorial_id": "topics/climate/tutorials/earth_system", "query": "I want to access and analyze ocean data from the Argo program, which tool should I use in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Getting your hands-on earth data", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutotrial aims at familiarzing you with Earth Science and discovering the earth data available on Galaxy. The target audience is not a scientist but", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "earth_system-q02", "tutorial_id": "topics/climate/tutorials/earth_system", "query": "How can I visualize and extract marine chemical data from EMODnet Chemistry using Galaxy tools?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Getting your hands-on earth data", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutotrial aims at familiarzing you with Earth Science and discovering the earth data available on Galaxy. The target audience is not a scientist but", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "earth_system-q03", "tutorial_id": "topics/climate/tutorials/earth_system", "query": "I need to analyze Sentinel-5P data for atmospheric monitoring, which tool in Galaxy can help me achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Getting your hands-on earth data", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutotrial aims at familiarzing you with Earth Science and discovering the earth data available on Galaxy. The target audience is not a scientist but", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "earth_system-q04", "tutorial_id": "topics/climate/tutorials/earth_system", "query": "What is the best way to access and visualize biodiversity data from OBIS using Galaxy tools?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Getting your hands-on earth data", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutotrial aims at familiarzing you with Earth Science and discovering the earth data available on Galaxy. The target audience is not a scientist but", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fates-jupyterlab-q01", "tutorial_id": "topics/climate/tutorials/fates-jupyterlab", "query": "I want to upload and uncompress the tar file 'inputdata_version2.0.0_ALP1.tar' from Zenodo. Which Galaxy tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Functionally Assembled Terrestrial Ecosystem Simulator (FATES) with Galaxy Climate JupyterLab", "datasets": ["zenodo.4108341"], "dataset_paths": ["zenodo.4108341"], "dataset_count": 1, "context_summary": "The practical aims at familiarizing you with running CLM-FATES within Galaxy Climate JupyterLab.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fates-jupyterlab-q02", "tutorial_id": "topics/climate/tutorials/fates-jupyterlab", "query": "How can I launch the Galaxy Climate JupyterLab interactive tool on LiveGalaxy.eu to run CLM-FATES simulations?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Functionally Assembled Terrestrial Ecosystem Simulator (FATES) with Galaxy Climate JupyterLab", "datasets": ["https://doi.org/10.5281/zenodo.4108341"], "dataset_paths": ["https://doi.org/10.5281/zenodo.4108341"], "dataset_count": 1, "context_summary": "The practical aims at familiarizing you with running CLM-FATES within Galaxy Climate JupyterLab.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fates-jupyterlab-q03", "tutorial_id": "topics/climate/tutorials/fates-jupyterlab", "query": "I have a CLM-FATES simulation output in netCDF format. Which Galaxy tool can I use to visualize and analyze the data?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Functionally Assembled Terrestrial Ecosystem Simulator (FATES) with Galaxy Climate JupyterLab", "datasets": ["https://doi.org/10.5281/zenodo.4108341"], "dataset_paths": ["https://doi.org/10.5281/zenodo.4108341"], "dataset_count": 1, "context_summary": "The practical aims at familiarizing you with running CLM-FATES within Galaxy Climate JupyterLab.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fates-jupyterlab-q04", "tutorial_id": "topics/climate/tutorials/fates-jupyterlab", "query": "How can I save my CLM-FATES simulation results and Jupyter notebooks to my Galaxy history for later use?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Functionally Assembled Terrestrial Ecosystem Simulator (FATES) with Galaxy Climate JupyterLab", "datasets": ["https://doi.org/10.5281/zenodo.4108341"], "dataset_paths": ["https://doi.org/10.5281/zenodo.4108341"], "dataset_count": 1, "context_summary": "The practical aims at familiarizing you with running CLM-FATES within Galaxy Climate JupyterLab.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "jupytergis_collaboration-q01", "tutorial_id": "topics/climate/tutorials/jupytergis_collaboration", "query": "I want to add a new layer to my GIS file in JupyterGIS. Which tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Collaboration with JupyterGIS", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Welcome to the JupyterGIS collaborative features tutorial. JupyterGIS enables the seamless sharing of notebooks and GIS files, allowing teams—including GIS specialists, data analysts,", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "jupytergis_collaboration-q02", "tutorial_id": "topics/climate/tutorials/jupytergis_collaboration", "query": "How can I track my collaborators' cursors in real-time in JupyterGIS?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Collaboration with JupyterGIS", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Welcome to the JupyterGIS collaborative features tutorial. JupyterGIS enables the seamless sharing of notebooks and GIS files, allowing teams—including GIS specialists, data analysts,", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "jupytergis_collaboration-q03", "tutorial_id": "topics/climate/tutorials/jupytergis_collaboration", "query": "I need to invite collaborators to join my JupyterGIS session. What steps should I take?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Collaboration with JupyterGIS", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Welcome to the JupyterGIS collaborative features tutorial. JupyterGIS enables the seamless sharing of notebooks and GIS files, allowing teams—including GIS specialists, data analysts,", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "jupytergis_collaboration-q04", "tutorial_id": "topics/climate/tutorials/jupytergis_collaboration", "query": "How can I activate follow mode in JupyterGIS to track another user's activity?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Collaboration with JupyterGIS", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Welcome to the JupyterGIS collaborative features tutorial. JupyterGIS enables the seamless sharing of notebooks and GIS files, allowing teams—including GIS specialists, data analysts,", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ocean-data-view-q01", "tutorial_id": "topics/climate/tutorials/ocean-data-view", "query": "I have a netCDF file containing oceanographic data and I want to create a map of the data. What tool should I use in Galaxy to visualize this data?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Ocean Data View (ODV)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Through this tutorial you will learn here how to access, filter and import netCDF data through using ODV Galaxy interactive tool:", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "ocean-data-view-q02", "tutorial_id": "topics/climate/tutorials/ocean-data-view", "query": "How can I use Galaxy to subset my large netCDF file and create a profile curve of temperature vs pressure?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Ocean Data View (ODV)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Through this tutorial you will learn here how to access, filter and import netCDF data through using ODV Galaxy interactive tool:", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "ocean-data-view-q03", "tutorial_id": "topics/climate/tutorials/ocean-data-view", "query": "What tool is required to deploy an Ocean Data View (ODV) instance in Galaxy for interactive exploration of oceanographic data?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Ocean Data View (ODV)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Through this tutorial you will learn here how to access, filter and import netCDF data through using ODV Galaxy interactive tool:", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "ocean-data-view-q04", "tutorial_id": "topics/climate/tutorials/ocean-data-view", "query": "How do I save my ODV analysis, including the map and profile curves, as images in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Ocean Data View (ODV)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Through this tutorial you will learn here how to access, filter and import netCDF data through using ODV Galaxy interactive tool:", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "pangeo-notebook-q01", "tutorial_id": "topics/climate/tutorials/pangeo-notebook", "query": "I have PM2.5 forecast data ([zenodo.5805953]) and want to visualize it on a map for December 24th, 2021 at 12:00 UTC. What should I do?", "tools": ["interactive_tool_pangeo_notebook"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Pangeo Notebook in Galaxy - Introduction to Xarray", "datasets": ["zenodo.5805953"], "dataset_paths": ["zenodo.5805953"], "dataset_count": 1, "context_summary": "In this tutorial, we will learn about [Xarray](https://xarray.pydata.org/), one of the most used Python library from the [Pangeo](https://pangeo.io/) ecosystem.", "priority": 1, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_pangeo_notebook"]}, "query_type": "science_first", "tool_focus": "interactive_tool_pangeo_notebook"}}
{"id": "pangeo-notebook-q02", "tutorial_id": "topics/climate/tutorials/pangeo-notebook", "query": "My PM2.5 forecast data ([zenodo.5805953]) has multiple time points; how can I subset it to a specific time range for analysis?", "tools": ["interactive_tool_pangeo_notebook"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Pangeo Notebook in Galaxy - Introduction to Xarray", "datasets": ["zenodo.5805953"], "dataset_paths": ["zenodo.5805953"], "dataset_count": 1, "context_summary": "In this tutorial, we will learn about [Xarray](https://xarray.pydata.org/), one of the most used Python library from the [Pangeo](https://pangeo.io/) ecosystem.", "priority": 2, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_pangeo_notebook"]}, "query_type": "science_first", "tool_focus": "interactive_tool_pangeo_notebook"}}
{"id": "pangeo-notebook-q03", "tutorial_id": "topics/climate/tutorials/pangeo-notebook", "query": "Which Galaxy tool can I use to open and read metadata from my netCDF dataset ([zenodo.5805953])?", "tools": ["interactive_tool_pangeo_notebook"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Pangeo Notebook in Galaxy - Introduction to Xarray", "datasets": ["zenodo.5805953"], "dataset_paths": ["zenodo.5805953"], "dataset_count": 1, "context_summary": "In this tutorial, we will learn about [Xarray](https://xarray.pydata.org/), one of the most used Python library from the [Pangeo](https://pangeo.io/) ecosystem.", "priority": 3, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_pangeo_notebook"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_pangeo_notebook"}}
{"id": "pangeo-notebook-q04", "tutorial_id": "topics/climate/tutorials/pangeo-notebook", "query": "How can I use the Pangeo Notebook in Galaxy to plot my PM2.5 forecast data ([zenodo.5805953]) as a multi-plot figure?", "tools": ["interactive_tool_pangeo_notebook"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Pangeo Notebook in Galaxy - Introduction to Xarray", "datasets": ["zenodo.5805953"], "dataset_paths": ["zenodo.5805953"], "dataset_count": 1, "context_summary": "In this tutorial, we will learn about [Xarray](https://xarray.pydata.org/), one of the most used Python library from the [Pangeo](https://pangeo.io/) ecosystem.", "priority": 4, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_pangeo_notebook"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_pangeo_notebook"}}
{"id": "panoply-q01", "tutorial_id": "topics/climate/tutorials/panoply", "query": "I have a netCDF file containing climate data and I want to visualize it as a geo-referenced longitude-latitude plot. What tool should I use in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Visualize Climate data with Panoply netCDF viewer", "datasets": ["ecv_1979.nc"], "dataset_paths": ["ecv_1979.nc"], "dataset_count": 1, "context_summary": "The practical aims at familiarzing you with the [Panoply](https://www.giss.nasa.gov/tools/panoply/) Galaxy interactive environment. Panoply is among the most popular tool to visualize geo-referenced data stored in [Network Common Data Form](https://en.wikipedia.org/wiki/NetCDF) (netCDF). It provides a graphical interface for inspecting (show metadata) and visualizing netCDF data. It supports many features to customize your plots and we will introduce some of them in this lesson.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "panoply-q02", "tutorial_id": "topics/climate/tutorials/panoply", "query": "How can I export an animation of sea ice extent over time from a netCDF file in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Visualize Climate data with Panoply netCDF viewer", "datasets": ["ecv_1979.nc"], "dataset_paths": ["ecv_1979.nc"], "dataset_count": 1, "context_summary": "The practical aims at familiarzing you with the [Panoply](https://www.giss.nasa.gov/tools/panoply/) Galaxy interactive environment. Panoply is among the most popular tool to visualize geo-referenced data stored in [Network Common Data Form](https://en.wikipedia.org/wiki/NetCDF) (netCDF). It provides a graphical interface for inspecting (show metadata) and visualizing netCDF data. It supports many features to customize your plots and we will introduce some of them in this lesson.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "panoply-q03", "tutorial_id": "topics/climate/tutorials/panoply", "query": "I need to change the map projection of a geo-referenced plot created from a netCDF file in Galaxy. Which tool can I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Visualize Climate data with Panoply netCDF viewer", "datasets": ["ecv_1979.nc"], "dataset_paths": ["ecv_1979.nc"], "dataset_count": 1, "context_summary": "The practical aims at familiarzing you with the [Panoply](https://www.giss.nasa.gov/tools/panoply/) Galaxy interactive environment. Panoply is among the most popular tool to visualize geo-referenced data stored in [Network Common Data Form](https://en.wikipedia.org/wiki/NetCDF) (netCDF). It provides a graphical interface for inspecting (show metadata) and visualizing netCDF data. It supports many features to customize your plots and we will introduce some of them in this lesson.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "panoply-q04", "tutorial_id": "topics/climate/tutorials/panoply", "query": "How can I create a time series plot of surface temperature at a specific location from a netCDF file in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "climate", "tutorial_title": "Visualize Climate data with Panoply netCDF viewer", "datasets": ["ecv_1979.nc"], "dataset_paths": ["ecv_1979.nc"], "dataset_count": 1, "context_summary": "The practical aims at familiarzing you with the [Panoply](https://www.giss.nasa.gov/tools/panoply/) Galaxy interactive environment. Panoply is among the most popular tool to visualize geo-referenced data stored in [Network Common Data Form](https://en.wikipedia.org/wiki/NetCDF) (netCDF). It provides a graphical interface for inspecting (show metadata) and visualizing netCDF data. It supports many features to customize your plots and we will introduce some of them in this lesson.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "sentinel5_data-q01", "tutorial_id": "topics/climate/tutorials/sentinel5_data", "query": "I want to visualize Sentinel 5P data to monitor volcanic activity and aerosol spread, how can I access and process the data?", "tools": ["interactive_tool_copernicus_notebook"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Sentinel 5P data visualisation", "datasets": ["sentinel5.nc"], "dataset_paths": ["sentinel5.nc"], "dataset_count": 1, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 1, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_panoply"]}, "query_type": "science_first", "tool_focus": "interactive_tool_copernicus_notebook"}}
{"id": "sentinel5_data-q02", "tutorial_id": "topics/climate/tutorials/sentinel5_data", "query": "How can I use a JupyterLab tool to download and visualize Copernicus Data Space Ecosystem data for climate monitoring?", "tools": ["interactive_tool_copernicus_notebook"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Sentinel 5P data visualisation", "datasets": ["sentinel5.nc"], "dataset_paths": ["sentinel5.nc"], "dataset_count": 1, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 2, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_panoply"]}, "query_type": "science_first", "tool_focus": "interactive_tool_copernicus_notebook"}}
{"id": "sentinel5_data-q03", "tutorial_id": "topics/climate/tutorials/sentinel5_data", "query": "Which Galaxy tool can I use to access and download Copernicus Data Space Ecosystem data?", "tools": ["interactive_tool_copernicus_notebook"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Sentinel 5P data visualisation", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 3, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_panoply"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_copernicus_notebook"}}
{"id": "sentinel5_data-q04", "tutorial_id": "topics/climate/tutorials/sentinel5_data", "query": "How do I navigate and run a JupyterLab notebook in Galaxy to process Sentinel 5P data?", "tools": ["interactive_tool_copernicus_notebook"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Sentinel 5P data visualisation", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 4, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_panoply"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_copernicus_notebook"}}
{"id": "sentinel5_data-q05", "tutorial_id": "topics/climate/tutorials/sentinel5_data", "query": "I have Sentinel 5P data in netCDF format, which Galaxy tool can I use to visualize and analyze the data?", "tools": ["interactive_tool_panoply"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Sentinel 5P data visualisation", "datasets": ["sentinel5_SO2.nc", "sentinel5_aerosol_340.nc", "sentinel5_aerosol_354.nc"], "dataset_paths": ["sentinel5_SO2.nc", "sentinel5_aerosol_340.nc", "sentinel5_aerosol_354.nc"], "dataset_count": 3, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 5, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_panoply"]}, "query_type": "science_first", "tool_focus": "interactive_tool_panoply"}}
{"id": "sentinel5_data-q06", "tutorial_id": "topics/climate/tutorials/sentinel5_data", "query": "How can I create a georeferenced plot of Sentinel 5P data using a Galaxy tool?", "tools": ["interactive_tool_panoply"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Sentinel 5P data visualisation", "datasets": ["sentinel5_SO2.nc", "sentinel5_aerosol_340.nc", "sentinel5_aerosol_354.nc"], "dataset_paths": ["sentinel5_SO2.nc", "sentinel5_aerosol_340.nc", "sentinel5_aerosol_354.nc"], "dataset_count": 3, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 6, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_panoply"]}, "query_type": "science_first", "tool_focus": "interactive_tool_panoply"}}
{"id": "sentinel5_data-q07", "tutorial_id": "topics/climate/tutorials/sentinel5_data", "query": "Which Galaxy tool can I use to visualize and analyze netCDF data?", "tools": ["interactive_tool_panoply"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Sentinel 5P data visualisation", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 7, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_panoply"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_panoply"}}
{"id": "sentinel5_data-q08", "tutorial_id": "topics/climate/tutorials/sentinel5_data", "query": "How do I export an animation of Sentinel 5P data from a Galaxy tool?", "tools": ["interactive_tool_panoply"], "workflows": ["main_workflow"], "metadata": {"topic": "climate", "tutorial_title": "Sentinel 5P data visualisation", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 8, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_panoply"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_panoply"}}
{"id": "community-lab-q01", "tutorial_id": "topics/community/tutorials/community-lab", "query": "I need to create a lab webpage for my community on Galaxy, what tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of the labs in the different Galaxy instances for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The **Community lab**, a centralised webpage that enables communities to rapidly aggregate, curate, integrate, display, and launch relevant tools, workflows, and training on different Galaxy servers. This user-friendly interface, built on the Galaxy framework, provides community members with data analysis capacity without requiring programming expertise. Users can run individual tools or create complex workflows, with full provenance tracking to ensure reproducibility, designed specifically for the community research (Nasr et al., 2024).", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "community-lab-q02", "tutorial_id": "topics/community/tutorials/community-lab", "query": "How do I add a new section to the community lab webpage in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of the labs in the different Galaxy instances for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The **Community lab**, a centralised webpage that enables communities to rapidly aggregate, curate, integrate, display, and launch relevant tools, workflows, and training on different Galaxy servers. This user-friendly interface, built on the Galaxy framework, provides community members with data analysis capacity without requiring programming expertise. Users can run individual tools or create complex workflows, with full provenance tracking to ensure reproducibility, designed specifically for the community research (Nasr et al., 2024).", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "community-lab-q03", "tutorial_id": "topics/community/tutorials/community-lab", "query": "What tools are required to personalize the community lab files generated by the script in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of the labs in the different Galaxy instances for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The **Community lab**, a centralised webpage that enables communities to rapidly aggregate, curate, integrate, display, and launch relevant tools, workflows, and training on different Galaxy servers. This user-friendly interface, built on the Galaxy framework, provides community members with data analysis capacity without requiring programming expertise. Users can run individual tools or create complex workflows, with full provenance tracking to ensure reproducibility, designed specifically for the community research (Nasr et al., 2024).", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "community-lab-q04", "tutorial_id": "topics/community/tutorials/community-lab", "query": "How can I include the community lab in different Galaxy instances?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of the labs in the different Galaxy instances for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The **Community lab**, a centralised webpage that enables communities to rapidly aggregate, curate, integrate, display, and launch relevant tools, workflows, and training on different Galaxy servers. This user-friendly interface, built on the Galaxy framework, provides community members with data analysis capacity without requiring programming expertise. Users can run individual tools or create complex workflows, with full provenance tracking to ensure reproducibility, designed specifically for the community research (Nasr et al., 2024).", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "community-tool-table-q01", "tutorial_id": "topics/community/tutorials/community-tool-table", "query": "I want to add my community to the Galaxy CoDex but I'm not sure how to create a new folder in the data/community folder within Galaxy CoDex code source. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of resources listing all the tools and their metadata relevant to your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy offers thousands of tools. They are developed across various GitHub repositories. Furthermore, Galaxy also embraces granular implementation of software tools as sub-modules. In practice, this means that tool suites are separated into Galaxy tools, also known as wrappers, that capture their component operations. Some key examples of suites include [Mothur](https://bio.tools/mothur) and [OpenMS](https://bio.tools/openms), which translate to tens and even hundreds of Galaxy tools.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "community-tool-table-q02", "tutorial_id": "topics/community/tutorials/community-tool-table", "query": "I need to select ToolShed categories for my community, but I'm not sure which categories are most relevant. How can I choose the best categories for my community?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of resources listing all the tools and their metadata relevant to your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy offers thousands of tools. They are developed across various GitHub repositories. Furthermore, Galaxy also embraces granular implementation of software tools as sub-modules. In practice, this means that tool suites are separated into Galaxy tools, also known as wrappers, that capture their component operations. Some key examples of suites include [Mothur](https://bio.tools/mothur) and [OpenMS](https://bio.tools/openms), which translate to tens and even hundreds of Galaxy tools.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "community-tool-table-q03", "tutorial_id": "topics/community/tutorials/community-tool-table", "query": "I have added my community to the Galaxy CoDex and selected the ToolShed categories, but I'm not sure how to submit the new list of categories to Galaxy CoDex. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of resources listing all the tools and their metadata relevant to your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy offers thousands of tools. They are developed across various GitHub repositories. Furthermore, Galaxy also embraces granular implementation of software tools as sub-modules. In practice, this means that tool suites are separated into Galaxy tools, also known as wrappers, that capture their component operations. Some key examples of suites include [Mothur](https://bio.tools/mothur) and [OpenMS](https://bio.tools/openms), which translate to tens and even hundreds of Galaxy tools.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "community-tool-table-q04", "tutorial_id": "topics/community/tutorials/community-tool-table", "query": "I want to embed the interactive table in my community page on the Hub, but I'm not sure how to add an iframe to embed the interactive table. Can you provide an example?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of resources listing all the tools and their metadata relevant to your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy offers thousands of tools. They are developed across various GitHub repositories. Furthermore, Galaxy also embraces granular implementation of software tools as sub-modules. In practice, this means that tool suites are separated into Galaxy tools, also known as wrappers, that capture their component operations. Some key examples of suites include [Mothur](https://bio.tools/mothur) and [OpenMS](https://bio.tools/openms), which translate to tens and even hundreds of Galaxy tools.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "community-tutorial-table-q01", "tutorial_id": "topics/community/tutorials/community-tutorial-table", "query": "I want to add my community to the Galaxy CoDex, but I don't know how to create a new folder in the data/community folder within Galaxy CoDex code source. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of a Galaxy tutorial table for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Similarly to the numerous tools available on Galaxy, the [Galaxy Training Network](https://training.galaxyproject.org/) includes numerous tutorials. This tutorial will take you through the steps to generate resources listing all the relevant tutorials and display the tutorial table on your community codex page.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "community-tutorial-table-q02", "tutorial_id": "topics/community/tutorials/community-tutorial-table", "query": "I have identified some tags relevant to my community, but I'm not sure how to add them to the tutorial_tags file. Can you guide me through the process?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of a Galaxy tutorial table for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Similarly to the numerous tools available on Galaxy, the [Galaxy Training Network](https://training.galaxyproject.org/) includes numerous tutorials. This tutorial will take you through the steps to generate resources listing all the relevant tutorials and display the tutorial table on your community codex page.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "community-tutorial-table-q03", "tutorial_id": "topics/community/tutorials/community-tutorial-table", "query": "I want to embed the tutorial table in my community page on the Hub, but I don't know how to fork the Galaxy Hub repository and open my community page. What are the steps?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of a Galaxy tutorial table for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Similarly to the numerous tools available on Galaxy, the [Galaxy Training Network](https://training.galaxyproject.org/) includes numerous tutorials. This tutorial will take you through the steps to generate resources listing all the relevant tutorials and display the tutorial table on your community codex page.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "community-tutorial-table-q04", "tutorial_id": "topics/community/tutorials/community-tutorial-table", "query": "I have made changes to my community's tutorial_tags file and submitted a pull request, but I'm not sure what happens next. How can I ensure that my changes are reviewed and merged?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of a Galaxy tutorial table for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Similarly to the numerous tools available on Galaxy, the [Galaxy Training Network](https://training.galaxyproject.org/) includes numerous tutorials. This tutorial will take you through the steps to generate resources listing all the relevant tutorials and display the tutorial table on your community codex page.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "community-workflow-table-q01", "tutorial_id": "topics/community/tutorials/community-workflow-table", "query": "I need to add my community to the Galaxy CoDex, but I'm not sure how to create a new folder in the data/community folder within Galaxy CoDex code source. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of resources listing Galaxy workflow for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Similarly to the numerous tools available on Galaxy, numerous workflow are available on public Galaxy instances and in [Workflow Hub](https://workflowhub.eu/). This tutorail will take you through the steps to generate resources listing the relevant workflows and how to display them on your community codex page.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "community-workflow-table-q02", "tutorial_id": "topics/community/tutorials/community-workflow-table", "query": "I have a list of tags relevant to my community, but I'm not sure how to add them to the workflow_tags file in my community metadata folder. What are the steps to do this?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of resources listing Galaxy workflow for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Similarly to the numerous tools available on Galaxy, numerous workflow are available on public Galaxy instances and in [Workflow Hub](https://workflowhub.eu/). This tutorail will take you through the steps to generate resources listing the relevant workflows and how to display them on your community codex page.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "community-workflow-table-q03", "tutorial_id": "topics/community/tutorials/community-workflow-table", "query": "I want to filter the workflows in my community table to only include workflows that are relevant to my research community. How can I update the 'To keep' and 'Deprecated' columns in the workflow_status.tsv file?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of resources listing Galaxy workflow for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Similarly to the numerous tools available on Galaxy, numerous workflow are available on public Galaxy instances and in [Workflow Hub](https://workflowhub.eu/). This tutorail will take you through the steps to generate resources listing the relevant workflows and how to display them on your community codex page.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "community-workflow-table-q04", "tutorial_id": "topics/community/tutorials/community-workflow-table", "query": "I have updated my community's workflow_status.tsv file and want to embed the table in my community page on the Hub. What are the steps to include the table in my community page?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creation of resources listing Galaxy workflow for your community", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Similarly to the numerous tools available on Galaxy, numerous workflow are available on public Galaxy instances and in [Workflow Hub](https://workflowhub.eu/). This tutorail will take you through the steps to generate resources listing the relevant workflows and how to display them on your community codex page.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "community_content-q01", "tutorial_id": "topics/community/tutorials/community_content", "query": "I want to see the usage statistics for my topic, but I'm not sure how to access it. How do I find the topic usage statistics page?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creating community content", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy *[Special Interest Group](https://galaxyproject.org/community/sig)* (**SIG**)s work hard to build and maintain training resources. The GTN has worked hard to acknowledge this and offer nice impact pages to communities.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "community_content-q02", "tutorial_id": "topics/community/tutorials/community_content", "query": "I want to embed news and events into my community page. What tools or features can I use to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creating community content", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy *[Special Interest Group](https://galaxyproject.org/community/sig)* (**SIG**)s work hard to build and maintain training resources. The GTN has worked hard to acknowledge this and offer nice impact pages to communities.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "community_content-q03", "tutorial_id": "topics/community/tutorials/community_content", "query": "Which Galaxy feature can I use to search for workflows tagged with my community tag across public servers?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creating community content", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy *[Special Interest Group](https://galaxyproject.org/community/sig)* (**SIG**)s work hard to build and maintain training resources. The GTN has worked hard to acknowledge this and offer nice impact pages to communities.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "community_content-q04", "tutorial_id": "topics/community/tutorials/community_content", "query": "How can I access the Maintainer Home page for my topic to update and fix materials?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creating community content", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy *[Special Interest Group](https://galaxyproject.org/community/sig)* (**SIG**)s work hard to build and maintain training resources. The GTN has worked hard to acknowledge this and offer nice impact pages to communities.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "sig_create-q01", "tutorial_id": "topics/community/tutorials/sig_create", "query": "I want to create a new Special Interest Group (SIG) in Galaxy, what are the essential requirements that I need to fulfill?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creating a Special Interest Group", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "So you have decided to create a new Special Interest Group (**SIG**)!", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "sig_create-q02", "tutorial_id": "topics/community/tutorials/sig_create", "query": "How do I create a Matrix group within the Galaxy Matrix chat forum space for my new SIG?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creating a Special Interest Group", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "So you have decided to create a new Special Interest Group (**SIG**)!", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "sig_create-q03", "tutorial_id": "topics/community/tutorials/sig_create", "query": "What are the steps to end a SIG if it is no longer active or needed?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creating a Special Interest Group", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "So you have decided to create a new Special Interest Group (**SIG**)!", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "sig_create-q04", "tutorial_id": "topics/community/tutorials/sig_create", "query": "How do I update the SIG Directory on the Hub to reflect changes in my SIG's information or status?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Creating a Special Interest Group", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "So you have decided to create a new Special Interest Group (**SIG**)!", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "sig_define-q01", "tutorial_id": "topics/community/tutorials/sig_define", "query": "I want to assess library quality for my paired-end FASTQ reads from a ChIP-seq experiment before alignment. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "What's a Special Interest Group?", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In Galaxy, the term *[Special Interest Group](https://galaxyproject.org/community/sig)* (**SIG**) refers to a dedicated scientific community that crosses individual lab boundaries and wants to collaborate, share resources, support each other, and/or collectively advocate on a given theme. We have **SIGs** based on [**region**](https://galaxyproject.org/community/sig/#regional-communities), [**domain of science**](https://galaxyproject.org/community/sig/#communities-of-practice), and more. You might consider that a **SIG** covers any group of like-minded Galaxy enthusiasts not currently combined into a [**Working Group**](https://galaxyproject.org/community/wg/).", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "sig_define-q02", "tutorial_id": "topics/community/tutorials/sig_define", "query": "Which Galaxy tool should I use to assess read quality for my single-cell FASTQ files showing variable read quality?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "What's a Special Interest Group?", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In Galaxy, the term *[Special Interest Group](https://galaxyproject.org/community/sig)* (**SIG**) refers to a dedicated scientific community that crosses individual lab boundaries and wants to collaborate, share resources, support each other, and/or collectively advocate on a given theme. We have **SIGs** based on [**region**](https://galaxyproject.org/community/sig/#regional-communities), [**domain of science**](https://galaxyproject.org/community/sig/#communities-of-practice), and more. You might consider that a **SIG** covers any group of like-minded Galaxy enthusiasts not currently combined into a [**Working Group**](https://galaxyproject.org/community/wg/).", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "sig_define-q03", "tutorial_id": "topics/community/tutorials/sig_define", "query": "How can I gather input from members of a Special Interest Group in Galaxy for a collaborative project?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "What's a Special Interest Group?", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In Galaxy, the term *[Special Interest Group](https://galaxyproject.org/community/sig)* (**SIG**) refers to a dedicated scientific community that crosses individual lab boundaries and wants to collaborate, share resources, support each other, and/or collectively advocate on a given theme. We have **SIGs** based on [**region**](https://galaxyproject.org/community/sig/#regional-communities), [**domain of science**](https://galaxyproject.org/community/sig/#communities-of-practice), and more. You might consider that a **SIG** covers any group of like-minded Galaxy enthusiasts not currently combined into a [**Working Group**](https://galaxyproject.org/community/wg/).", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "sig_define-q04", "tutorial_id": "topics/community/tutorials/sig_define", "query": "What steps can I take to build a community around my Special Interest Group in Galaxy and increase user engagement?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "What's a Special Interest Group?", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In Galaxy, the term *[Special Interest Group](https://galaxyproject.org/community/sig)* (**SIG**) refers to a dedicated scientific community that crosses individual lab boundaries and wants to collaborate, share resources, support each other, and/or collectively advocate on a given theme. We have **SIGs** based on [**region**](https://galaxyproject.org/community/sig/#regional-communities), [**domain of science**](https://galaxyproject.org/community/sig/#communities-of-practice), and more. You might consider that a **SIG** covers any group of like-minded Galaxy enthusiasts not currently combined into a [**Working Group**](https://galaxyproject.org/community/wg/).", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "tools_subdomains-q01", "tutorial_id": "topics/community/tutorials/tools_subdomains", "query": "I want to make my tool visible on my subdomain, what repository should I clone?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Make your tools available on your subdomain", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial explains how to make your brand new tools, once they're published through a Pull Request ([check this tutorial]({%link topics/dev/tutorials/tool-from-scratch/tutorial.md %}) on how to build your tool from scracth), visible on your subdomain. Here we'll follow the example on how to make the tools visible on [Galaxy for earth System](https://earth-system.usegalaxy.eu/). You can also find the explanations on how to add your tools on this [Github page](https://usegalaxy-eu.github.io/operations/subdomains.html).", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "tools_subdomains-q02", "tutorial_id": "topics/community/tutorials/tools_subdomains", "query": "How do I add a new section for my tools on my subdomain?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Make your tools available on your subdomain", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial explains how to make your brand new tools, once they're published through a Pull Request ([check this tutorial]({%link topics/dev/tutorials/tool-from-scratch/tutorial.md %}) on how to build your tool from scracth), visible on your subdomain. Here we'll follow the example on how to make the tools visible on [Galaxy for earth System](https://earth-system.usegalaxy.eu/). You can also find the explanations on how to add your tools on this [Github page](https://usegalaxy-eu.github.io/operations/subdomains.html).", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "tools_subdomains-q03", "tutorial_id": "topics/community/tutorials/tools_subdomains", "query": "What file do I need to edit to add my interactive tool to the right section?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Make your tools available on your subdomain", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial explains how to make your brand new tools, once they're published through a Pull Request ([check this tutorial]({%link topics/dev/tutorials/tool-from-scratch/tutorial.md %}) on how to build your tool from scracth), visible on your subdomain. Here we'll follow the example on how to make the tools visible on [Galaxy for earth System](https://earth-system.usegalaxy.eu/). You can also find the explanations on how to add your tools on this [Github page](https://usegalaxy-eu.github.io/operations/subdomains.html).", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "tools_subdomains-q04", "tutorial_id": "topics/community/tutorials/tools_subdomains", "query": "How do I make my batch tool visible in my subdomain?", "tools": [], "workflows": [], "metadata": {"topic": "community", "tutorial_title": "Make your tools available on your subdomain", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial explains how to make your brand new tools, once they're published through a Pull Request ([check this tutorial]({%link topics/dev/tutorials/tool-from-scratch/tutorial.md %}) on how to build your tool from scracth), visible on your subdomain. Here we'll follow the example on how to make the tools visible on [Galaxy for earth System](https://earth-system.usegalaxy.eu/). You can also find the explanations on how to add your tools on this [Github page](https://usegalaxy-eu.github.io/operations/subdomains.html).", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "setting-up-molecular-systems-q01", "tutorial_id": "topics/computational-chemistry/tutorials/setting-up-molecular-systems", "query": "I have a PDB file of a protein-ligand complex and I want to set up a molecular system for simulation. What tools or software would I need to use to prepare the system for molecular dynamics simulation?", "tools": [], "workflows": [], "metadata": {"topic": "computational-chemistry", "tutorial_title": "Setting up molecular systems", "datasets": ["2600690"], "dataset_paths": ["2600690"], "dataset_count": 1, "context_summary": "In this tutorial, we'll cover the basics of molecular modelling by setting up a protein in complex with a ligand and uploading the structure to Galaxy. This tutorial will make use of CHARMM-GUI. Please note that the follow-up to this tutorial (located in [Running molecular dynamics simulations using NAMD]({% link topics/computational-chemistry/tutorials/md-simulation-namd/tutorial.md %})) requires access to NAMD Galaxy tools, which can be accessed using the [Docker container](https://github.com/scientificomputing/BRIDGE) but are currently not available on any public Galaxy server.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "setting-up-molecular-systems-q02", "tutorial_id": "topics/computational-chemistry/tutorials/setting-up-molecular-systems", "query": "I need to upload a protein structure to Galaxy for molecular modelling. How can I convert my PDB file to a format that can be used by CHARMM-GUI?", "tools": [], "workflows": [], "metadata": {"topic": "computational-chemistry", "tutorial_title": "Setting up molecular systems", "datasets": ["2600690"], "dataset_paths": ["2600690"], "dataset_count": 1, "context_summary": "In this tutorial, we'll cover the basics of molecular modelling by setting up a protein in complex with a ligand and uploading the structure to Galaxy. This tutorial will make use of CHARMM-GUI. Please note that the follow-up to this tutorial (located in [Running molecular dynamics simulations using NAMD]({% link topics/computational-chemistry/tutorials/md-simulation-namd/tutorial.md %})) requires access to NAMD Galaxy tools, which can be accessed using the [Docker container](https://github.com/scientificomputing/BRIDGE) but are currently not available on any public Galaxy server.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "setting-up-molecular-systems-q03", "tutorial_id": "topics/computational-chemistry/tutorials/setting-up-molecular-systems", "query": "What tool can I use in Galaxy to solvate a protein structure with a waterbox and add ions for molecular dynamics simulation?", "tools": [], "workflows": [], "metadata": {"topic": "computational-chemistry", "tutorial_title": "Setting up molecular systems", "datasets": ["2600690"], "dataset_paths": ["2600690"], "dataset_count": 1, "context_summary": "In this tutorial, we'll cover the basics of molecular modelling by setting up a protein in complex with a ligand and uploading the structure to Galaxy. This tutorial will make use of CHARMM-GUI. Please note that the follow-up to this tutorial (located in [Running molecular dynamics simulations using NAMD]({% link topics/computational-chemistry/tutorials/md-simulation-namd/tutorial.md %})) requires access to NAMD Galaxy tools, which can be accessed using the [Docker container](https://github.com/scientificomputing/BRIDGE) but are currently not available on any public Galaxy server.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "setting-up-molecular-systems-q04", "tutorial_id": "topics/computational-chemistry/tutorials/setting-up-molecular-systems", "query": "I have prepared a molecular system using CHARMM-GUI and I want to upload it to Galaxy for further analysis. How can I upload the PSF, PDB, and other output files from CHARMM-GUI to Galaxy and ensure they are in the correct format?", "tools": [], "workflows": [], "metadata": {"topic": "computational-chemistry", "tutorial_title": "Setting up molecular systems", "datasets": ["2600690"], "dataset_paths": ["2600690"], "dataset_count": 1, "context_summary": "In this tutorial, we'll cover the basics of molecular modelling by setting up a protein in complex with a ligand and uploading the structure to Galaxy. This tutorial will make use of CHARMM-GUI. Please note that the follow-up to this tutorial (located in [Running molecular dynamics simulations using NAMD]({% link topics/computational-chemistry/tutorials/md-simulation-namd/tutorial.md %})) requires access to NAMD Galaxy tools, which can be accessed using the [Docker container](https://github.com/scientificomputing/BRIDGE) but are currently not available on any public Galaxy server.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "admin-knitting-q01", "tutorial_id": "topics/contributing/tutorials/admin-knitting", "query": "I want to update the text of a specific commit in the admin training tutorial. What tools would I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Updating diffs in admin training", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Updating Diffs", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "admin-knitting-q02", "tutorial_id": "topics/contributing/tutorials/admin-knitting", "query": "How can I add a new commit to the admin training tutorial using the knit-automated.sh script?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Updating diffs in admin training", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Updating Diffs", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "admin-knitting-q03", "tutorial_id": "topics/contributing/tutorials/admin-knitting", "query": "I need to upgrade an existing tutorial in the admin training to use the new diffs feature. What tools would I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Updating diffs in admin training", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Updating Diffs", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "admin-knitting-q04", "tutorial_id": "topics/contributing/tutorials/admin-knitting", "query": "How can I fix the 'sha1 information is lacking or useless' error when applying patches to the admin training tutorial?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Updating diffs in admin training", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Updating Diffs", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "create-new-topic-q01", "tutorial_id": "topics/contributing/tutorials/create-new-topic", "query": "I want to create a new topic for my training materials. What tools do I need to use to create the directory structure and metadata for the topic?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Including a new topic", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Each training material is related to a topic. All training materials (slides, tutorials, ...) related to a topic are found in a dedicated directory (*e.g.* `transcriptomics` directory contains the material related to exome sequencing analysis).", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "create-new-topic-q02", "tutorial_id": "topics/contributing/tutorials/create-new-topic", "query": "How do I create a new topic with its own materials in Galaxy Training Network?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Including a new topic", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Each training material is related to a topic. All training materials (slides, tutorials, ...) related to a topic are found in a dedicated directory (*e.g.* `transcriptomics` directory contains the material related to exome sequencing analysis).", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "create-new-topic-q03", "tutorial_id": "topics/contributing/tutorials/create-new-topic", "query": "I want to add a new tutorial to an existing topic. What steps do I need to take to create the tutorial directory and metadata?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Including a new topic", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Each training material is related to a topic. All training materials (slides, tutorials, ...) related to a topic are found in a dedicated directory (*e.g.* `transcriptomics` directory contains the material related to exome sequencing analysis).", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "create-new-topic-q04", "tutorial_id": "topics/contributing/tutorials/create-new-topic", "query": "How can I define a tag-based topic and aggregate related tutorials in Galaxy Training Network?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Including a new topic", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Each training material is related to a topic. All training materials (slides, tutorials, ...) related to a topic are found in a dedicated directory (*e.g.* `transcriptomics` directory contains the material related to exome sequencing analysis).", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-content-q01", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-content", "query": "I have paired-end FASTQ reads from a ChIP-seq experiment and want to assess library quality before alignment. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Creating content in Markdown", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Once we have set up the infrastructure, we are ready to write the tutorial.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "create-new-tutorial-content-q02", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-content", "query": "My single-cell FASTQ files show variable read quality; how can I clean them for downstream analysis?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Creating content in Markdown", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Once we have set up the infrastructure, we are ready to write the tutorial.", "priority": 2, "version": "v0", "query_type": "science_first"}}
{"id": "create-new-tutorial-content-q03", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-content", "query": "Which Galaxy tool should I use to assess read quality for my paired-end FASTQ reads?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Creating content in Markdown", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Once we have set up the infrastructure, we are ready to write the tutorial.", "priority": 3, "version": "v0", "query_type": "tool_first"}}
{"id": "create-new-tutorial-content-q04", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-content", "query": "How can I trim adapters and low-quality bases on my single-cell FASTQ files in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Creating content in Markdown", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Once we have set up the infrastructure, we are ready to write the tutorial.", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "create-new-tutorial-quiz-q01", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-quiz", "query": "I want to create an interactive quiz in Galaxy, what tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Adding Quizzes to your Tutorial", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Interactive quizzes can be used either alone, or with a classroom of students, to check student's knowledge.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-quiz-q02", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-quiz", "query": "How do I insert a quiz at a specific place within a tutorial in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Adding Quizzes to your Tutorial", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Interactive quizzes can be used either alone, or with a classroom of students, to check student's knowledge.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-quiz-q03", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-quiz", "query": "What tools are required to create a Kahoot-like interface for a quiz in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Adding Quizzes to your Tutorial", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Interactive quizzes can be used either alone, or with a classroom of students, to check student's knowledge.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-quiz-q04", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-quiz", "query": "How can I show the results of a poll live during a quiz in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Adding Quizzes to your Tutorial", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Interactive quizzes can be used either alone, or with a classroom of students, to check student's knowledge.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-technical-q01", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-technical", "query": "I need to test if a public Galaxy instance can run the tools required for my tutorial. What tools are needed to run a workflow on a Galaxy instance?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Tools, Data, and Workflows for tutorials", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Building a Galaxy instance specifically for your training", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-technical-q02", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-technical", "query": "How do I create a workflow that represents the steps taken in my tutorial and extract it to add to the workflows directory in my tutorial?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Tools, Data, and Workflows for tutorials", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Building a Galaxy instance specifically for your training", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-technical-q03", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-technical", "query": "What tools are required to create a virtualized Galaxy instance based on Docker to run my training?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Tools, Data, and Workflows for tutorials", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Building a Galaxy instance specifically for your training", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-technical-q04", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-technical", "query": "How do I test the technical infrastructure required to run my tutorial, either in a locally running Galaxy or in a Docker container?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Tools, Data, and Workflows for tutorials", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Building a Galaxy instance specifically for your training", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-tours-q01", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-tours", "query": "I want to create a Galaxy Interactive Tour for a BLAST tutorial. What tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Creating Interactive Galaxy Tours", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy is a great solution to train the bioinformatics concepts:", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-tours-q02", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-tours", "query": "How do I integrate a YAML file of a tour into a Galaxy instance?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Creating Interactive Galaxy Tours", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy is a great solution to train the bioinformatics concepts:", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-tours-q03", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-tours", "query": "I need to design a new tutorial for a Galaxy Interactive Tour. What are the essential steps I should follow?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Creating Interactive Galaxy Tours", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy is a great solution to train the bioinformatics concepts:", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "create-new-tutorial-tours-q04", "tutorial_id": "topics/contributing/tutorials/create-new-tutorial-tours", "query": "How can I test a Galaxy Interactive Tour on a local Galaxy instance?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Creating Interactive Galaxy Tours", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy is a great solution to train the bioinformatics concepts:", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "design-q01", "tutorial_id": "topics/contributing/tutorials/design", "query": "I want to create a 3-minute training session on Galaxy interface. What tools or software do I need to make it interactive?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Design and plan session, course, materials", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "**Teaching and training**, core elements of academic life, can be enormously", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "design-q02", "tutorial_id": "topics/contributing/tutorials/design", "query": "How can I assess the effectiveness of a training session on Galaxy interface in leading learners to the stated learning outcomes?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Design and plan session, course, materials", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "**Teaching and training**, core elements of academic life, can be enormously", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "design-q03", "tutorial_id": "topics/contributing/tutorials/design", "query": "What tools can I use to create a concept map for my training session on Galaxy interface?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Design and plan session, course, materials", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "**Teaching and training**, core elements of academic life, can be enormously", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "design-q04", "tutorial_id": "topics/contributing/tutorials/design", "query": "How can I write learning outcomes that are SMART (Specific, Measurable, Achievable, Realistic, Time-bound) for my training session on Galaxy interface?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Design and plan session, course, materials", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "**Teaching and training**, core elements of academic life, can be enormously", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-by-design-q01", "tutorial_id": "topics/contributing/tutorials/fair-by-design", "query": "I need to create a concept map of my learning materials as part of the FAIR-by-Design Methodology. What tools would I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "FAIR-by-Design methodology", "datasets": ["data/datasets/contributing/fair-by-design/microlearning.zip"], "dataset_paths": ["data/datasets/contributing/fair-by-design/microlearning.zip"], "dataset_count": 1, "context_summary": "Welcome to the FAIR-by-Design Methodology Microlearning GTN adapted tutorial.\n\nDataset files (1): data/datasets/contributing/fair-by-design/microlearning.zip", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fair-by-design-q02", "tutorial_id": "topics/contributing/tutorials/fair-by-design", "query": "How do I properly attribute a CC-licensed learning material that I want to reuse in my own materials?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "FAIR-by-Design methodology", "datasets": ["data/datasets/contributing/fair-by-design/microlearning.zip"], "dataset_paths": ["data/datasets/contributing/fair-by-design/microlearning.zip"], "dataset_count": 1, "context_summary": "Welcome to the FAIR-by-Design Methodology Microlearning GTN adapted tutorial.\n\nDataset files (1): data/datasets/contributing/fair-by-design/microlearning.zip", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fair-by-design-q03", "tutorial_id": "topics/contributing/tutorials/fair-by-design", "query": "I want to make my learning materials available in an open repository like Zenodo. What steps should I take to ensure they are properly indexed and discoverable?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "FAIR-by-Design methodology", "datasets": ["data/datasets/contributing/fair-by-design/microlearning.zip"], "dataset_paths": ["data/datasets/contributing/fair-by-design/microlearning.zip"], "dataset_count": 1, "context_summary": "Welcome to the FAIR-by-Design Methodology Microlearning GTN adapted tutorial.\n\nDataset files (1): data/datasets/contributing/fair-by-design/microlearning.zip", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-by-design-q04", "tutorial_id": "topics/contributing/tutorials/fair-by-design", "query": "What are some strategies for designing learning content that is accessible to learners with different learning modalities?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "FAIR-by-Design methodology", "datasets": ["data/datasets/contributing/fair-by-design/microlearning.zip"], "dataset_paths": ["data/datasets/contributing/fair-by-design/microlearning.zip"], "dataset_count": 1, "context_summary": "Welcome to the FAIR-by-Design Methodology Microlearning GTN adapted tutorial.\n\nDataset files (1): data/datasets/contributing/fair-by-design/microlearning.zip", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-gtn-q01", "tutorial_id": "topics/contributing/tutorials/fair-gtn", "query": "I want to make my training materials findable by properly describing them, what tools should I use to create and edit metadata?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "FAIR Galaxy Training Material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Encouraging computational reproducibility in research, we will present a variety of data stewardship recommendations that we have found useful in the process of training development. As part of that process, we are exploring the application of the FAIR (Findable, Accessible, Interoperable, Reusable) guidelines to the Galaxy Training Network (GTN) materials, in order to improve their secondary use and adaptation.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fair-gtn-q02", "tutorial_id": "topics/contributing/tutorials/fair-gtn", "query": "How can I give my training materials a unique identity and register them online to make them more discoverable and accessible?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "FAIR Galaxy Training Material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Encouraging computational reproducibility in research, we will present a variety of data stewardship recommendations that we have found useful in the process of training development. As part of that process, we are exploring the application of the FAIR (Findable, Accessible, Interoperable, Reusable) guidelines to the Galaxy Training Network (GTN) materials, in order to improve their secondary use and adaptation.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fair-gtn-q03", "tutorial_id": "topics/contributing/tutorials/fair-gtn", "query": "What tools are required to use an interoperable format for my training materials, such as Markdown and YAML?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "FAIR Galaxy Training Material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Encouraging computational reproducibility in research, we will present a variety of data stewardship recommendations that we have found useful in the process of training development. As part of that process, we are exploring the application of the FAIR (Findable, Accessible, Interoperable, Reusable) guidelines to the Galaxy Training Network (GTN) materials, in order to improve their secondary use and adaptation.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-gtn-q04", "tutorial_id": "topics/contributing/tutorials/fair-gtn", "query": "How can I make my training materials reusable for trainers and trainees by adding metadata and licenses?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "FAIR Galaxy Training Material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Encouraging computational reproducibility in research, we will present a variety of data stewardship recommendations that we have found useful in the process of training development. As part of that process, we are exploring the application of the FAIR (Findable, Accessible, Interoperable, Reusable) guidelines to the Galaxy Training Network (GTN) materials, in order to improve their secondary use and adaptation.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "generating-pdf-q01", "tutorial_id": "topics/contributing/tutorials/generating-pdf", "query": "I want to generate PDFs of the tutorials, what tools do I need to install on my local machine to run the command `make pdf`?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Generating PDF artefacts of the website", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The website with the training material can be run locally. Sometimes, it is also interesting to freeze the tutorials or to get PDFs of the tutorials.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "generating-pdf-q02", "tutorial_id": "topics/contributing/tutorials/generating-pdf", "query": "How do I run a local instance of the GTN website to generate PDFs of the tutorials?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Generating PDF artefacts of the website", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The website with the training material can be run locally. Sometimes, it is also interesting to freeze the tutorials or to get PDFs of the tutorials.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "generating-pdf-q03", "tutorial_id": "topics/contributing/tutorials/generating-pdf", "query": "What software is required to generate PDFs of the slide decks by calling decktape using the `make pdf` command?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Generating PDF artefacts of the website", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The website with the training material can be run locally. Sometimes, it is also interesting to freeze the tutorials or to get PDFs of the tutorials.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "generating-pdf-q04", "tutorial_id": "topics/contributing/tutorials/generating-pdf", "query": "How can I check the generated PDFs in the `_pdf` folder after running the `make pdf` command?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Generating PDF artefacts of the website", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The website with the training material can be run locally. Sometimes, it is also interesting to freeze the tutorials or to get PDFs of the tutorials.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "github-contribution-q01", "tutorial_id": "topics/contributing/tutorials/github-contribution", "query": "I want to contribute to the Galaxy Training Network, but I don't have a GitHub account. What do I need to do to get started with creating a pull request?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Contributing to the Galaxy Training Network with GitHub", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Most of the GTN content is written in [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/) with some metadata (or variables) found in [YAML](http://yaml.org/) files. Everything is stored on a [GitHub](https://github.com) repository: [{{ site.github_repository }}]({{ site.github_repository }}).", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "github-contribution-q02", "tutorial_id": "topics/contributing/tutorials/github-contribution", "query": "I have made changes to a file in my local repository, but I'm not sure how to push those changes to my GitHub fork. What steps should I take?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Contributing to the Galaxy Training Network with GitHub", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Most of the GTN content is written in [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/) with some metadata (or variables) found in [YAML](http://yaml.org/) files. Everything is stored on a [GitHub](https://github.com) repository: [{{ site.github_repository }}]({{ site.github_repository }}).", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "github-contribution-q03", "tutorial_id": "topics/contributing/tutorials/github-contribution", "query": "I have created a new branch in my local repository and made some changes, but I'm not sure how to submit a pull request to the main repository. What do I need to do?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Contributing to the Galaxy Training Network with GitHub", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Most of the GTN content is written in [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/) with some metadata (or variables) found in [YAML](http://yaml.org/) files. Everything is stored on a [GitHub](https://github.com) repository: [{{ site.github_repository }}]({{ site.github_repository }}).", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "github-contribution-q04", "tutorial_id": "topics/contributing/tutorials/github-contribution", "query": "My pull request has been reviewed and I need to make some changes. How do I update my local repository and push the changes to my GitHub fork?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Contributing to the Galaxy Training Network with GitHub", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Most of the GTN content is written in [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/) with some metadata (or variables) found in [YAML](http://yaml.org/) files. Everything is stored on a [GitHub](https://github.com) repository: [{{ site.github_repository }}]({{ site.github_repository }}).", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "github-interface-contribution-q01", "tutorial_id": "topics/contributing/tutorials/github-interface-contribution", "query": "I want to edit a file in a GitHub repository. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Contributing with GitHub via its interface", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "All the training material which you find on [{{ site.url }}{{ site.baseurl }}/]({{ site.baseurl }}/) is stored on a [GitHub](https://github.com) repository ([{{ site.github_repository }}]({{ site.github_repository }})), a code hosting platform for version control and collaboration. GitHub interface is quite intuitive and simplifies the contributions from anyone.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "github-interface-contribution-q02", "tutorial_id": "topics/contributing/tutorials/github-interface-contribution", "query": "How do I create a pull request on GitHub to contribute to a repository?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Contributing with GitHub via its interface", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "All the training material which you find on [{{ site.url }}{{ site.baseurl }}/]({{ site.baseurl }}/) is stored on a [GitHub](https://github.com) repository ([{{ site.github_repository }}]({{ site.github_repository }})), a code hosting platform for version control and collaboration. GitHub interface is quite intuitive and simplifies the contributions from anyone.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "github-interface-contribution-q03", "tutorial_id": "topics/contributing/tutorials/github-interface-contribution", "query": "What is required to update a pull request on GitHub after a reviewer requests changes?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Contributing with GitHub via its interface", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "All the training material which you find on [{{ site.url }}{{ site.baseurl }}/]({{ site.baseurl }}/) is stored on a [GitHub](https://github.com) repository ([{{ site.github_repository }}]({{ site.github_repository }})), a code hosting platform for version control and collaboration. GitHub interface is quite intuitive and simplifies the contributions from anyone.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "github-interface-contribution-q04", "tutorial_id": "topics/contributing/tutorials/github-interface-contribution", "query": "How can I close a pull request on GitHub that I previously created?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Contributing with GitHub via its interface", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "All the training material which you find on [{{ site.url }}{{ site.baseurl }}/]({{ site.baseurl }}/) is stored on a [GitHub](https://github.com) repository ([{{ site.github_repository }}]({{ site.github_repository }})), a code hosting platform for version control and collaboration. GitHub interface is quite intuitive and simplifies the contributions from anyone.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "learning-principles-q01", "tutorial_id": "topics/contributing/tutorials/learning-principles", "query": "What are some ways to make room in working memory for learners?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Principles of learning and how they apply to training and teaching", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we will discuss the principles of learning", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "learning-principles-q02", "tutorial_id": "topics/contributing/tutorials/learning-principles", "query": "How can I apply the six strategies for effective learning in my teaching practice?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Principles of learning and how they apply to training and teaching", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we will discuss the principles of learning", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "learning-principles-q03", "tutorial_id": "topics/contributing/tutorials/learning-principles", "query": "What is the difference between teaching and training?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Principles of learning and how they apply to training and teaching", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we will discuss the principles of learning", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "learning-principles-q04", "tutorial_id": "topics/contributing/tutorials/learning-principles", "query": "How can I use Bloom's Taxonomy to design learning objectives?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Principles of learning and how they apply to training and teaching", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we will discuss the principles of learning", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "meta-analysis-data-q01", "tutorial_id": "topics/contributing/tutorials/meta-analysis-data", "query": "I have single-cell RNA-seq data and want to assess the quality of my reads. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Single Cell Publication - Data Analysis", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Extracting data from the GTN's Git history isn't that difficult, but it requires some internal knowledge of how the GTN's Jekyll-based codebase works. Here we'll document what we've done!", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "meta-analysis-data-q02", "tutorial_id": "topics/contributing/tutorials/meta-analysis-data", "query": "How can I trim adapters and low-quality bases from my single-cell RNA-seq data in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Single Cell Publication - Data Analysis", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Extracting data from the GTN's Git history isn't that difficult, but it requires some internal knowledge of how the GTN's Jekyll-based codebase works. Here we'll document what we've done!", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "meta-analysis-data-q03", "tutorial_id": "topics/contributing/tutorials/meta-analysis-data", "query": "Which tool can I use to analyze my single-cell RNA-seq data?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Single Cell Publication - Data Analysis", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Extracting data from the GTN's Git history isn't that difficult, but it requires some internal knowledge of how the GTN's Jekyll-based codebase works. Here we'll document what we've done!", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "meta-analysis-data-q04", "tutorial_id": "topics/contributing/tutorials/meta-analysis-data", "query": "How can I identify and remove contaminants from my single-cell RNA-seq data?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Single Cell Publication - Data Analysis", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Extracting data from the GTN's Git history isn't that difficult, but it requires some internal knowledge of how the GTN's Jekyll-based codebase works. Here we'll document what we've done!", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "meta-analysis-plot-q01", "tutorial_id": "topics/contributing/tutorials/meta-analysis-plot", "query": "I want to plot lines added/removed by date/time period for my single cell data. What tools would I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Single Cell Publication - Data Plotting", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "We'll use some ggplot and tidyverse code to plot the data we collected in part 1", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "meta-analysis-plot-q02", "tutorial_id": "topics/contributing/tutorials/meta-analysis-plot", "query": "How can I create a cumulative plot of lines added over time for my single cell data?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Single Cell Publication - Data Plotting", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "We'll use some ggplot and tidyverse code to plot the data we collected in part 1", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "meta-analysis-plot-q03", "tutorial_id": "topics/contributing/tutorials/meta-analysis-plot", "query": "What tools would I need to use to filter out null mergedAt dates and ignore certain classes of datasets when plotting contributions over time?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Single Cell Publication - Data Plotting", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "We'll use some ggplot and tidyverse code to plot the data we collected in part 1", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "meta-analysis-plot-q04", "tutorial_id": "topics/contributing/tutorials/meta-analysis-plot", "query": "How can I download and plot page views for my single cell topic, including annotations for outages and events?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Single Cell Publication - Data Plotting", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "We'll use some ggplot and tidyverse code to plot the data we collected in part 1", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-q01", "tutorial_id": "topics/contributing/tutorials/python", "query": "What tools can I use to implement pair programming in my course?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Teaching Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Improving student learning and out comes should always be a goal of teaching. Here we present several strategies to improve student experiences during courses by focusing on how they approach specific problems, and giving them real world applicable solutions to those problems.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-q02", "tutorial_id": "topics/contributing/tutorials/python", "query": "How can I use a debugger like pudb to follow the execution of a bit of code and show exactly how it's working?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Teaching Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Improving student learning and out comes should always be a goal of teaching. Here we present several strategies to improve student experiences during courses by focusing on how they approach specific problems, and giving them real world applicable solutions to those problems.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-q03", "tutorial_id": "topics/contributing/tutorials/python", "query": "What strategies can I use to help students develop a good mental model of code execution?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Teaching Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Improving student learning and out comes should always be a goal of teaching. Here we present several strategies to improve student experiences during courses by focusing on how they approach specific problems, and giving them real world applicable solutions to those problems.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-q04", "tutorial_id": "topics/contributing/tutorials/python", "query": "How can I design compounding problems to provide a gentle ramp up to increased complexity for my students?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Teaching Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Improving student learning and out comes should always be a goal of teaching. Here we present several strategies to improve student experiences during courses by focusing on how they approach specific problems, and giving them real world applicable solutions to those problems.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "rendering_gtn-q01", "tutorial_id": "topics/contributing/tutorials/rendering_gtn", "query": "I want to preview changes to training materials in an online environment without installing anything on my computer. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Preview the GTN website as you edit your training material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "If you are working on training materials, you will likely want to preview your changes as you go! You have a few options on how to do this.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "rendering_gtn-q02", "tutorial_id": "topics/contributing/tutorials/rendering_gtn", "query": "How can I edit a tutorial and see the effects on the GTN website instantly?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Preview the GTN website as you edit your training material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "If you are working on training materials, you will likely want to preview your changes as you go! You have a few options on how to do this.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "rendering_gtn-q03", "tutorial_id": "topics/contributing/tutorials/rendering_gtn", "query": "What tools would be needed to build and preview the GTN website locally?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Preview the GTN website as you edit your training material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "If you are working on training materials, you will likely want to preview your changes as you go! You have a few options on how to do this.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "rendering_gtn-q04", "tutorial_id": "topics/contributing/tutorials/rendering_gtn", "query": "How can I save my changes to a tutorial back to GitHub so that I can make a Pull Request to the GTN?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Preview the GTN website as you edit your training material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "If you are working on training materials, you will likely want to preview your changes as you go! You have a few options on how to do this.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "schemas-q01", "tutorial_id": "topics/contributing/tutorials/schemas", "query": "I want to assess the structure and quality of my training materials. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "GTN Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "## Training Materials", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "schemas-q02", "tutorial_id": "topics/contributing/tutorials/schemas", "query": "How can I create a new tutorial in the GTN, including metadata and contributors?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "GTN Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "## Training Materials", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "schemas-q03", "tutorial_id": "topics/contributing/tutorials/schemas", "query": "Which tools are required to work with the GTN schemas, such as Tutorial Schema or FAQ Schema?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "GTN Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "## Training Materials", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "schemas-q04", "tutorial_id": "topics/contributing/tutorials/schemas", "query": "What steps do I need to take to add a new contributor to a tutorial in the GTN?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "GTN Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "## Training Materials", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "slides-with-video-q01", "tutorial_id": "topics/contributing/tutorials/slides-with-video", "query": "I want to generate a video for my tutorial, but I'm not sure how to enable video generation. How do I do it?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Adding auto-generated video to your slides", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Video Lectures", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "slides-with-video-q02", "tutorial_id": "topics/contributing/tutorials/slides-with-video", "query": "I have a slide deck and I want to add auto-generated video to it. What tools do I need to use to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Adding auto-generated video to your slides", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Video Lectures", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "slides-with-video-q03", "tutorial_id": "topics/contributing/tutorials/slides-with-video", "query": "I want to write good captions for my video, but I'm not sure what are the best practices for writing captions. Can you provide some guidelines?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Adding auto-generated video to your slides", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Video Lectures", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "slides-with-video-q04", "tutorial_id": "topics/contributing/tutorials/slides-with-video", "query": "I want to choose a specific voice for my video, how can I do that?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Adding auto-generated video to your slides", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Video Lectures", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "updating_tutorial-q01", "tutorial_id": "topics/contributing/tutorials/updating_tutorial", "query": "I have a workflow with outdated tools and I want to update them. What tools should I use to assess which tools in my workflow are outdated?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Updating tool versions in a tutorial", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here, we provide a clear set of instructions for updating a GTN tutorial that uses the Galaxy interface for performing analysis. The GTN, and Galaxy, have a number of features to make it as reproducible and shareable as possible, so navigating what needs to be done for an overall update may feel daunting - but not anymore!", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "updating_tutorial-q02", "tutorial_id": "topics/contributing/tutorials/updating_tutorial", "query": "I updated the tools in my workflow and now I need to test it. Which tools can I use to test my workflow and ensure it is working correctly?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Updating tool versions in a tutorial", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here, we provide a clear set of instructions for updating a GTN tutorial that uses the Galaxy interface for performing analysis. The GTN, and Galaxy, have a number of features to make it as reproducible and shareable as possible, so navigating what needs to be done for an overall update may feel daunting - but not anymore!", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "updating_tutorial-q03", "tutorial_id": "topics/contributing/tutorials/updating_tutorial", "query": "How do I update the tool versions in a Galaxy workflow?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Updating tool versions in a tutorial", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here, we provide a clear set of instructions for updating a GTN tutorial that uses the Galaxy interface for performing analysis. The GTN, and Galaxy, have a number of features to make it as reproducible and shareable as possible, so navigating what needs to be done for an overall update may feel daunting - but not anymore!", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "updating_tutorial-q04", "tutorial_id": "topics/contributing/tutorials/updating_tutorial", "query": "How can I test a Galaxy workflow after updating the tool versions?", "tools": [], "workflows": [], "metadata": {"topic": "contributing", "tutorial_title": "Updating tool versions in a tutorial", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here, we provide a clear set of instructions for updating a GTN tutorial that uses the Galaxy interface for performing analysis. The GTN, and Galaxy, have a number of features to make it as reproducible and shareable as possible, so navigating what needs to be done for an overall update may feel daunting - but not anymore!", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bash-git-q01", "tutorial_id": "topics/data-science/tutorials/bash-git", "query": "I want to create a new Git repository for my project. What tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Version Control with Git", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Version control is a way of tracking the change history of a project, and `git` is one of the most popular systems for doing that! This tutorial will guide you through the basics of using git for version control.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bash-git-q02", "tutorial_id": "topics/data-science/tutorials/bash-git", "query": "How can I track changes to my files and collaborate with others on a project using Git?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Version Control with Git", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Version control is a way of tracking the change history of a project, and `git` is one of the most popular systems for doing that! This tutorial will guide you through the basics of using git for version control.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bash-git-q03", "tutorial_id": "topics/data-science/tutorials/bash-git", "query": "Which tool can I use to configure Git and set up my identity as a user?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Version Control with Git", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Version control is a way of tracking the change history of a project, and `git` is one of the most popular systems for doing that! This tutorial will guide you through the basics of using git for version control.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bash-git-q04", "tutorial_id": "topics/data-science/tutorials/bash-git", "query": "How can I explore the history of changes made to my project using Git?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Version Control with Git", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Version control is a way of tracking the change history of a project, and `git` is one of the most popular systems for doing that! This tutorial will guide you through the basics of using git for version control.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bash-variant-calling-q01", "tutorial_id": "topics/data-science/tutorials/bash-variant-calling", "query": "I have paired-end FASTQ reads from a ChIP-seq experiment and want to perform variant calling. What tools would I need to align the reads to a reference genome?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Variant Calling Workflow", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are working with files from a long-term evolution study of an *E. coli* population (designated Ara-3). We will perform variant calling to see how the population changed over time. We care how this population changed relative to the original population, *E. coli* strain REL606. Therefore, we will align each of our samples to the *E. coli* REL606 reference genome, and see what differences exist in our reads versus the genome.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bash-variant-calling-q02", "tutorial_id": "topics/data-science/tutorials/bash-variant-calling", "query": "My goal is to perform variant calling on a bacterial genome. How can I calculate the read coverage of positions in the genome?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Variant Calling Workflow", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are working with files from a long-term evolution study of an *E. coli* population (designated Ara-3). We will perform variant calling to see how the population changed over time. We care how this population changed relative to the original population, *E. coli* strain REL606. Therefore, we will align each of our samples to the *E. coli* REL606 reference genome, and see what differences exist in our reads versus the genome.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bash-variant-calling-q03", "tutorial_id": "topics/data-science/tutorials/bash-variant-calling", "query": "I want to identify single nucleotide variants (SNVs) in a bacterial genome. What tool can I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Variant Calling Workflow", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are working with files from a long-term evolution study of an *E. coli* population (designated Ara-3). We will perform variant calling to see how the population changed over time. We care how this population changed relative to the original population, *E. coli* strain REL606. Therefore, we will align each of our samples to the *E. coli* REL606 reference genome, and see what differences exist in our reads versus the genome.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bash-variant-calling-q04", "tutorial_id": "topics/data-science/tutorials/bash-variant-calling", "query": "I have a BAM file and a VCF file. How can I visualize the alignment and variant calls in a genome browser?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Variant Calling Workflow", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are working with files from a long-term evolution study of an *E. coli* population (designated Ara-3). We will perform variant calling to see how the population changed over time. We care how this population changed relative to the original population, *E. coli* strain REL606. Therefore, we will align each of our samples to the *E. coli* REL606 reference genome, and see what differences exist in our reads versus the genome.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "cli-advanced-q01", "tutorial_id": "topics/data-science/tutorials/cli-advanced", "query": "I have paired-end FASTQ reads from a ChIP-seq experiment (shell-lesson-data/data/animals.txt), want to assess library quality before alignment. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced CLI in Galaxy", "datasets": ["shell-lesson-data/data/animals.txt"], "dataset_paths": ["shell-lesson-data/data/animals.txt"], "dataset_count": 1, "context_summary": "This tutorial will walk you through the basics of how to use the Unix command line.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "cli-advanced-q02", "tutorial_id": "topics/data-science/tutorials/cli-advanced", "query": "Which Galaxy tool should I use to assess read quality for shell-lesson-data/data/animals.txt?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced CLI in Galaxy", "datasets": ["shell-lesson-data/data/animals.txt"], "dataset_paths": ["shell-lesson-data/data/animals.txt"], "dataset_count": 1, "context_summary": "This tutorial will walk you through the basics of how to use the Unix command line.", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "cli-advanced-q03", "tutorial_id": "topics/data-science/tutorials/cli-advanced", "query": "My single-cell FASTQ files (shell-lesson-data/data/animals.txt) show variable read quality; how can I clean them for downstream analysis?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced CLI in Galaxy", "datasets": ["shell-lesson-data/data/animals.txt"], "dataset_paths": ["shell-lesson-data/data/animals.txt"], "dataset_count": 1, "context_summary": "This tutorial will walk you through the basics of how to use the Unix command line.", "priority": 3, "version": "v0", "query_type": "science_first"}}
{"id": "cli-advanced-q04", "tutorial_id": "topics/data-science/tutorials/cli-advanced", "query": "How can I trim adapters and low-quality bases on shell-lesson-data/data/animals.txt in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced CLI in Galaxy", "datasets": ["shell-lesson-data/data/animals.txt"], "dataset_paths": ["shell-lesson-data/data/animals.txt"], "dataset_count": 1, "context_summary": "This tutorial will walk you through the basics of how to use the Unix command line.", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "cli-bashcrawl-q01", "tutorial_id": "topics/data-science/tutorials/cli-bashcrawl", "query": "I want to clone the Bashcrawl repository from GitLab. What tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "CLI Educational Game - Bashcrawl", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is not a tutorial like most GTN content but a fun exercise for you to play around and learn a bit about the command line, and hopefully re-inforce the skills you covered in Basic and Advanced CLI skills.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "cli-bashcrawl-q02", "tutorial_id": "topics/data-science/tutorials/cli-bashcrawl", "query": "How can I navigate to the 'entrance' directory in Bashcrawl?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "CLI Educational Game - Bashcrawl", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is not a tutorial like most GTN content but a fun exercise for you to play around and learn a bit about the command line, and hopefully re-inforce the skills you covered in Basic and Advanced CLI skills.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "cli-bashcrawl-q03", "tutorial_id": "topics/data-science/tutorials/cli-bashcrawl", "query": "Which tool can I use to view the contents of a file named 'scroll'?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "CLI Educational Game - Bashcrawl", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is not a tutorial like most GTN content but a fun exercise for you to play around and learn a bit about the command line, and hopefully re-inforce the skills you covered in Basic and Advanced CLI skills.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "cli-bashcrawl-q04", "tutorial_id": "topics/data-science/tutorials/cli-bashcrawl", "query": "How do I run the command to view the contents of 'scroll' in the Bashcrawl repository?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "CLI Educational Game - Bashcrawl", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is not a tutorial like most GTN content but a fun exercise for you to play around and learn a bit about the command line, and hopefully re-inforce the skills you covered in Basic and Advanced CLI skills.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "cli-basics-q01", "tutorial_id": "topics/data-science/tutorials/cli-basics", "query": "I want to list the contents of my current directory. What tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "CLI basics", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will walk you through the basics of how to use the Unix command line.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "cli-basics-q02", "tutorial_id": "topics/data-science/tutorials/cli-basics", "query": "I want to create a new directory called 'results'. What tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "CLI basics", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will walk you through the basics of how to use the Unix command line.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "cli-basics-q03", "tutorial_id": "topics/data-science/tutorials/cli-basics", "query": "How can I navigate to a specific directory?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "CLI basics", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will walk you through the basics of how to use the Unix command line.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "cli-basics-q04", "tutorial_id": "topics/data-science/tutorials/cli-basics", "query": "How can I delete an empty directory?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "CLI basics", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will walk you through the basics of how to use the Unix command line.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-jq-q01", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-jq", "query": "I have a JSON file with Olympics data and I want to filter it to only include athletes who competed in the Winter Olympics. What tool can I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data Manipulation Olympics - JQ", "datasets": ["olympics.json"], "dataset_paths": ["olympics.json"], "dataset_count": 1, "context_summary": "Scientific analyses often consist of a number of tools that run one after the other, in order to go from the raw data to scientific insight. Between these specialized tools, simple data manipulation steps are often needed as a kind of \"glue\" between tools. For example, the output of tool A may produce a file that contains all the information needed as input for tool B, but tool B expects the columns in a different order. Or in genomic data analysis, some tools expect chromosome X to be listed as `chrX`, while others simply expect `X`. In these situations, extra data manipulation steps are needed to prepare files for input to analysis tools.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-jq-q02", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-jq", "query": "I need to sort my Olympics data by athlete name and then by year. Which tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data Manipulation Olympics - JQ", "datasets": ["olympics.json"], "dataset_paths": ["olympics.json"], "dataset_count": 1, "context_summary": "Scientific analyses often consist of a number of tools that run one after the other, in order to go from the raw data to scientific insight. Between these specialized tools, simple data manipulation steps are often needed as a kind of \"glue\" between tools. For example, the output of tool A may produce a file that contains all the information needed as input for tool B, but tool B expects the columns in a different order. Or in genomic data analysis, some tools expect chromosome X to be listed as `chrX`, while others simply expect `X`. In these situations, extra data manipulation steps are needed to prepare files for input to analysis tools.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-jq-q03", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-jq", "query": "How can I use Galaxy to filter my Olympics data to only include athletes who won a medal?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data Manipulation Olympics - JQ", "datasets": ["olympics.json"], "dataset_paths": ["olympics.json"], "dataset_count": 1, "context_summary": "Scientific analyses often consist of a number of tools that run one after the other, in order to go from the raw data to scientific insight. Between these specialized tools, simple data manipulation steps are often needed as a kind of \"glue\" between tools. For example, the output of tool A may produce a file that contains all the information needed as input for tool B, but tool B expects the columns in a different order. Or in genomic data analysis, some tools expect chromosome X to be listed as `chrX`, while others simply expect `X`. In these situations, extra data manipulation steps are needed to prepare files for input to analysis tools.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-jq-q04", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-jq", "query": "I want to group my Olympics data by Olympic Games and calculate the number of athletes who participated in each Games. What tool can I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data Manipulation Olympics - JQ", "datasets": ["olympics.json"], "dataset_paths": ["olympics.json"], "dataset_count": 1, "context_summary": "Scientific analyses often consist of a number of tools that run one after the other, in order to go from the raw data to scientific insight. Between these specialized tools, simple data manipulation steps are often needed as a kind of \"glue\" between tools. For example, the output of tool A may produce a file that contains all the information needed as input for tool B, but tool B expects the columns in a different order. Or in genomic data analysis, some tools expect chromosome X to be listed as `chrX`, while others simply expect `X`. In these situations, extra data manipulation steps are needed to prepare files for input to analysis tools.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-sql-q01", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-sql", "query": "I have a table with Olympics results and I want to filter out rows with missing values in the height column. What tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data Manipulation Olympics - SQL", "datasets": ["olympics"], "dataset_paths": ["olympics"], "dataset_count": 1, "context_summary": "Scientific analyses often consist of a number of tools that run one after the other, in order to go from the raw data to scientific insight. Between these specialized tools, simple data manipulation steps are often needed as a kind of \"glue\" between tools. For example, the output of tool A may produce a file that contains all the information needed as input for tool B, but tool B expects the columns in a different order. Or in genomic data analysis, some tools expect chromosome X to be listed as `chrX`, while others simply expect `X`. In these situations, extra data manipulation steps are needed to prepare files for input to analysis tools.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-sql-q02", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-sql", "query": "I need to sort a table with Olympics results by the year of the Olympic games and then by athlete name. Which tool can I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data Manipulation Olympics - SQL", "datasets": ["olympics"], "dataset_paths": ["olympics"], "dataset_count": 1, "context_summary": "Scientific analyses often consist of a number of tools that run one after the other, in order to go from the raw data to scientific insight. Between these specialized tools, simple data manipulation steps are often needed as a kind of \"glue\" between tools. For example, the output of tool A may produce a file that contains all the information needed as input for tool B, but tool B expects the columns in a different order. Or in genomic data analysis, some tools expect chromosome X to be listed as `chrX`, while others simply expect `X`. In these situations, extra data manipulation steps are needed to prepare files for input to analysis tools.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-sql-q03", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-sql", "query": "How can I group a table with Olympics results by the country and calculate the average height of athletes for each country?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data Manipulation Olympics - SQL", "datasets": ["olympics"], "dataset_paths": ["olympics"], "dataset_count": 1, "context_summary": "Scientific analyses often consist of a number of tools that run one after the other, in order to go from the raw data to scientific insight. Between these specialized tools, simple data manipulation steps are often needed as a kind of \"glue\" between tools. For example, the output of tool A may produce a file that contains all the information needed as input for tool B, but tool B expects the columns in a different order. Or in genomic data analysis, some tools expect chromosome X to be listed as `chrX`, while others simply expect `X`. In these situations, extra data manipulation steps are needed to prepare files for input to analysis tools.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-sql-q04", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-sql", "query": "I want to join two tables, one with Olympics results and one with country information, on the country code. What tool can I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data Manipulation Olympics - SQL", "datasets": ["olympics", "countries"], "dataset_paths": ["olympics", "countries"], "dataset_count": 2, "context_summary": "Scientific analyses often consist of a number of tools that run one after the other, in order to go from the raw data to scientific insight. Between these specialized tools, simple data manipulation steps are often needed as a kind of \"glue\" between tools. For example, the output of tool A may produce a file that contains all the information needed as input for tool B, but tool B expects the columns in a different order. Or in genomic data analysis, some tools expect chromosome X to be listed as `chrX`, while others simply expect `X`. In these situations, extra data manipulation steps are needed to prepare files for input to analysis tools.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-viz-r-q01", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-viz-r", "query": "I want to create a scatter plot of height vs sport with different colors for each season, but I'm not sure which ggplot2 functions to use.", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data visualisation Olympics - Visualization in R", "datasets": ["olympics"], "dataset_paths": ["olympics"], "dataset_count": 1, "context_summary": "In this tutorial, you will learn how to produce scatter plots, boxplots, and time series plots using ggplot. You will also learn how to set universal plot settings, modify the aesthetics of an existing ggplot plots (including axis labels and color), and learn how to facet in ggplot.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-viz-r-q02", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-viz-r", "query": "How do I add a trend line to a time series plot created with ggplot2?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data visualisation Olympics - Visualization in R", "datasets": ["olympics"], "dataset_paths": ["olympics"], "dataset_count": 1, "context_summary": "In this tutorial, you will learn how to produce scatter plots, boxplots, and time series plots using ggplot. You will also learn how to set universal plot settings, modify the aesthetics of an existing ggplot plots (including axis labels and color), and learn how to facet in ggplot.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-viz-r-q03", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-viz-r", "query": "What tools are needed to perform data cleaning and calculations on the olympics dataset?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data visualisation Olympics - Visualization in R", "datasets": ["olympics"], "dataset_paths": ["olympics"], "dataset_count": 1, "context_summary": "In this tutorial, you will learn how to produce scatter plots, boxplots, and time series plots using ggplot. You will also learn how to set universal plot settings, modify the aesthetics of an existing ggplot plots (including axis labels and color), and learn how to facet in ggplot.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "data-manipulation-olympics-viz-r-q04", "tutorial_id": "topics/data-science/tutorials/data-manipulation-olympics-viz-r", "query": "How can I customize the appearance of a ggplot2 plot, such as changing the font size and axis labels?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data visualisation Olympics - Visualization in R", "datasets": ["olympics"], "dataset_paths": ["olympics"], "dataset_count": 1, "context_summary": "In this tutorial, you will learn how to produce scatter plots, boxplots, and time series plots using ggplot. You will also learn how to set universal plot settings, modify the aesthetics of an existing ggplot plots (including axis labels and color), and learn how to facet in ggplot.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "git-cli-q01", "tutorial_id": "topics/data-science/tutorials/git-cli", "query": "What tool should I use to create a new branch in Git?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Basics of using Git from the Command Line", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Version control is a way of tracking the change history of a project. Even if you have never used a version control tool, you've probably already done it manually: copying and renaming project folders (\"paper-1.doc\", \"paper-2.doc\", etc.) is a form of version control. Within bioinformatics (from research, to development, to sysadmin) a lot of us are using `git` as our primary method of source control for everything we do: notes, slides, tutorials, code, notebooks, ansible, system configuration, and more.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "git-cli-q02", "tutorial_id": "topics/data-science/tutorials/git-cli", "query": "How can I revert a commit in Git?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Basics of using Git from the Command Line", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Version control is a way of tracking the change history of a project. Even if you have never used a version control tool, you've probably already done it manually: copying and renaming project folders (\"paper-1.doc\", \"paper-2.doc\", etc.) is a form of version control. Within bioinformatics (from research, to development, to sysadmin) a lot of us are using `git` as our primary method of source control for everything we do: notes, slides, tutorials, code, notebooks, ansible, system configuration, and more.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "git-cli-q03", "tutorial_id": "topics/data-science/tutorials/git-cli", "query": "What command can I use to check the status of a Git repository?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Basics of using Git from the Command Line", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Version control is a way of tracking the change history of a project. Even if you have never used a version control tool, you've probably already done it manually: copying and renaming project folders (\"paper-1.doc\", \"paper-2.doc\", etc.) is a form of version control. Within bioinformatics (from research, to development, to sysadmin) a lot of us are using `git` as our primary method of source control for everything we do: notes, slides, tutorials, code, notebooks, ansible, system configuration, and more.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "git-cli-q04", "tutorial_id": "topics/data-science/tutorials/git-cli", "query": "How can I merge two branches in Git?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Basics of using Git from the Command Line", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Version control is a way of tracking the change history of a project. Even if you have never used a version control tool, you've probably already done it manually: copying and renaming project folders (\"paper-1.doc\", \"paper-2.doc\", etc.) is a form of version control. Within bioinformatics (from research, to development, to sysadmin) a lot of us are using `git` as our primary method of source control for everything we do: notes, slides, tutorials, code, notebooks, ansible, system configuration, and more.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture1-q01", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture1", "query": "I want to understand the historical context of the discovery of the structure of DNA. What tools or resources would I need to explore the classical publications mentioned in this tutorial?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "A (very) brief history of genomics", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "![Fluctuation test](./images/luria_small.png)", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture1-q02", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture1", "query": "How can I access and read the manuscripts from classical publications such as Avery, MacLeod, & McCarty (1944) and Watson & Crick (1953) in a format that is easily readable and understandable?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "A (very) brief history of genomics", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "![Fluctuation test](./images/luria_small.png)", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture1-q03", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture1", "query": "What tools or software would be useful for analyzing and visualizing the data from the fluctuation test, similar to the one performed by Luria and Delbrück?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "A (very) brief history of genomics", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "![Fluctuation test](./images/luria_small.png)", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture1-q04", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture1", "query": "How can I explore the popular literature on the history of genetics, such as books like 'A History of Genetics' by Sturtevant, in a way that allows me to take notes and annotate the text?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "A (very) brief history of genomics", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "![Fluctuation test](./images/luria_small.png)", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture2-q01", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture2", "query": "I have a collection of DNA sequences and I want to simulate Sanger sequencing with ddNTPs. What tools would I need to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part one)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "![Imgur image](https://i.imgur.com/1PCleoW.png)", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture2-q02", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture2", "query": "How can I generate a simulated gel image from my Sanger sequencing data using Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part one)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "![Imgur image](https://i.imgur.com/1PCleoW.png)", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture2-q03", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture2", "query": "What tools would I need to use to convert my Sanger sequencing data into a Pandas dataframe?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part one)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "![Imgur image](https://i.imgur.com/1PCleoW.png)", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture2-q04", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture2", "query": "How can I plot my Sanger sequencing data using a quadratic scale for realism?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part one)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "![Imgur image](https://i.imgur.com/1PCleoW.png)", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture3-q01", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture3", "query": "I have paired-end FASTQ reads from a ChIP-seq experiment and want to assess library quality before alignment. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part two)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD353](https://imgs.xkcd.com/comics/python.png)](https://xkcd.com/353/)", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture3-q02", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture3", "query": "Which tool can I use to assess read quality for FASTQ files?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part two)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD353](https://imgs.xkcd.com/comics/python.png)](https://xkcd.com/353/)", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture3-q03", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture3", "query": "My single-cell FASTQ files show variable read quality; how can I clean them for downstream analysis?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part two)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD353](https://imgs.xkcd.com/comics/python.png)](https://xkcd.com/353/)", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture3-q04", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture3", "query": "How can I trim adapters and low-quality bases on FASTQ files?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part two)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD353](https://imgs.xkcd.com/comics/python.png)](https://xkcd.com/353/)", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture4-q01", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture4", "query": "I have a DNA sequence and want to perform dynamic programming to find the edit distance between it and another sequence. What tools would I need to use in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part three)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD 2483](https://imgs.xkcd.com/comics/seven.png)](https://xkcd.com/2483)", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture4-q02", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture4", "query": "I want to translate a DNA sequence into a protein sequence in Galaxy. How can I do this using tools available in the Galaxy environment?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part three)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD 2483](https://imgs.xkcd.com/comics/seven.png)](https://xkcd.com/2483)", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture4-q03", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture4", "query": "What tool can I use to create a matrix for dynamic programming in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part three)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD 2483](https://imgs.xkcd.com/comics/seven.png)](https://xkcd.com/2483)", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture4-q04", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture4", "query": "How can I use Galaxy to translate a DNA sequence into all six reading frames and visualize the results?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part three)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD 2483](https://imgs.xkcd.com/comics/seven.png)](https://xkcd.com/2483)", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture5-q01", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture5", "query": "I have a FASTQ file and want to assess its quality. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part four)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Reading and writing files in Python", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "gnmx-lecture5-q02", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture5", "query": "Which tool can I use to read and write FASTA files in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part four)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Reading and writing files in Python", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "gnmx-lecture5-q03", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture5", "query": "How can I parse a SAM file to extract specific fields such as reference name and start position?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part four)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Reading and writing files in Python", "priority": 3, "version": "v0", "query_type": "science_first"}}
{"id": "gnmx-lecture5-q04", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture5", "query": "What tool can I use to trim adapters and low-quality bases from my FASTQ file?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to sequencing with Python (part four)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Reading and writing files in Python", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "gnmx-lecture6-q01", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture6", "query": "I have a table with information about SARS-CoV-2 datasets, want to filter the data to only include rows where the size of the run is above 100 MB. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data manipulation with Pandas", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "#  SARS-CoV-2 as a research problem", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture6-q02", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture6", "query": "My table with SARS-CoV-2 datasets has a column with library layout, how can I count the number of unique sequencing platforms for each library layout?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data manipulation with Pandas", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "#  SARS-CoV-2 as a research problem", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture6-q03", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture6", "query": "Which tool can I use to read in a CSV file and store its contents in a data frame?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data manipulation with Pandas", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "#  SARS-CoV-2 as a research problem", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture6-q04", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture6", "query": "How can I add a new column to a data frame that calculates the sum of two existing columns?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Data manipulation with Pandas", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "#  SARS-CoV-2 as a research problem", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture7-q01", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture7", "query": "I want to clone a Git repository from GitHub. What tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Versioning your code and data with git", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD1597](https://imgs.xkcd.com/comics/git.png)](https://xkcd.com/1597/)", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture7-q02", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture7", "query": "How do I create a new branch in Git and switch to it?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Versioning your code and data with git", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD1597](https://imgs.xkcd.com/comics/git.png)](https://xkcd.com/1597/)", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture7-q03", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture7", "query": "What tool can I use to stage and commit changes in a Git repository?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Versioning your code and data with git", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD1597](https://imgs.xkcd.com/comics/git.png)](https://xkcd.com/1597/)", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "gnmx-lecture7-q04", "tutorial_id": "topics/data-science/tutorials/gnmx-lecture7", "query": "How can I merge two branches in Git and resolve conflicts?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Versioning your code and data with git", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[![XKCD1597](https://imgs.xkcd.com/comics/git.png)](https://xkcd.com/1597/)", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "online-resources-gene-q01", "tutorial_id": "topics/data-science/tutorials/online-resources-gene", "query": "I have a list of gene names from an RNA-seq analysis and I want to explore them. What tools should I use to get more information about these genes?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Learning about one gene across biological resources and formats", "datasets": ["https://zenodo.org/record/8304465"], "dataset_paths": ["https://zenodo.org/record/8304465"], "dataset_count": 1, "context_summary": "When we do a bioinformatics analysis, e.g. RNA-seq, we might end up with a list of gene names. We then need to explore these genes. But how can we do that? What are the resources available for that? And how to navigate through them?", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "online-resources-gene-q02", "tutorial_id": "topics/data-science/tutorials/online-resources-gene", "query": "I have a gene name and I want to find its protein sequence. How can I achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Learning about one gene across biological resources and formats", "datasets": ["https://zenodo.org/record/8304465"], "dataset_paths": ["https://zenodo.org/record/8304465"], "dataset_count": 1, "context_summary": "When we do a bioinformatics analysis, e.g. RNA-seq, we might end up with a list of gene names. We then need to explore these genes. But how can we do that? What are the resources available for that? And how to navigate through them?", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "online-resources-gene-q03", "tutorial_id": "topics/data-science/tutorials/online-resources-gene", "query": "Which tool can I use to perform a BLAST search for a protein sequence?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Learning about one gene across biological resources and formats", "datasets": ["https://zenodo.org/record/8304465"], "dataset_paths": ["https://zenodo.org/record/8304465"], "dataset_count": 1, "context_summary": "When we do a bioinformatics analysis, e.g. RNA-seq, we might end up with a list of gene names. We then need to explore these genes. But how can we do that? What are the resources available for that? And how to navigate through them?", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "online-resources-gene-q04", "tutorial_id": "topics/data-science/tutorials/online-resources-gene", "query": "I want to download the protein sequence of a gene in different formats. How can I do this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Learning about one gene across biological resources and formats", "datasets": ["https://zenodo.org/record/8304465"], "dataset_paths": ["https://zenodo.org/record/8304465"], "dataset_count": 1, "context_summary": "When we do a bioinformatics analysis, e.g. RNA-seq, we might end up with a list of gene names. We then need to explore these genes. But how can we do that? What are the resources available for that? And how to navigate through them?", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "online-resources-protein-q01", "tutorial_id": "topics/data-science/tutorials/online-resources-protein", "query": "I have a protein sequence and want to assess its structure. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "One protein along the UniProt page", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "When doing a biological data analysis, we might end up with some interesting proteins, that we need explore these genes. But how can we do that? What are the resources available for that? And how to navigate through them?", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "online-resources-protein-q02", "tutorial_id": "topics/data-science/tutorials/online-resources-protein", "query": "I have a list of protein variants and want to assess their pathogenicity. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "One protein along the UniProt page", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "When doing a biological data analysis, we might end up with some interesting proteins, that we need explore these genes. But how can we do that? What are the resources available for that? And how to navigate through them?", "priority": 2, "version": "v0", "query_type": "science_first"}}
{"id": "online-resources-protein-q03", "tutorial_id": "topics/data-science/tutorials/online-resources-protein", "query": "Which tool can I use to predict the 3D structure of a protein from its sequence?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "One protein along the UniProt page", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "When doing a biological data analysis, we might end up with some interesting proteins, that we need explore these genes. But how can we do that? What are the resources available for that? And how to navigate through them?", "priority": 3, "version": "v0", "query_type": "tool_first"}}
{"id": "online-resources-protein-q04", "tutorial_id": "topics/data-science/tutorials/online-resources-protein", "query": "How can I find similar proteins to a given protein sequence?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "One protein along the UniProt page", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "When doing a biological data analysis, we might end up with some interesting proteins, that we need explore these genes. But how can we do that? What are the resources available for that? And how to navigate through them?", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "python-advanced-np-pd-q01", "tutorial_id": "topics/data-science/tutorials/python-advanced-np-pd", "query": "I have a large dataset of gene expression levels and I want to perform statistical analysis on it. What tools should I use to analyze the data?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced Python", "datasets": ["3477564"], "dataset_paths": ["3477564"], "dataset_count": 1, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. This tutorial assumes that the reader is familiar with the fundamentals of the Python programming language, as well as, how to run Python programs using Galaxy. Otherwise, it is advised to follow the \"Introduction to Python\" tutorial available in the same platform. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson. Please note:  JupyterNotebook is only currently available on the [usegalaxy.eu](https://usegalaxy.eu/) and [usegalaxy.org](https://usegalaxy.org/) sites.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-advanced-np-pd-q02", "tutorial_id": "topics/data-science/tutorials/python-advanced-np-pd", "query": "How can I use Python to perform data manipulation and analysis on my dataset?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced Python", "datasets": ["3477564"], "dataset_paths": ["3477564"], "dataset_count": 1, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. This tutorial assumes that the reader is familiar with the fundamentals of the Python programming language, as well as, how to run Python programs using Galaxy. Otherwise, it is advised to follow the \"Introduction to Python\" tutorial available in the same platform. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson. Please note:  JupyterNotebook is only currently available on the [usegalaxy.eu](https://usegalaxy.eu/) and [usegalaxy.org](https://usegalaxy.org/) sites.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-advanced-np-pd-q03", "tutorial_id": "topics/data-science/tutorials/python-advanced-np-pd", "query": "I want to find the maximum inflammation per patient over all days. Which tool or function should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced Python", "datasets": ["3477564"], "dataset_paths": ["3477564"], "dataset_count": 1, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. This tutorial assumes that the reader is familiar with the fundamentals of the Python programming language, as well as, how to run Python programs using Galaxy. Otherwise, it is advised to follow the \"Introduction to Python\" tutorial available in the same platform. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson. Please note:  JupyterNotebook is only currently available on the [usegalaxy.eu](https://usegalaxy.eu/) and [usegalaxy.org](https://usegalaxy.org/) sites.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-advanced-np-pd-q04", "tutorial_id": "topics/data-science/tutorials/python-advanced-np-pd", "query": "How can I group my data by chromosome and calculate the average gene length for each chromosome?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced Python", "datasets": ["3477564"], "dataset_paths": ["3477564"], "dataset_count": 1, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. This tutorial assumes that the reader is familiar with the fundamentals of the Python programming language, as well as, how to run Python programs using Galaxy. Otherwise, it is advised to follow the \"Introduction to Python\" tutorial available in the same platform. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson. Please note:  JupyterNotebook is only currently available on the [usegalaxy.eu](https://usegalaxy.eu/) and [usegalaxy.org](https://usegalaxy.org/) sites.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-argparse-q01", "tutorial_id": "topics/data-science/tutorials/python-argparse", "query": "I want to create a command line tool that takes a list of numbers as input and returns their sum. What tools or libraries can I use to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Argparse", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[`argparse`](https://docs.python.org/3/library/argparse.html) is an argument parsing library for Python that's part of the stdlib. It lets you make command line tools significantly nicer to work with.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-argparse-q02", "tutorial_id": "topics/data-science/tutorials/python-argparse", "query": "How can I generate a Galaxy tool wrapper from a Python script that uses argparse to parse command line arguments?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Argparse", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[`argparse`](https://docs.python.org/3/library/argparse.html) is an argument parsing library for Python that's part of the stdlib. It lets you make command line tools significantly nicer to work with.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-argparse-q03", "tutorial_id": "topics/data-science/tutorials/python-argparse", "query": "What tool can I use to parse command line arguments in a Python script?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Argparse", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[`argparse`](https://docs.python.org/3/library/argparse.html) is an argument parsing library for Python that's part of the stdlib. It lets you make command line tools significantly nicer to work with.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-argparse-q04", "tutorial_id": "topics/data-science/tutorials/python-argparse", "query": "How can I create a Python script that uses argparse to parse command line arguments and generates a Galaxy tool wrapper?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Argparse", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[`argparse`](https://docs.python.org/3/library/argparse.html) is an argument parsing library for Python that's part of the stdlib. It lets you make command line tools significantly nicer to work with.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-basics-q01", "tutorial_id": "topics/data-science/tutorials/python-basics", "query": "I want to write a program that converts temperature from Fahrenheit to Celsius. What programming tools do I need?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-basics-q02", "tutorial_id": "topics/data-science/tutorials/python-basics", "query": "How can I write a loop that calculates the sum of elements in a list by adding each element in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-basics-q03", "tutorial_id": "topics/data-science/tutorials/python-basics", "query": "I have a list of numbers and I want to find the maximum value. What programming tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-basics-q04", "tutorial_id": "topics/data-science/tutorials/python-basics", "query": "How can I use a for loop to repeat an operation for each thing in a sequence in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-basics-recap-q01", "tutorial_id": "topics/data-science/tutorials/python-basics-recap", "query": "I want to calculate the sum of an alternating series where each element of the series is an expression of the form 4⋅∑[k=1 to N] ((-1)^(k+1))/(2 * k-1). How can I achieve this in Galaxy using Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Introductory Graduation", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This module provide something like a recap of everything covered by the modular Python Introductory level curriculum. This serves as something of a graduation into the Intermediate tutorials which cover more advanced topics.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "python-basics-recap-q02", "tutorial_id": "topics/data-science/tutorials/python-basics-recap", "query": "Which Galaxy tool should I use to generate random points for a Monte Carlo simulation to estimate the value of π?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Introductory Graduation", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This module provide something like a recap of everything covered by the modular Python Introductory level curriculum. This serves as something of a graduation into the Intermediate tutorials which cover more advanced topics.", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "python-basics-recap-q03", "tutorial_id": "topics/data-science/tutorials/python-basics-recap", "query": "I have a DNA sequence and I want to find all possible ORFs in it. How can I do this in Galaxy using Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Introductory Graduation", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This module provide something like a recap of everything covered by the modular Python Introductory level curriculum. This serves as something of a graduation into the Intermediate tutorials which cover more advanced topics.", "priority": 3, "version": "v0", "query_type": "science_first"}}
{"id": "python-basics-recap-q04", "tutorial_id": "topics/data-science/tutorials/python-basics-recap", "query": "How can I trim adapters and low-quality bases from my paired-end FASTQ reads in Galaxy using Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Introductory Graduation", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This module provide something like a recap of everything covered by the modular Python Introductory level curriculum. This serves as something of a graduation into the Intermediate tutorials which cover more advanced topics.", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "python-conda-q01", "tutorial_id": "topics/data-science/tutorials/python-conda", "query": "I need to install a new package in my conda environment, but I'm not sure how to do it. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Conda Environments For Software Development", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Conda environments, like Python Virtual Environments allow you to easily manage your installed packages and prevent conflicts between different project's dependencies. This tutorial follows an identical structure to the virtualenv tutorial, but with conda.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-conda-q02", "tutorial_id": "topics/data-science/tutorials/python-conda", "query": "How do I create a new conda environment for my project and install the required packages?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Conda Environments For Software Development", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Conda environments, like Python Virtual Environments allow you to easily manage your installed packages and prevent conflicts between different project's dependencies. This tutorial follows an identical structure to the virtualenv tutorial, but with conda.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-conda-q03", "tutorial_id": "topics/data-science/tutorials/python-conda", "query": "What command should I use to export my conda environment so that I can share it with my collaborators?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Conda Environments For Software Development", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Conda environments, like Python Virtual Environments allow you to easily manage your installed packages and prevent conflicts between different project's dependencies. This tutorial follows an identical structure to the virtualenv tutorial, but with conda.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-conda-q04", "tutorial_id": "topics/data-science/tutorials/python-conda", "query": "I want to update a package in my conda environment, but I'm not sure how to do it without affecting other packages. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Conda Environments For Software Development", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Conda environments, like Python Virtual Environments allow you to easily manage your installed packages and prevent conflicts between different project's dependencies. This tutorial follows an identical structure to the virtualenv tutorial, but with conda.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-exceptions-q01", "tutorial_id": "topics/data-science/tutorials/python-exceptions", "query": "I want to calculate the mean of a list of numbers and handle potential errors, what programming approach should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Try & Except", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Try/except are a construct in Python used to catch a potential exception. Sometimes things go wrong in your code! Or in someone else's code in a module. Sometimes some errors might be expected like when you try and read a user supplied file, maybe it isn't available because they've specified the wrong path.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-exceptions-q02", "tutorial_id": "topics/data-science/tutorials/python-exceptions", "query": "How can I handle exceptions when working with user-supplied files in my Python code?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Try & Except", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Try/except are a construct in Python used to catch a potential exception. Sometimes things go wrong in your code! Or in someone else's code in a module. Sometimes some errors might be expected like when you try and read a user supplied file, maybe it isn't available because they've specified the wrong path.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-exceptions-q03", "tutorial_id": "topics/data-science/tutorials/python-exceptions", "query": "What is the best way to clean up temporary files after an error occurs in my Python script?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Try & Except", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Try/except are a construct in Python used to catch a potential exception. Sometimes things go wrong in your code! Or in someone else's code in a module. Sometimes some errors might be expected like when you try and read a user supplied file, maybe it isn't available because they've specified the wrong path.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-exceptions-q04", "tutorial_id": "topics/data-science/tutorials/python-exceptions", "query": "How can I provide friendlier error messages when exceptions occur in my Python code?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Try & Except", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Try/except are a construct in Python used to catch a potential exception. Sometimes things go wrong in your code! Or in someone else's code in a module. Sometimes some errors might be expected like when you try and read a user supplied file, maybe it isn't available because they've specified the wrong path.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-files-q01", "tutorial_id": "topics/data-science/tutorials/python-files", "query": "I have a CSV file with vaccination data and want to subset it for a specific country. What tool should I use to do this in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Files & CSV", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we'll give a quick tutorial on how to read and write files within Python.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-files-q02", "tutorial_id": "topics/data-science/tutorials/python-files", "query": "How can I convert a FASTQ file to a FASTA file in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Files & CSV", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we'll give a quick tutorial on how to read and write files within Python.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-files-q03", "tutorial_id": "topics/data-science/tutorials/python-files", "query": "Which Galaxy tool can I use to plot the fraction of the population that has been vaccinated over time?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Files & CSV", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we'll give a quick tutorial on how to read and write files within Python.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-files-q04", "tutorial_id": "topics/data-science/tutorials/python-files", "query": "How can I write out a list of percentages to a comma-separated file in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Files & CSV", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we'll give a quick tutorial on how to read and write files within Python.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-flow-q01", "tutorial_id": "topics/data-science/tutorials/python-flow", "query": "I want to write a Python script to compare two numbers and print out which one is larger. What tools would I need to use in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Flow Control", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "\"Flow Control\" is how we describe when we change the flow of code's execution, based on some conditions. Here we'll learn how to take different actions depending on what data out program sees, or how to run code only if some condition is true.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-flow-q02", "tutorial_id": "topics/data-science/tutorials/python-flow", "query": "How can I use Galaxy to write a Python script that uses conditional statements to categorize a list of numbers into different ranges?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Flow Control", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "\"Flow Control\" is how we describe when we change the flow of code's execution, based on some conditions. Here we'll learn how to take different actions depending on what data out program sees, or how to run code only if some condition is true.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-flow-q03", "tutorial_id": "topics/data-science/tutorials/python-flow", "query": "I have a list of numbers and I want to write a Python script to find the numbers that are within a certain range. What Galaxy tool can I use to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Flow Control", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "\"Flow Control\" is how we describe when we change the flow of code's execution, based on some conditions. Here we'll learn how to take different actions depending on what data out program sees, or how to run code only if some condition is true.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-flow-q04", "tutorial_id": "topics/data-science/tutorials/python-flow", "query": "Can I use Galaxy to write a Python script that uses if-elif-else statements to print out different messages based on the value of a variable?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Flow Control", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "\"Flow Control\" is how we describe when we change the flow of code's execution, based on some conditions. Here we'll learn how to take different actions depending on what data out program sees, or how to run code only if some condition is true.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-functions-q01", "tutorial_id": "topics/data-science/tutorials/python-functions", "query": "I want to convert a temperature from Fahrenheit to Celsius and then to Kelvin. What tools or libraries should I use in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Functions", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Functions are the basic unit of all work in Python! Absolutely everything you do uses functions. Conceptually, functions are super simple. Just like in maths, they take an input, do some transformation, and return an output. As an example, `f(x) = x + 2` is a function that calculates whatever value you request, plus two. But functions are foundational, so, you should understand them well before moving on.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-functions-q02", "tutorial_id": "topics/data-science/tutorials/python-functions", "query": "How can I write a Python function in Galaxy to calculate the average of two numbers?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Functions", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Functions are the basic unit of all work in Python! Absolutely everything you do uses functions. Conceptually, functions are super simple. Just like in maths, they take an input, do some transformation, and return an output. As an example, `f(x) = x + 2` is a function that calculates whatever value you request, plus two. But functions are foundational, so, you should understand them well before moving on.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-functions-q03", "tutorial_id": "topics/data-science/tutorials/python-functions", "query": "I need to trim adapters and low-quality bases from my FASTQ files. Which tools should I use in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Functions", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Functions are the basic unit of all work in Python! Absolutely everything you do uses functions. Conceptually, functions are super simple. Just like in maths, they take an input, do some transformation, and return an output. As an example, `f(x) = x + 2` is a function that calculates whatever value you request, plus two. But functions are foundational, so, you should understand them well before moving on.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-functions-q04", "tutorial_id": "topics/data-science/tutorials/python-functions", "query": "How can I document my Python functions in Galaxy to make them reusable and understandable?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Functions", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Functions are the basic unit of all work in Python! Absolutely everything you do uses functions. Conceptually, functions are super simple. Just like in maths, they take an input, do some transformation, and return an output. As an example, `f(x) = x + 2` is a function that calculates whatever value you request, plus two. But functions are foundational, so, you should understand them well before moving on.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-glob-q01", "tutorial_id": "topics/data-science/tutorials/python-glob", "query": "I want to find all CSV files in a directory and its subdirectories. How can I achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Globbing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Globbing is the term used in computer science when we have a bunch of files and we want to list all of them matching some pattern.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-glob-q02", "tutorial_id": "topics/data-science/tutorials/python-glob", "query": "What approach can I use to sort files in a directory before processing them to ensure consistent results?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Globbing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Globbing is the term used in computer science when we have a bunch of files and we want to list all of them matching some pattern.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-glob-q03", "tutorial_id": "topics/data-science/tutorials/python-glob", "query": "I need to identify all text files in a directory. Which method can I use to find them?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Globbing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Globbing is the term used in computer science when we have a bunch of files and we want to list all of them matching some pattern.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-glob-q04", "tutorial_id": "topics/data-science/tutorials/python-glob", "query": "How can I find all files starting with a specific letter in a directory and its subdirectories?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Globbing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Globbing is the term used in computer science when we have a bunch of files and we want to list all of them matching some pattern.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-iterables-q01", "tutorial_id": "topics/data-science/tutorials/python-iterables", "query": "I have a list of student names and I want to sort them alphabetically. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Lists & Strings & Dictionaries", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Doing calculations with hundreds of variables called `pressure_001`, `pressure_002`, etc. would be at least as slow as doing them by hand. Using a *list* to store many values together solves that problems. Lists are surrounded by square brackets: `[`, `]`, with values separated by commas:", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-iterables-q02", "tutorial_id": "topics/data-science/tutorials/python-iterables", "query": "How can I convert a string of DNA sequence to its complement strand?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Lists & Strings & Dictionaries", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Doing calculations with hundreds of variables called `pressure_001`, `pressure_002`, etc. would be at least as slow as doing them by hand. Using a *list* to store many values together solves that problems. Lists are surrounded by square brackets: `[`, `]`, with values separated by commas:", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-iterables-q03", "tutorial_id": "topics/data-science/tutorials/python-iterables", "query": "Which data type should I use to store a list of chromosome lengths?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Lists & Strings & Dictionaries", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Doing calculations with hundreds of variables called `pressure_001`, `pressure_002`, etc. would be at least as slow as doing them by hand. Using a *list* to store many values together solves that problems. Lists are surrounded by square brackets: `[`, `]`, with values separated by commas:", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-iterables-q04", "tutorial_id": "topics/data-science/tutorials/python-iterables", "query": "How can I create a dictionary to map DNA bases to their complements?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Lists & Strings & Dictionaries", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Doing calculations with hundreds of variables called `pressure_001`, `pressure_002`, etc. would be at least as slow as doing them by hand. Using a *list* to store many values together solves that problems. Lists are surrounded by square brackets: `[`, `]`, with values separated by commas:", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-linting-q01", "tutorial_id": "topics/data-science/tutorials/python-linting", "query": "I want to reformat my Python code to follow the PEP8 style guide. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Coding Style", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "But before you dive into writing some more code and", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-linting-q02", "tutorial_id": "topics/data-science/tutorials/python-linting", "query": "How can I automatically reformat my Python code to have consistent indentation and line length?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Coding Style", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "But before you dive into writing some more code and", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-linting-q03", "tutorial_id": "topics/data-science/tutorials/python-linting", "query": "I need to write a Python function with clear and descriptive variable names. What naming conventions should I follow?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Coding Style", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "But before you dive into writing some more code and", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-linting-q04", "tutorial_id": "topics/data-science/tutorials/python-linting", "query": "How can I add docstrings to my Python functions to make them more understandable to others?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Coding Style", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "But before you dive into writing some more code and", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-loops-q01", "tutorial_id": "topics/data-science/tutorials/python-loops", "query": "I have a list of numbers and want to calculate the cumulative sum, how can I achieve this in Galaxy using Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Loops", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "A *for loop* tells Python to execute some statements once for each value in a list, a character string, or some other collection: \"for each thing in this group, do these operations\"", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-loops-q02", "tutorial_id": "topics/data-science/tutorials/python-loops", "query": "Which tool in Galaxy can I use to loop over a collection of items and perform operations on each item?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Loops", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "A *for loop* tells Python to execute some statements once for each value in a list, a character string, or some other collection: \"for each thing in this group, do these operations\"", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-loops-q03", "tutorial_id": "topics/data-science/tutorials/python-loops", "query": "I want to extract specific characters from a string and print them out, how can I do this in Galaxy using Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Loops", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "A *for loop* tells Python to execute some statements once for each value in a list, a character string, or some other collection: \"for each thing in this group, do these operations\"", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-loops-q04", "tutorial_id": "topics/data-science/tutorials/python-loops", "query": "How can I use Galaxy's Python tool to iterate over a list of numbers and print out only the numbers that meet a certain condition?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Loops", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "A *for loop* tells Python to execute some statements once for each value in a list, a character string, or some other collection: \"for each thing in this group, do these operations\"", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-math-q01", "tutorial_id": "topics/data-science/tutorials/python-math", "query": "I want to calculate the value of a variable using a mathematical equation in Python. How can I do this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Math", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we'll learn some of the fundamentals of python and how to do basic maths in Python.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-math-q02", "tutorial_id": "topics/data-science/tutorials/python-math", "query": "I have two values and I want to find their average using Python. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Math", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we'll learn some of the fundamentals of python and how to do basic maths in Python.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-math-q03", "tutorial_id": "topics/data-science/tutorials/python-math", "query": "What tool or function can I use to calculate the square root of a number in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Math", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we'll learn some of the fundamentals of python and how to do basic maths in Python.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-math-q04", "tutorial_id": "topics/data-science/tutorials/python-math", "query": "How can I import a library or module in Python to use its mathematical functions?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Math", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we'll learn some of the fundamentals of python and how to do basic maths in Python.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-multiprocessing-q01", "tutorial_id": "topics/data-science/tutorials/python-multiprocessing", "query": "I have a computationally intensive task to calculate prime numbers, how can I parallelize it using multiple processes in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Multiprocessing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to the basics of Threads and Processes in", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-multiprocessing-q02", "tutorial_id": "topics/data-science/tutorials/python-multiprocessing", "query": "Which type of parallelism is more suitable for tasks that involve waiting for server responses, threads or processes?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Multiprocessing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to the basics of Threads and Processes in", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-multiprocessing-q03", "tutorial_id": "topics/data-science/tutorials/python-multiprocessing", "query": "How can I determine the optimal pool size for parallelizing tasks using the multiprocessing library in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Multiprocessing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to the basics of Threads and Processes in", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-multiprocessing-q04", "tutorial_id": "topics/data-science/tutorials/python-multiprocessing", "query": "What are the advantages and disadvantages of using threads versus processes for parallelizing tasks in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Multiprocessing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to the basics of Threads and Processes in", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-plotting-q01", "tutorial_id": "topics/data-science/tutorials/python-plotting", "query": "I have a table with gene expression data and want to create a bar plot of the top 10 genes with the highest expression values. What tools should I use in Galaxy to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Plotting in Python", "datasets": ["annotated DE genes tabular"], "dataset_paths": ["annotated DE genes tabular"], "dataset_count": 1, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. This tutorial assumes that the reader is familiar with the fundamentals of data analysis using the Python programming language, as well as, how to run Python programs using Galaxy. Otherwise, it is advised to follow the \"Introduction to Python\" and \"Advanced Python\" tutorials available in the same platform. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-plotting-q02", "tutorial_id": "topics/data-science/tutorials/python-plotting", "query": "How can I change the style of my plot to ggplot in Galaxy using the plotting tool?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Plotting in Python", "datasets": ["annotated DE genes tabular"], "dataset_paths": ["annotated DE genes tabular"], "dataset_count": 1, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. This tutorial assumes that the reader is familiar with the fundamentals of data analysis using the Python programming language, as well as, how to run Python programs using Galaxy. Otherwise, it is advised to follow the \"Introduction to Python\" and \"Advanced Python\" tutorials available in the same platform. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-plotting-q03", "tutorial_id": "topics/data-science/tutorials/python-plotting", "query": "Which tool in Galaxy can I use to save a plot as a PNG file?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Plotting in Python", "datasets": ["annotated DE genes tabular"], "dataset_paths": ["annotated DE genes tabular"], "dataset_count": 1, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. This tutorial assumes that the reader is familiar with the fundamentals of data analysis using the Python programming language, as well as, how to run Python programs using Galaxy. Otherwise, it is advised to follow the \"Introduction to Python\" and \"Advanced Python\" tutorials available in the same platform. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-plotting-q04", "tutorial_id": "topics/data-science/tutorials/python-plotting", "query": "I want to create a scatterplot of the average P-value for every chromosome for the + and the - strand. How can I do this in Galaxy using the plotting tool?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Plotting in Python", "datasets": ["annotated DE genes tabular"], "dataset_paths": ["annotated DE genes tabular"], "dataset_count": 1, "context_summary": "In this lesson, we will be using Python 3 with some of its most popular scientific libraries. This tutorial assumes that the reader is familiar with the fundamentals of data analysis using the Python programming language, as well as, how to run Python programs using Galaxy. Otherwise, it is advised to follow the \"Introduction to Python\" and \"Advanced Python\" tutorials available in the same platform. We will be using JupyterNotebook, a Python interpreter that comes with everything we need for the lesson.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-subprocess-q01", "tutorial_id": "topics/data-science/tutorials/python-subprocess", "query": "I want to download a file from a URL using Python. What tools or libraries should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Subprocess", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Sometimes you need to run other tools in Python, like maybe you want to", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-subprocess-q02", "tutorial_id": "topics/data-science/tutorials/python-subprocess", "query": "How can I run a gene caller like Augustus on a genome file using Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Subprocess", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Sometimes you need to run other tools in Python, like maybe you want to", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-subprocess-q03", "tutorial_id": "topics/data-science/tutorials/python-subprocess", "query": "I have a genome file and I want to decompress it. What tools or libraries can I use in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Subprocess", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Sometimes you need to run other tools in Python, like maybe you want to", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-subprocess-q04", "tutorial_id": "topics/data-science/tutorials/python-subprocess", "query": "How can I capture the output of a command run using subprocess in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Subprocess", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Sometimes you need to run other tools in Python, like maybe you want to", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-testing-q01", "tutorial_id": "topics/data-science/tutorials/python-testing", "query": "I want to write unit tests for my Python functions, what tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Testing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we will cover the basics of testing, an important part of software development. Testing lets you know that your code is correct in many situations that matter to you.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-testing-q02", "tutorial_id": "topics/data-science/tutorials/python-testing", "query": "How can I automate testing for my Python code to ensure it works correctly?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Testing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we will cover the basics of testing, an important part of software development. Testing lets you know that your code is correct in many situations that matter to you.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-testing-q03", "tutorial_id": "topics/data-science/tutorials/python-testing", "query": "What tools are required to run and manage unit tests for a Python project?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Testing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we will cover the basics of testing, an important part of software development. Testing lets you know that your code is correct in many situations that matter to you.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-testing-q04", "tutorial_id": "topics/data-science/tutorials/python-testing", "query": "How can I use a testing framework to write and run tests for my Python code?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Testing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here we will cover the basics of testing, an important part of software development. Testing lets you know that your code is correct in many situations that matter to you.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-types-q01", "tutorial_id": "topics/data-science/tutorials/python-types", "query": "I want to check the type of a value in Python. What tool or function can I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Basic Types & Type Conversion", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Python is a typed language, data has a type, and different types of data cannot always be connected immediately and might need some conversion step before they can be used together. For instance if you add a number to a number, what should happen? If you add a number to a message, what do you expect will happen?", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-types-q02", "tutorial_id": "topics/data-science/tutorials/python-types", "query": "How can I convert an integer to a floating-point number in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Basic Types & Type Conversion", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Python is a typed language, data has a type, and different types of data cannot always be connected immediately and might need some conversion step before they can be used together. For instance if you add a number to a number, what should happen? If you add a number to a message, what do you expect will happen?", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-types-q03", "tutorial_id": "topics/data-science/tutorials/python-types", "query": "What tool or function can I use to perform arithmetic operations on numbers with different types in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Basic Types & Type Conversion", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Python is a typed language, data has a type, and different types of data cannot always be connected immediately and might need some conversion step before they can be used together. For instance if you add a number to a number, what should happen? If you add a number to a message, what do you expect will happen?", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-types-q04", "tutorial_id": "topics/data-science/tutorials/python-types", "query": "How can I concatenate a string and an integer in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Basic Types & Type Conversion", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Python is a typed language, data has a type, and different types of data cannot always be connected immediately and might need some conversion step before they can be used together. For instance if you add a number to a number, what should happen? If you add a number to a message, what do you expect will happen?", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-typing-q01", "tutorial_id": "topics/data-science/tutorials/python-typing", "query": "I want to use MonkeyType to automatically apply type annotations to my code. What tools do I need to install?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Type annotations", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In some languages type annotations are a core part of the language and types are checked at compile time, to ensure your code can never use the incorrect type of object. Python, and a few other dynamic languages, instead use [\"Duck Typing\"](https://en.wikipedia.org/wiki/Duck_typing) wherein the type of the object is less important than whether or not the correct methods or attributes are available.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-typing-q02", "tutorial_id": "topics/data-science/tutorials/python-typing", "query": "How can I use type annotations to catch bugs in my Python code?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Type annotations", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In some languages type annotations are a core part of the language and types are checked at compile time, to ensure your code can never use the incorrect type of object. Python, and a few other dynamic languages, instead use [\"Duck Typing\"](https://en.wikipedia.org/wiki/Duck_typing) wherein the type of the object is less important than whether or not the correct methods or attributes are available.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-typing-q03", "tutorial_id": "topics/data-science/tutorials/python-typing", "query": "What tool can I use to ensure that my type annotations are working correctly in my project?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Type annotations", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In some languages type annotations are a core part of the language and types are checked at compile time, to ensure your code can never use the incorrect type of object. Python, and a few other dynamic languages, instead use [\"Duck Typing\"](https://en.wikipedia.org/wiki/Duck_typing) wherein the type of the object is less important than whether or not the correct methods or attributes are available.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-typing-q04", "tutorial_id": "topics/data-science/tutorials/python-typing", "query": "How can I add type annotations to my Python functions and variables?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Type annotations", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In some languages type annotations are a core part of the language and types are checked at compile time, to ensure your code can never use the incorrect type of object. Python, and a few other dynamic languages, instead use [\"Duck Typing\"](https://en.wikipedia.org/wiki/Duck_typing) wherein the type of the object is less important than whether or not the correct methods or attributes are available.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-venv-q01", "tutorial_id": "topics/data-science/tutorials/python-venv", "query": "I need to create a new virtual environment for my Python project. What tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Virtual Environments For Software Development", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "\"Virtual Environments\" allow you to easily manage your installed Python packages and prevent conflicts between different project's dependencies. In general most modern projects should use `conda` for dependency management, but `venv` can be convenient for Python-only projects.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-venv-q02", "tutorial_id": "topics/data-science/tutorials/python-venv", "query": "How do I install external libraries in my virtual environment using pip?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Virtual Environments For Software Development", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "\"Virtual Environments\" allow you to easily manage your installed Python packages and prevent conflicts between different project's dependencies. In general most modern projects should use `conda` for dependency management, but `venv` can be convenient for Python-only projects.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-venv-q03", "tutorial_id": "topics/data-science/tutorials/python-venv", "query": "What is the best way to manage different Python versions and packages for multiple projects on my machine?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Virtual Environments For Software Development", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "\"Virtual Environments\" allow you to easily manage your installed Python packages and prevent conflicts between different project's dependencies. In general most modern projects should use `conda` for dependency management, but `venv` can be convenient for Python-only projects.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-venv-q04", "tutorial_id": "topics/data-science/tutorials/python-venv", "query": "How can I share my virtual environment with my collaborators so they can easily replicate it?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Virtual Environments For Software Development", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "\"Virtual Environments\" allow you to easily manage your installed Python packages and prevent conflicts between different project's dependencies. In general most modern projects should use `conda` for dependency management, but `venv` can be convenient for Python-only projects.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "python-warmup-stat-ml-q01", "tutorial_id": "topics/data-science/tutorials/python-warmup-stat-ml", "query": "I have a list of numbers generated with a loop and I want to calculate the square of each number. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Warm-up for statistics and machine learning", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "> <agenda-title></agenda-title>", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "python-warmup-stat-ml-q02", "tutorial_id": "topics/data-science/tutorials/python-warmup-stat-ml", "query": "I need to plot a line graph with markers, but I'm not sure which tool to use in Galaxy. Which tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Warm-up for statistics and machine learning", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "> <agenda-title></agenda-title>", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "python-warmup-stat-ml-q03", "tutorial_id": "topics/data-science/tutorials/python-warmup-stat-ml", "query": "I want to create a figure with multiple subplots and customize the labels and titles. How can I achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Warm-up for statistics and machine learning", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "> <agenda-title></agenda-title>", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "python-warmup-stat-ml-q04", "tutorial_id": "topics/data-science/tutorials/python-warmup-stat-ml", "query": "I'm working with a large dataset and I want to perform statistical testing to compare the means of two groups. What tool can I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Python - Warm-up for statistics and machine learning", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "> <agenda-title></agenda-title>", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "r-advanced-q01", "tutorial_id": "topics/data-science/tutorials/r-advanced", "query": "I have a table of differentially expressed genes ([annotatedDEgenes.tabular]) and I want to filter it to only include genes with an adjusted p-value less than 0.01. How can I do this in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced R in Galaxy", "datasets": ["annotatedDEgenes.tabular"], "dataset_paths": ["annotatedDEgenes.tabular"], "dataset_count": 1, "context_summary": "With HTS-Seq data analysis, we generated tables containing list of DE genes, their expression, some statistics, etc. We can manipulate these tables using Galaxy, as we saw in some tutorials, e.g. [\"Reference-based RNA-Seq data analysis\"]({% link topics/transcriptomics/tutorials/ref-based/tutorial.md %}), and create some visualisations.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "r-advanced-q02", "tutorial_id": "topics/data-science/tutorials/r-advanced", "query": "I need to perform a fold change calculation on my differential expression data ([annotatedDEgenes.tabular]) in Galaxy. Which tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced R in Galaxy", "datasets": ["annotatedDEgenes.tabular"], "dataset_paths": ["annotatedDEgenes.tabular"], "dataset_count": 1, "context_summary": "With HTS-Seq data analysis, we generated tables containing list of DE genes, their expression, some statistics, etc. We can manipulate these tables using Galaxy, as we saw in some tutorials, e.g. [\"Reference-based RNA-Seq data analysis\"]({% link topics/transcriptomics/tutorials/ref-based/tutorial.md %}), and create some visualisations.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "r-advanced-q03", "tutorial_id": "topics/data-science/tutorials/r-advanced", "query": "How can I use Galaxy to create a new column in my differential expression table ([annotatedDEgenes.tabular]) that categorizes genes as up-regulated or down-regulated based on their log2 fold change?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced R in Galaxy", "datasets": ["annotatedDEgenes.tabular"], "dataset_paths": ["annotatedDEgenes.tabular"], "dataset_count": 1, "context_summary": "With HTS-Seq data analysis, we generated tables containing list of DE genes, their expression, some statistics, etc. We can manipulate these tables using Galaxy, as we saw in some tutorials, e.g. [\"Reference-based RNA-Seq data analysis\"]({% link topics/transcriptomics/tutorials/ref-based/tutorial.md %}), and create some visualisations.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "r-advanced-q04", "tutorial_id": "topics/data-science/tutorials/r-advanced", "query": "I want to visualize the distribution of log2 fold changes for my differentially expressed genes ([annotatedDEgenes.tabular]) in Galaxy. What tool can I use to create a histogram?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced R in Galaxy", "datasets": ["annotatedDEgenes.tabular"], "dataset_paths": ["annotatedDEgenes.tabular"], "dataset_count": 1, "context_summary": "With HTS-Seq data analysis, we generated tables containing list of DE genes, their expression, some statistics, etc. We can manipulate these tables using Galaxy, as we saw in some tutorials, e.g. [\"Reference-based RNA-Seq data analysis\"]({% link topics/transcriptomics/tutorials/ref-based/tutorial.md %}), and create some visualisations.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "r-basics-q01", "tutorial_id": "topics/data-science/tutorials/r-basics", "query": "I want to create an object in R and check its mode. What tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "R basics in Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce R basics, using an RStudio Interactive Tool in Galaxy", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "r-basics-q02", "tutorial_id": "topics/data-science/tutorials/r-basics", "query": "How can I subset a vector in R to retrieve specific values?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "R basics in Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce R basics, using an RStudio Interactive Tool in Galaxy", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "r-basics-q03", "tutorial_id": "topics/data-science/tutorials/r-basics", "query": "I have a vector of numbers and I want to perform mathematical operations on it. Which tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "R basics in Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce R basics, using an RStudio Interactive Tool in Galaxy", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "r-basics-q04", "tutorial_id": "topics/data-science/tutorials/r-basics", "query": "How can I coerce a vector of characters into a numeric type in R?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "R basics in Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce R basics, using an RStudio Interactive Tool in Galaxy", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "r-dplyr-q01", "tutorial_id": "topics/data-science/tutorials/r-dplyr", "query": "I want to filter the rows for mammals that sleep a total of more than 16 hours and have a body weight of greater than 1 kilogram. How can I do this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "dplyr & tidyverse for data processing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "dplyr ({% cite r-dplyr %}) is a powerful R-package to transform and summarize tabular data with rows and columns. It is part of a group of packages (including `ggplot2`) called the `tidyverse` ({% cite r-tidyverse %}), a collection of packages for data processing and visualisation. For further exploration please see the dplyr package vignette: [Introduction to dplyr](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html)", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "r-dplyr-q02", "tutorial_id": "topics/data-science/tutorials/r-dplyr", "query": "Which function can I use to create a new column called rem_proportion, which is the ratio of rem sleep to total amount of sleep?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "dplyr & tidyverse for data processing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "dplyr ({% cite r-dplyr %}) is a powerful R-package to transform and summarize tabular data with rows and columns. It is part of a group of packages (including `ggplot2`) called the `tidyverse` ({% cite r-tidyverse %}), a collection of packages for data processing and visualisation. For further exploration please see the dplyr package vignette: [Introduction to dplyr](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html)", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "r-dplyr-q03", "tutorial_id": "topics/data-science/tutorials/r-dplyr", "query": "How can I arrange the rows in the msleep dataset by the taxonomic order and then by sleep_total in descending order?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "dplyr & tidyverse for data processing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "dplyr ({% cite r-dplyr %}) is a powerful R-package to transform and summarize tabular data with rows and columns. It is part of a group of packages (including `ggplot2`) called the `tidyverse` ({% cite r-tidyverse %}), a collection of packages for data processing and visualisation. For further exploration please see the dplyr package vignette: [Introduction to dplyr](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html)", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "r-dplyr-q04", "tutorial_id": "topics/data-science/tutorials/r-dplyr", "query": "What is the purpose of the group_by() function in dplyr and how can I use it to calculate the average sleep time for each taxonomic order?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "dplyr & tidyverse for data processing", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "dplyr ({% cite r-dplyr %}) is a powerful R-package to transform and summarize tabular data with rows and columns. It is part of a group of packages (including `ggplot2`) called the `tidyverse` ({% cite r-tidyverse %}), a collection of packages for data processing and visualisation. For further exploration please see the dplyr package vignette: [Introduction to dplyr](https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html)", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "snakemake-q01", "tutorial_id": "topics/data-science/tutorials/snakemake", "query": "I have paired-end FASTQ reads from a ChIP-seq experiment (SRR2584866_1.fq.gz, SRR2584866_2.fq.gz), want to assess library quality before alignment. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Make & Snakemake", "datasets": ["SRR2584866_1.fq.gz", "SRR2584866_2.fq.gz"], "dataset_paths": ["SRR2584866_1.fq.gz", "SRR2584866_2.fq.gz"], "dataset_count": 2, "context_summary": "Here you will learn to write both Make and Snakemake workflows. We teach two workflow engines because Snakemake uses a lot of the concepts of Make, and these concepts are somewhat complex and a very different way of thinking than you might be used to with workflow design.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "snakemake-q02", "tutorial_id": "topics/data-science/tutorials/snakemake", "query": "My single-cell FASTQ files (SRR2589044_1.fq.gz, SRR2589044_2.fq.gz) show variable read quality; how can I clean them for downstream analysis?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Make & Snakemake", "datasets": ["SRR2589044_1.fq.gz", "SRR2589044_2.fq.gz"], "dataset_paths": ["SRR2589044_1.fq.gz", "SRR2589044_2.fq.gz"], "dataset_count": 2, "context_summary": "Here you will learn to write both Make and Snakemake workflows. We teach two workflow engines because Snakemake uses a lot of the concepts of Make, and these concepts are somewhat complex and a very different way of thinking than you might be used to with workflow design.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "snakemake-q03", "tutorial_id": "topics/data-science/tutorials/snakemake", "query": "We sequenced tumor samples (GCA_000017985.1_ASM1798v1_genomic.fna.gz); how do I check for adapter contamination and trim low-quality bases?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Make & Snakemake", "datasets": ["GCA_000017985.1_ASM1798v1_genomic.fna.gz"], "dataset_paths": ["GCA_000017985.1_ASM1798v1_genomic.fna.gz"], "dataset_count": 1, "context_summary": "Here you will learn to write both Make and Snakemake workflows. We teach two workflow engines because Snakemake uses a lot of the concepts of Make, and these concepts are somewhat complex and a very different way of thinking than you might be used to with workflow design.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "snakemake-q04", "tutorial_id": "topics/data-science/tutorials/snakemake", "query": "Which tools should I use to assess read quality and trim adapters for paired-end FASTQ reads (SRR2584866_1.fq.gz, SRR2584866_2.fq.gz)?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Make & Snakemake", "datasets": ["SRR2584866_1.fq.gz", "SRR2584866_2.fq.gz"], "dataset_paths": ["SRR2584866_1.fq.gz", "SRR2584866_2.fq.gz"], "dataset_count": 2, "context_summary": "Here you will learn to write both Make and Snakemake workflows. We teach two workflow engines because Snakemake uses a lot of the concepts of Make, and these concepts are somewhat complex and a very different way of thinking than you might be used to with workflow design.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "sql-advanced-q01", "tutorial_id": "topics/data-science/tutorials/sql-advanced", "query": "I want to calculate ranges and averages for my data. What tool would I need to use for aggregation in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced SQL", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "> <comment-title></comment-title>", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "sql-advanced-q02", "tutorial_id": "topics/data-science/tutorials/sql-advanced", "query": "I have a table with site information and a table with visit information. How can I combine these tables based on the site name in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced SQL", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "> <comment-title></comment-title>", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "sql-advanced-q03", "tutorial_id": "topics/data-science/tutorials/sql-advanced", "query": "What tool can I use to create a new table with specific fields from existing tables in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced SQL", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "> <comment-title></comment-title>", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "sql-advanced-q04", "tutorial_id": "topics/data-science/tutorials/sql-advanced", "query": "I need to replace missing values in a field with a specific string in Galaxy. How can I do this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Advanced SQL", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "> <comment-title></comment-title>", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "sql-basic-q01", "tutorial_id": "topics/data-science/tutorials/sql-basic", "query": "I have a database with a table of people and their personal and family names, want to format the names as full names with a space between them. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to SQL", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to {SQL} which can be used to query databases!", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "sql-basic-q02", "tutorial_id": "topics/data-science/tutorials/sql-basic", "query": "Which Galaxy tool can be used to perform SQL queries on a database?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to SQL", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to {SQL} which can be used to query databases!", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "sql-basic-q03", "tutorial_id": "topics/data-science/tutorials/sql-basic", "query": "I have a table with site names and latitude values, want to filter the table to only include sites with latitude values between -50 and 50. How can I do this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to SQL", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to {SQL} which can be used to query databases!", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "sql-basic-q04", "tutorial_id": "topics/data-science/tutorials/sql-basic", "query": "I want to sort a table of survey data by date and then by person, how can I achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "Introduction to SQL", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to {SQL} which can be used to query databases!", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "sql-game-q01", "tutorial_id": "topics/data-science/tutorials/sql-game", "query": "I want to retrieve the corresponding crime scene report from the police department's database for a murder that occurred on Jan.15, 2018 in SQL City. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL Educational Game - Murder Mystery", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is not a tutorial like most GTN content but a fun exercise for you to play around and learn a bit about SQL in a more 'practical', and hopefully re-inforce the skills you covered in Basic and Advanced SQL skills. It makes use of the [NUKnightLab/sql-mysteries](https://github.com/NUKnightLab/sql-mysteries) SQL murder mystery project and released under open licenses:", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "sql-game-q02", "tutorial_id": "topics/data-science/tutorials/sql-game", "query": "I need to insert the name of the murderer into the solution table. How can I do this?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL Educational Game - Murder Mystery", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is not a tutorial like most GTN content but a fun exercise for you to play around and learn a bit about SQL in a more 'practical', and hopefully re-inforce the skills you covered in Basic and Advanced SQL skills. It makes use of the [NUKnightLab/sql-mysteries](https://github.com/NUKnightLab/sql-mysteries) SQL murder mystery project and released under open licenses:", "priority": 2, "version": "v0", "query_type": "science_first"}}
{"id": "sql-game-q03", "tutorial_id": "topics/data-science/tutorials/sql-game", "query": "Which tool should I use to run SQL queries in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL Educational Game - Murder Mystery", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is not a tutorial like most GTN content but a fun exercise for you to play around and learn a bit about SQL in a more 'practical', and hopefully re-inforce the skills you covered in Basic and Advanced SQL skills. It makes use of the [NUKnightLab/sql-mysteries](https://github.com/NUKnightLab/sql-mysteries) SQL murder mystery project and released under open licenses:", "priority": 3, "version": "v0", "query_type": "tool_first"}}
{"id": "sql-game-q04", "tutorial_id": "topics/data-science/tutorials/sql-game", "query": "How can I download and set up the SQL murder mystery database in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL Educational Game - Murder Mystery", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is not a tutorial like most GTN content but a fun exercise for you to play around and learn a bit about SQL in a more 'practical', and hopefully re-inforce the skills you covered in Basic and Advanced SQL skills. It makes use of the [NUKnightLab/sql-mysteries](https://github.com/NUKnightLab/sql-mysteries) SQL murder mystery project and released under open licenses:", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "sql-python-q01", "tutorial_id": "topics/data-science/tutorials/sql-python", "query": "I want to connect to an SQLite database from Python and perform queries. What library should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL with Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to accessing a SQL database from within Python. Experience with both SQL and Python is a pre-requisite.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "sql-python-q02", "tutorial_id": "topics/data-science/tutorials/sql-python", "query": "How can I prevent SQL injection attacks when inserting user-provided values into my database queries in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL with Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to accessing a SQL database from within Python. Experience with both SQL and Python is a pre-requisite.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "sql-python-q03", "tutorial_id": "topics/data-science/tutorials/sql-python", "query": "Which approach is faster for filtering data: filtering in SQL or reading all data into memory and filtering in Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL with Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to accessing a SQL database from within Python. Experience with both SQL and Python is a pre-requisite.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "sql-python-q04", "tutorial_id": "topics/data-science/tutorials/sql-python", "query": "How can I insert data from a CSV file into an SQLite database using Python?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL with Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will introduce you to accessing a SQL database from within Python. Experience with both SQL and Python is a pre-requisite.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "sql-r-q01", "tutorial_id": "topics/data-science/tutorials/sql-r", "query": "I want to create a new database in a file called 'original.db' containing a single table called 'Pressure', with a single field called 'reading', and insert 100,000 random numbers between 10.0 and 25.0. Which tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL with R", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial you'll learn to use SQL via R. Some R and SQL experience is a pre-requisite.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "sql-r-q02", "tutorial_id": "topics/data-science/tutorials/sql-r", "query": "How can I write an R program that creates a new database called 'backup.db' with the same structure as 'original.db' and copies all the values greater than 20.0 from 'original.db' to 'backup.db'?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL with R", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial you'll learn to use SQL via R. Some R and SQL experience is a pre-requisite.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "sql-r-q03", "tutorial_id": "topics/data-science/tutorials/sql-r", "query": "What tools are required to view all tables in a database and read an entire table as a dataframe?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL with R", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial you'll learn to use SQL via R. Some R and SQL experience is a pre-requisite.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "sql-r-q04", "tutorial_id": "topics/data-science/tutorials/sql-r", "query": "How can I use R to connect to an SQLite database, execute an SQL query, and retrieve the results?", "tools": [], "workflows": [], "metadata": {"topic": "data-science", "tutorial_title": "SQL with R", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial you'll learn to use SQL via R. Some R and SQL experience is a pre-requisite.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bioblend-api-q01", "tutorial_id": "topics/dev/tutorials/bioblend-api", "query": "I have a list of gene IDs and I want to find their corresponding gene names. What tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Scripting Galaxy using the API and BioBlend", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "BioBlend ({% cite Sloggett2013 %}) is a Python library to enable simple interaction with Galaxy ({% cite Afgan2018 %}) via the command line or scripts.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bioblend-api-q02", "tutorial_id": "topics/dev/tutorials/bioblend-api", "query": "How can I upload a file to a new history and run a workflow on it using the Galaxy API?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Scripting Galaxy using the API and BioBlend", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "BioBlend ({% cite Sloggett2013 %}) is a Python library to enable simple interaction with Galaxy ({% cite Afgan2018 %}) via the command line or scripts.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bioblend-api-q03", "tutorial_id": "topics/dev/tutorials/bioblend-api", "query": "I need to find a tool to convert a file from one format to another. What tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Scripting Galaxy using the API and BioBlend", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "BioBlend ({% cite Sloggett2013 %}) is a Python library to enable simple interaction with Galaxy ({% cite Afgan2018 %}) via the command line or scripts.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bioblend-api-q04", "tutorial_id": "topics/dev/tutorials/bioblend-api", "query": "How can I use BioBlend to interact with a Galaxy server and perform tasks programmatically?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Scripting Galaxy using the API and BioBlend", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "BioBlend ({% cite Sloggett2013 %}) is a Python library to enable simple interaction with Galaxy ({% cite Afgan2018 %}) via the command line or scripts.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bioblend-dev-q01", "tutorial_id": "topics/dev/tutorials/bioblend-dev", "query": "I want to contribute to BioBlend by adding a new method to the ToolsClient class. What tools would I need to use to interact with the Galaxy API and write tests for my new method?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Contributing to BioBlend as a developer", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "BioBlend ({% cite Sloggett2013 %}) is a Python library to enable simple interaction with Galaxy ({% cite Afgan2018 %}) via the command line or scripts.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bioblend-dev-q02", "tutorial_id": "topics/dev/tutorials/bioblend-dev", "query": "How can I run the BioBlend tests against a specific version of Galaxy, such as 21.01, to ensure compatibility?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Contributing to BioBlend as a developer", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "BioBlend ({% cite Sloggett2013 %}) is a Python library to enable simple interaction with Galaxy ({% cite Afgan2018 %}) via the command line or scripts.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bioblend-dev-q03", "tutorial_id": "topics/dev/tutorials/bioblend-dev", "query": "What tools are required to set up a local Galaxy server for testing BioBlend functionality?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Contributing to BioBlend as a developer", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "BioBlend ({% cite Sloggett2013 %}) is a Python library to enable simple interaction with Galaxy ({% cite Afgan2018 %}) via the command line or scripts.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bioblend-dev-q04", "tutorial_id": "topics/dev/tutorials/bioblend-dev", "query": "How can I determine the version of the Galaxy server from within BioBlend to ensure that my code is compatible with different versions?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Contributing to BioBlend as a developer", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "BioBlend ({% cite Sloggett2013 %}) is a Python library to enable simple interaction with Galaxy ({% cite Afgan2018 %}) via the command line or scripts.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "core-contributing-q01", "tutorial_id": "topics/dev/tutorials/core-contributing", "query": "I want to implement a new feature in Galaxy core. What tools do I need to develop and test my extension?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Contributing a New Feature to Galaxy Core", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial walks you through developing an extension to Galaxy, and how to contribute back to the core project.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "core-contributing-q02", "tutorial_id": "topics/dev/tutorials/core-contributing", "query": "How do I create a new branch for my edits in the Galaxy repository?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Contributing a New Feature to Galaxy Core", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial walks you through developing an extension to Galaxy, and how to contribute back to the core project.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "core-contributing-q03", "tutorial_id": "topics/dev/tutorials/core-contributing", "query": "What tools are required to run the tests for my Galaxy extension?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Contributing a New Feature to Galaxy Core", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial walks you through developing an extension to Galaxy, and how to contribute back to the core project.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "core-contributing-q04", "tutorial_id": "topics/dev/tutorials/core-contributing", "query": "How do I add a new table to Galaxy's data model and create the corresponding database schema?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Contributing a New Feature to Galaxy Core", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial walks you through developing an extension to Galaxy, and how to contribute back to the core project.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "data-source-integration-q01", "tutorial_id": "topics/dev/tutorials/data-source-integration", "query": "I want to create a new history called 'doRiNA' in Galaxy. How do I do that?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Data source integration", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Data Source Integration", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "data-source-integration-q02", "tutorial_id": "topics/dev/tutorials/data-source-integration", "query": "Which Galaxy tool can I use to search the doRiNA database and send the results to my Galaxy history?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Data source integration", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Data Source Integration", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "data-source-integration-q03", "tutorial_id": "topics/dev/tutorials/data-source-integration", "query": "I want to search the doRiNA database using the hg19 genome build and Regulators (set A) drop-down list. How do I do that?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Data source integration", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Data Source Integration", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "data-source-integration-q04", "tutorial_id": "topics/dev/tutorials/data-source-integration", "query": "How do I access the doRiNA database directly from Galaxy and add it to my history?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Data source integration", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Data Source Integration", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "debugging-q01", "tutorial_id": "topics/dev/tutorials/debugging", "query": "I want to fix a unit test failure in Galaxy. What tools would I need to use to identify and fix the issue?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Debugging Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we will demonstrate how to find and fix common types of bugs you may encounter as a contributor to Galaxy. We will step you through the process of finding and fixing a bug - from locating specific errors in the logs of Galaxy's GitHub Actions, to identifying their cause, developing a solution and committing your edits", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "debugging-q02", "tutorial_id": "topics/dev/tutorials/debugging", "query": "I want to fix a client linting error in Galaxy. What tools would I need to use to identify and fix the issue?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Debugging Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we will demonstrate how to find and fix common types of bugs you may encounter as a contributor to Galaxy. We will step you through the process of finding and fixing a bug - from locating specific errors in the logs of Galaxy's GitHub Actions, to identifying their cause, developing a solution and committing your edits", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "debugging-q03", "tutorial_id": "topics/dev/tutorials/debugging", "query": "How can I achieve fixing a runtime error in Galaxy using the debugging tools provided?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Debugging Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we will demonstrate how to find and fix common types of bugs you may encounter as a contributor to Galaxy. We will step you through the process of finding and fixing a bug - from locating specific errors in the logs of Galaxy's GitHub Actions, to identifying their cause, developing a solution and committing your edits", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "debugging-q04", "tutorial_id": "topics/dev/tutorials/debugging", "query": "How can I achieve fixing a Selenium test failure in Galaxy using the provided testing framework?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Debugging Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we will demonstrate how to find and fix common types of bugs you may encounter as a contributor to Galaxy. We will step you through the process of finding and fixing a bug - from locating specific errors in the logs of Galaxy's GitHub Actions, to identifying their cause, developing a solution and committing your edits", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "interactive-tools-q01", "tutorial_id": "topics/dev/tutorials/interactive-tools", "query": "I want to build a Galaxy Interactive Tool (GxIT) for a simple web application. What tools do I need to create and configure?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Galaxy Interactive Tools", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "<!--", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "interactive-tools-q02", "tutorial_id": "topics/dev/tutorials/interactive-tools", "query": "How do I push a Docker image to a container registry like Docker Hub or quay.io to make it accessible to my Galaxy server?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Galaxy Interactive Tools", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "<!--", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "interactive-tools-q03", "tutorial_id": "topics/dev/tutorials/interactive-tools", "query": "I have created a Galaxy Interactive Tool (GxIT) and I want to test it locally. What tools do I need to install and configure on my machine?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Galaxy Interactive Tools", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "<!--", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "interactive-tools-q04", "tutorial_id": "topics/dev/tutorials/interactive-tools", "query": "How do I deploy a Galaxy Interactive Tool (GxIT) to a production Galaxy instance and make it available to users?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Galaxy Interactive Tools", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "<!--", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "onedata-dev-instance-q01", "tutorial_id": "topics/dev/tutorials/onedata-dev-instance", "query": "I want to test Galaxy & Onedata integration, how can I set up a local Onedata sandbox deployment?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Setting up a dev Onedata instance", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Prerequisites", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "onedata-dev-instance-q02", "tutorial_id": "topics/dev/tutorials/onedata-dev-instance", "query": "Which method should I use to acquire an access token for Onedata in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Setting up a dev Onedata instance", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Prerequisites", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "onedata-dev-instance-q03", "tutorial_id": "topics/dev/tutorials/onedata-dev-instance", "query": "What should I do if I encounter untrusted connection issues when accessing the Onezone UI in demo mode?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Setting up a dev Onedata instance", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Prerequisites", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "onedata-dev-instance-q04", "tutorial_id": "topics/dev/tutorials/onedata-dev-instance", "query": "How can I configure Galaxy to use Onedata with self-signed certificates in demo mode?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Setting up a dev Onedata instance", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Prerequisites", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "tool-annotation-q01", "tutorial_id": "topics/dev/tutorials/tool-annotation", "query": "I want to add a bio.tools entry to a Galaxy tool, but I'm not sure which tool to use. Can someone help me find the right tool for the job?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Adding and updating best practice metadata for Galaxy tools using the bio.tools registry", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy offers thousands of tools. Many of these tools either have incomplete metadata or are not yet linked to sources of high-quality metadata such as [bio.tools](https://bio.tools/).", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "tool-annotation-q02", "tutorial_id": "topics/dev/tutorials/tool-annotation", "query": "How do I link a Galaxy tool to its corresponding bio.tools entry? I'm having trouble finding the right xref section to add the bio.tools ID.", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Adding and updating best practice metadata for Galaxy tools using the bio.tools registry", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy offers thousands of tools. Many of these tools either have incomplete metadata or are not yet linked to sources of high-quality metadata such as [bio.tools](https://bio.tools/).", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "tool-annotation-q03", "tutorial_id": "topics/dev/tutorials/tool-annotation", "query": "What tool can I use to update the EDAM terms for a bio.tools entry? I want to make sure the terms are correct before linking it to a Galaxy tool.", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Adding and updating best practice metadata for Galaxy tools using the bio.tools registry", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy offers thousands of tools. Many of these tools either have incomplete metadata or are not yet linked to sources of high-quality metadata such as [bio.tools](https://bio.tools/).", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "tool-annotation-q04", "tutorial_id": "topics/dev/tutorials/tool-annotation", "query": "I have a Galaxy tool and I want to add a bio.tools entry to it. Can someone walk me through the process of creating a new bio.tools entry and linking it to my Galaxy tool?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Adding and updating best practice metadata for Galaxy tools using the bio.tools registry", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy offers thousands of tools. Many of these tools either have incomplete metadata or are not yet linked to sources of high-quality metadata such as [bio.tools](https://bio.tools/).", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "tool-from-scratch-q01", "tutorial_id": "topics/dev/tutorials/tool-from-scratch", "query": "I want to create a bio.tools ID for my tool, how do I do that?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Creating Galaxy tools from Conda Through Deployment", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Tools wrappers allow any command line runnable code or programs to be run inside a galaxy environment.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "tool-from-scratch-q02", "tutorial_id": "topics/dev/tutorials/tool-from-scratch", "query": "What are the required sections for a Bioconda recipe?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Creating Galaxy tools from Conda Through Deployment", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Tools wrappers allow any command line runnable code or programs to be run inside a galaxy environment.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "tool-from-scratch-q03", "tutorial_id": "topics/dev/tutorials/tool-from-scratch", "query": "How do I initialize a tool wrapper using planemo?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Creating Galaxy tools from Conda Through Deployment", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Tools wrappers allow any command line runnable code or programs to be run inside a galaxy environment.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "tool-from-scratch-q04", "tutorial_id": "topics/dev/tutorials/tool-from-scratch", "query": "What is the purpose of the macros section in a Galaxy tool wrapper?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Creating Galaxy tools from Conda Through Deployment", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Tools wrappers allow any command line runnable code or programs to be run inside a galaxy environment.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "tool-generators-q01", "tutorial_id": "topics/dev/tutorials/tool-generators", "query": "I have a bash script that takes two positional parameters and want to turn it into a Galaxy tool. What tools would I use?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "ToolFactory: Generating Tools From Simple Scripts", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The Toolfactory and these tutorials are for developers and researchers learning about Galaxy, who routinely develop their own analysis scripts using", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "tool-generators-q02", "tutorial_id": "topics/dev/tutorials/tool-generators", "query": "I need to create a Galaxy tool that uses a Python script and takes input files from the history. What tools would I use?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "ToolFactory: Generating Tools From Simple Scripts", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The Toolfactory and these tutorials are for developers and researchers learning about Galaxy, who routinely develop their own analysis scripts using", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "tool-generators-q03", "tutorial_id": "topics/dev/tutorials/tool-generators", "query": "How do I create a new Galaxy tool using the ToolFactory to wrap a bash script?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "ToolFactory: Generating Tools From Simple Scripts", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The Toolfactory and these tutorials are for developers and researchers learning about Galaxy, who routinely develop their own analysis scripts using", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "tool-generators-q04", "tutorial_id": "topics/dev/tutorials/tool-generators", "query": "How can I modify a generated Galaxy tool to add additional user-controlled parameters?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "ToolFactory: Generating Tools From Simple Scripts", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The Toolfactory and these tutorials are for developers and researchers learning about Galaxy, who routinely develop their own analysis scripts using", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "tool-generators-advanced-q01", "tutorial_id": "topics/dev/tutorials/tool-generators-advanced", "query": "I have a script that I want to turn into a Galaxy tool. What tools do I need to use to do this?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "ToolFactory: Generating Tools From More Complex Scripts", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy users who write and share scripts useful for scientific analyses are likely to be reading this material, perhaps after seeing the \"Hello Galaxy\"", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "tool-generators-advanced-q02", "tutorial_id": "topics/dev/tutorials/tool-generators-advanced", "query": "How do I create a Galaxy tool that runs a script with multiple input files and parameters?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "ToolFactory: Generating Tools From More Complex Scripts", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy users who write and share scripts useful for scientific analyses are likely to be reading this material, perhaps after seeing the \"Hello Galaxy\"", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "tool-generators-advanced-q03", "tutorial_id": "topics/dev/tutorials/tool-generators-advanced", "query": "What tools are required to wrap a Conda package in a Galaxy tool?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "ToolFactory: Generating Tools From More Complex Scripts", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy users who write and share scripts useful for scientific analyses are likely to be reading this material, perhaps after seeing the \"Hello Galaxy\"", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "tool-generators-advanced-q04", "tutorial_id": "topics/dev/tutorials/tool-generators-advanced", "query": "How can I use the ToolFactory to generate a Galaxy tool that produces a collection of output files?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "ToolFactory: Generating Tools From More Complex Scripts", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Galaxy users who write and share scripts useful for scientific analyses are likely to be reading this material, perhaps after seeing the \"Hello Galaxy\"", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "visualization-charts-q01", "tutorial_id": "topics/dev/tutorials/visualization-charts", "query": "I want to visualize a PDB file in Galaxy using the PV-Javascript Protein Viewer. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "JavaScript plugins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are going to demonstrate how to add a third party", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "visualization-charts-q02", "tutorial_id": "topics/dev/tutorials/visualization-charts", "query": "How can I add a new visualization plugin to Galaxy and make it available for PDB files?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "JavaScript plugins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are going to demonstrate how to add a third party", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "visualization-charts-q03", "tutorial_id": "topics/dev/tutorials/visualization-charts", "query": "Which tool can I use to convert a PDB file to a format that can be visualized in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "JavaScript plugins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are going to demonstrate how to add a third party", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "visualization-charts-q04", "tutorial_id": "topics/dev/tutorials/visualization-charts", "query": "How can I customize the rendering mode of the PV-Javascript Protein Viewer in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "JavaScript plugins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are going to demonstrate how to add a third party", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "visualization-generic-q01", "tutorial_id": "topics/dev/tutorials/visualization-generic", "query": "I have a BAM file and want to create a visualization of the number of aligned reads per chromosome. What tools or programming languages should I use?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Generic plugins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Visualizations may be very helpful in understanding data better. There is a whole", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "visualization-generic-q02", "tutorial_id": "topics/dev/tutorials/visualization-generic", "query": "I need to parse a BAM index file and extract the number of reads per chromosome. Which programming libraries or tools can help me achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Generic plugins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Visualizations may be very helpful in understanding data better. There is a whole", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "visualization-generic-q03", "tutorial_id": "topics/dev/tutorials/visualization-generic", "query": "How can I create a visualization plugin in Galaxy to display the number of aligned reads per chromosome for a BAM file?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Generic plugins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Visualizations may be very helpful in understanding data better. There is a whole", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "visualization-generic-q04", "tutorial_id": "topics/dev/tutorials/visualization-generic", "query": "What are the steps to link a visualization plugin with Galaxy and create a mako file for rendering the visualization?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Generic plugins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Visualizations may be very helpful in understanding data better. There is a whole", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "webhooks-q01", "tutorial_id": "topics/dev/tutorials/webhooks", "query": "I want to display a random comic on the tool execution page in Galaxy. What tools or programming languages should I use?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Galaxy Webhooks", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are going to demonstrate how to add a webhook to the tool-execution endpoint. This is the web-page that appears", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "webhooks-q02", "tutorial_id": "topics/dev/tutorials/webhooks", "query": "How can I add a custom button to the Galaxy tool execution page that fetches data from an external API?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Galaxy Webhooks", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are going to demonstrate how to add a webhook to the tool-execution endpoint. This is the web-page that appears", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "webhooks-q03", "tutorial_id": "topics/dev/tutorials/webhooks", "query": "What tools or libraries are required to parse HTML pages and make API calls in Galaxy webhooks?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Galaxy Webhooks", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are going to demonstrate how to add a webhook to the tool-execution endpoint. This is the web-page that appears", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "webhooks-q04", "tutorial_id": "topics/dev/tutorials/webhooks", "query": "How can I customize the appearance of a Galaxy webhook using CSS, and what files need to be modified?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Galaxy Webhooks", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "In this tutorial we are going to demonstrate how to add a webhook to the tool-execution endpoint. This is the web-page that appears", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "writing_tests-q01", "tutorial_id": "topics/dev/tutorials/writing_tests", "query": "I want to write API tests for adding a simple object, like a role, using the Galaxy API. What tools or setup do I need?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Writing Automated Tests for Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The Galaxy code base contains thousands of tests that include tests of different types (unit vs. functional vs. end-to-end; client vs. backend, etc.) that are supported by a variety of testing frameworks and libraries. In this tutorial, we will offer a small, yet representative sample of the types of tests you might write, as well as the concepts and issues you may need to be familiar with when writing tests for Galaxy code, whether as part of a new feature you are implementing, or as a standalone contribution to Galaxy's testing code.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "writing_tests-q02", "tutorial_id": "topics/dev/tutorials/writing_tests", "query": "How can I test the 'validate_email' function in the 'lib/galaxy/security/validate_user_input.py' module, which depends on a Transaction and User objects?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Writing Automated Tests for Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The Galaxy code base contains thousands of tests that include tests of different types (unit vs. functional vs. end-to-end; client vs. backend, etc.) that are supported by a variety of testing frameworks and libraries. In this tutorial, we will offer a small, yet representative sample of the types of tests you might write, as well as the concepts and issues you may need to be familiar with when writing tests for Galaxy code, whether as part of a new feature you are implementing, or as a standalone contribution to Galaxy's testing code.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "writing_tests-q03", "tutorial_id": "topics/dev/tutorials/writing_tests", "query": "What approach can I use to refactor the 'validate_email' function to make it more testable, considering its dependencies on the GalaxyApplication and database?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Writing Automated Tests for Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The Galaxy code base contains thousands of tests that include tests of different types (unit vs. functional vs. end-to-end; client vs. backend, etc.) that are supported by a variety of testing frameworks and libraries. In this tutorial, we will offer a small, yet representative sample of the types of tests you might write, as well as the concepts and issues you may need to be familiar with when writing tests for Galaxy code, whether as part of a new feature you are implementing, or as a standalone contribution to Galaxy's testing code.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "writing_tests-q04", "tutorial_id": "topics/dev/tutorials/writing_tests", "query": "How can I utilize Galaxy's populators to simplify the setup of database state for my API tests, such as creating roles and datasets?", "tools": [], "workflows": [], "metadata": {"topic": "dev", "tutorial_title": "Writing Automated Tests for Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The Galaxy code base contains thousands of tests that include tests of different types (unit vs. functional vs. end-to-end; client vs. backend, etc.) that are supported by a variety of testing frameworks and libraries. In this tutorial, we will offer a small, yet representative sample of the types of tests you might write, as well as the concepts and issues you may need to be familiar with when writing tests for Galaxy code, whether as part of a new feature you are implementing, or as a standalone contribution to Galaxy's testing code.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ENA_Biodiv_submission-q01", "tutorial_id": "topics/ecology/tutorials/ENA_Biodiv_submission", "query": "I have raw AB1 sequencing files and want to convert them to FASTQ format for quality control. Which Galaxy tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Data submission using ENA upload Tool", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will guide you through the necessary steps to manage and prepare sequencing files (ab1, FASTQ, FASTA) for submission to the genomic database ENA.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "ENA_Biodiv_submission-q02", "tutorial_id": "topics/ecology/tutorials/ENA_Biodiv_submission", "query": "How can I perform quality control on my FASTQ files and generate reports to assess their quality?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Data submission using ENA upload Tool", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will guide you through the necessary steps to manage and prepare sequencing files (ab1, FASTQ, FASTA) for submission to the genomic database ENA.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "ENA_Biodiv_submission-q03", "tutorial_id": "topics/ecology/tutorials/ENA_Biodiv_submission", "query": "I need to trim adapters and low-quality bases from my FASTQ files. Which Galaxy tool can I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Data submission using ENA upload Tool", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will guide you through the necessary steps to manage and prepare sequencing files (ab1, FASTQ, FASTA) for submission to the genomic database ENA.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "ENA_Biodiv_submission-q04", "tutorial_id": "topics/ecology/tutorials/ENA_Biodiv_submission", "query": "How can I submit my cleaned and quality-controlled FASTQ files to the ENA database using Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Data submission using ENA upload Tool", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will guide you through the necessary steps to manage and prepare sequencing files (ab1, FASTQ, FASTA) for submission to the genomic database ENA.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "MetaShARK_tutorial-q01", "tutorial_id": "topics/ecology/tutorials/MetaShARK_tutorial", "query": "I want to create a data package using MetaShARK, but I'm not sure which tools I need to use. Can you tell me which tools are required for this task?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Creating metadata using Ecological Metadata Language (EML) standard with EML Assembly Line functionalities", "datasets": ["https://zenodo.org/records/10663465"], "dataset_paths": ["https://zenodo.org/records/10663465"], "dataset_count": 1, "context_summary": "<p align=\"justify\">This tutorial aims to teach <b>how to use functionalities of the EML Assembly Line R package to produce rich metadata</b> using the Ecological Metadata Language (EML) international metadata standard. Here, we will notably propose a concrete example on how to use <b>Galaxy Ecology tools to create, evaluate and modify EML metadata</b> content using both EML Assemby Line metadata template tabular files, easily readable and editable by humans, and XML file, devoted to machine.</p>", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "MetaShARK_tutorial-q02", "tutorial_id": "topics/ecology/tutorials/MetaShARK_tutorial", "query": "I have created an EML metadata file using MetaShARK and I want to assess its FAIRness. How can I do this in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Creating metadata using Ecological Metadata Language (EML) standard with EML Assembly Line functionalities", "datasets": ["https://zenodo.org/records/10663465"], "dataset_paths": ["https://zenodo.org/records/10663465"], "dataset_count": 1, "context_summary": "<p align=\"justify\">This tutorial aims to teach <b>how to use functionalities of the EML Assembly Line R package to produce rich metadata</b> using the Ecological Metadata Language (EML) international metadata standard. Here, we will notably propose a concrete example on how to use <b>Galaxy Ecology tools to create, evaluate and modify EML metadata</b> content using both EML Assemby Line metadata template tabular files, easily readable and editable by humans, and XML file, devoted to machine.</p>", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "MetaShARK_tutorial-q03", "tutorial_id": "topics/ecology/tutorials/MetaShARK_tutorial", "query": "I need to upload shapefile related files into Galaxy, but I'm not sure how to do it. Can you guide me through the process?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Creating metadata using Ecological Metadata Language (EML) standard with EML Assembly Line functionalities", "datasets": ["https://zenodo.org/records/10663465"], "dataset_paths": ["https://zenodo.org/records/10663465"], "dataset_count": 1, "context_summary": "<p align=\"justify\">This tutorial aims to teach <b>how to use functionalities of the EML Assembly Line R package to produce rich metadata</b> using the Ecological Metadata Language (EML) international metadata standard. Here, we will notably propose a concrete example on how to use <b>Galaxy Ecology tools to create, evaluate and modify EML metadata</b> content using both EML Assemby Line metadata template tabular files, easily readable and editable by humans, and XML file, devoted to machine.</p>", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "MetaShARK_tutorial-q04", "tutorial_id": "topics/ecology/tutorials/MetaShARK_tutorial", "query": "I want to use MetaShRIMPS to evaluate and modify metadata elements, but I don't know how to launch the tool. Can you tell me how to do it?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Creating metadata using Ecological Metadata Language (EML) standard with EML Assembly Line functionalities", "datasets": ["https://zenodo.org/records/10663465"], "dataset_paths": ["https://zenodo.org/records/10663465"], "dataset_count": 1, "context_summary": "<p align=\"justify\">This tutorial aims to teach <b>how to use functionalities of the EML Assembly Line R package to produce rich metadata</b> using the Ecological Metadata Language (EML) international metadata standard. Here, we will notably propose a concrete example on how to use <b>Galaxy Ecology tools to create, evaluate and modify EML metadata</b> content using both EML Assemby Line metadata template tabular files, easily readable and editable by humans, and XML file, devoted to machine.</p>", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "Metashrimps_tutorial-q01", "tutorial_id": "topics/ecology/tutorials/Metashrimps_tutorial", "query": "I have an EML metadata file and I want to assess its FAIR quality. Which tool should I use in Galaxy to do this?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Creating FAIR Quality assessment reports and draft of Data Papers from EML metadata with MetaShRIMPS", "datasets": ["zenodo.8130567"], "dataset_paths": ["zenodo.8130567"], "dataset_count": 1, "context_summary": "This tutorial aims to teach how to use the interactive tool MetaShRIMPS, available on Galaxy Ecology,", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "Metashrimps_tutorial-q02", "tutorial_id": "topics/ecology/tutorials/Metashrimps_tutorial", "query": "I need to create a Data Paper draft from my EML metadata. How can I do this in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Creating FAIR Quality assessment reports and draft of Data Papers from EML metadata with MetaShRIMPS", "datasets": ["zenodo.8130567"], "dataset_paths": ["zenodo.8130567"], "dataset_count": 1, "context_summary": "This tutorial aims to teach how to use the interactive tool MetaShRIMPS, available on Galaxy Ecology,", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "Metashrimps_tutorial-q03", "tutorial_id": "topics/ecology/tutorials/Metashrimps_tutorial", "query": "I want to evaluate the FAIRness of my metadata. What steps should I take to get a quality assessment report?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Creating FAIR Quality assessment reports and draft of Data Papers from EML metadata with MetaShRIMPS", "datasets": ["zenodo.8130567"], "dataset_paths": ["zenodo.8130567"], "dataset_count": 1, "context_summary": "This tutorial aims to teach how to use the interactive tool MetaShRIMPS, available on Galaxy Ecology,", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "Metashrimps_tutorial-q04", "tutorial_id": "topics/ecology/tutorials/Metashrimps_tutorial", "query": "I have uploaded my EML metadata to Galaxy and I want to get a draft of a Data Paper. What tool should I use to generate it?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Creating FAIR Quality assessment reports and draft of Data Papers from EML metadata with MetaShRIMPS", "datasets": ["zenodo.8130567"], "dataset_paths": ["zenodo.8130567"], "dataset_count": 1, "context_summary": "This tutorial aims to teach how to use the interactive tool MetaShRIMPS, available on Galaxy Ecology,", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "NEAL_tutorial-q01", "tutorial_id": "topics/ecology/tutorials/NEAL_tutorial", "query": "I have an audio file (1008421.wav) and I want to annotate it using the NEAL interactive tool in Galaxy. What tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Audio data annotation with NEAL (Nature + Energy Audio labeler)", "datasets": ["1008421.wav"], "dataset_paths": ["1008421.wav"], "dataset_count": 1, "context_summary": "This tutorial is designed to guide you through the annotation of audio data via the NEAL interactive tool.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "NEAL_tutorial-q02", "tutorial_id": "topics/ecology/tutorials/NEAL_tutorial", "query": "I need to export the labels file from the NEAL interactive tool in Galaxy. How can I do that?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Audio data annotation with NEAL (Nature + Energy Audio labeler)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial is designed to guide you through the annotation of audio data via the NEAL interactive tool.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "NEAL_tutorial-q03", "tutorial_id": "topics/ecology/tutorials/NEAL_tutorial", "query": "Which tool should I use to import an audio file into Galaxy and prepare it for annotation with NEAL?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Audio data annotation with NEAL (Nature + Energy Audio labeler)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial is designed to guide you through the annotation of audio data via the NEAL interactive tool.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "NEAL_tutorial-q04", "tutorial_id": "topics/ecology/tutorials/NEAL_tutorial", "query": "How can I restart the NEAL interactive tool in Galaxy using a previous labels file (my_labels_file.csv) and an audio file (1008421.wav)?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Audio data annotation with NEAL (Nature + Energy Audio labeler)", "datasets": ["1008421.wav", "my_labels_file.csv"], "dataset_paths": ["1008421.wav", "my_labels_file.csv"], "dataset_count": 2, "context_summary": "This tutorial is designed to guide you through the annotation of audio data via the NEAL interactive tool.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "QGIS_Web_Feature_Services-q01", "tutorial_id": "topics/ecology/tutorials/QGIS_Web_Feature_Services", "query": "I want to load a WFS layer into QGIS using a URL, what tools do I need to use?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "QGIS Web Feature Services", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Based on this [QGIS official tutorial](https://docs.qgis.org/2.18/en/docs/training_manual/online_resources/wfs.html), you will learn here how to access, filter and import GIS data through WFS web service using QGIS Galaxy interactive tool:", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "QGIS_Web_Feature_Services-q02", "tutorial_id": "topics/ecology/tutorials/QGIS_Web_Feature_Services", "query": "How can I query a WFS layer to only load specific features in QGIS?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "QGIS Web Feature Services", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Based on this [QGIS official tutorial](https://docs.qgis.org/2.18/en/docs/training_manual/online_resources/wfs.html), you will learn here how to access, filter and import GIS data through WFS web service using QGIS Galaxy interactive tool:", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "QGIS_Web_Feature_Services-q03", "tutorial_id": "topics/ecology/tutorials/QGIS_Web_Feature_Services", "query": "I need to access and filter GIS data through a WFS web service using QGIS Galaxy interactive tool, what is the first step?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "QGIS Web Feature Services", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Based on this [QGIS official tutorial](https://docs.qgis.org/2.18/en/docs/training_manual/online_resources/wfs.html), you will learn here how to access, filter and import GIS data through WFS web service using QGIS Galaxy interactive tool:", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "QGIS_Web_Feature_Services-q04", "tutorial_id": "topics/ecology/tutorials/QGIS_Web_Feature_Services", "query": "How do I save my QGIS project and layers for future use in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "QGIS Web Feature Services", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Based on this [QGIS official tutorial](https://docs.qgis.org/2.18/en/docs/training_manual/online_resources/wfs.html), you will learn here how to access, filter and import GIS data through WFS web service using QGIS Galaxy interactive tool:", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ecoregiolifetraits-q01", "tutorial_id": "topics/ecology/tutorials/ecoregiolifetraits", "query": "I have environmental data and occurrence data, what tools are needed to merge them based on their latitude and longitude coordinates?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Life Traits Ecoregionalization workflow", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial is designed to guide you through the Ecoregionalization Galaxy workflow, demonstrating how to create a life traits ecoregionalization map from occurrences and environmental data using a boosted regression tree model for predictions.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "ecoregiolifetraits-q02", "tutorial_id": "topics/ecology/tutorials/ecoregiolifetraits", "query": "How can I use a boosted regression tree model to predict life traits from environmental data and occurrence data in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Life Traits Ecoregionalization workflow", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial is designed to guide you through the Ecoregionalization Galaxy workflow, demonstrating how to create a life traits ecoregionalization map from occurrences and environmental data using a boosted regression tree model for predictions.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "ecoregiolifetraits-q03", "tutorial_id": "topics/ecology/tutorials/ecoregiolifetraits", "query": "What tools are required to clean and format occurrence data for the ecoregionalization workflow in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Life Traits Ecoregionalization workflow", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial is designed to guide you through the Ecoregionalization Galaxy workflow, demonstrating how to create a life traits ecoregionalization map from occurrences and environmental data using a boosted regression tree model for predictions.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "ecoregiolifetraits-q04", "tutorial_id": "topics/ecology/tutorials/ecoregiolifetraits", "query": "How can I determine the optimal number of clusters for ecoregionalization using clustering algorithms in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Life Traits Ecoregionalization workflow", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial is designed to guide you through the Ecoregionalization Galaxy workflow, demonstrating how to create a life traits ecoregionalization map from occurrences and environmental data using a boosted regression tree model for predictions.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ndvi_openeo-q01", "tutorial_id": "topics/ecology/tutorials/ndvi_openeo", "query": "I have NDVI data from Copernicus Data Space Ecosystem and want to visualize it as a time series. What should I do?", "tools": ["interactive_tool_copernicus_notebook"], "workflows": ["NDVI-with-OpenEO", "main_workflow"], "metadata": {"topic": "ecology", "tutorial_title": "From NDVI data with OpenEO to time series visualisation with Holoviews", "datasets": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_paths": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_count": 3, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 1, "version": "v0", "workflow_steps": {"NDVI-with-OpenEO": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"], "main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"]}, "query_type": "science_first", "tool_focus": "interactive_tool_copernicus_notebook"}}
{"id": "ndvi_openeo-q02", "tutorial_id": "topics/ecology/tutorials/ndvi_openeo", "query": "How can I access and download Copernicus Data Space Ecosystem data through a JupyterLab Galaxy interactive tool?", "tools": ["interactive_tool_copernicus_notebook"], "workflows": ["NDVI-with-OpenEO", "main_workflow"], "metadata": {"topic": "ecology", "tutorial_title": "From NDVI data with OpenEO to time series visualisation with Holoviews", "datasets": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_paths": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_count": 3, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 2, "version": "v0", "workflow_steps": {"NDVI-with-OpenEO": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"], "main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"]}, "query_type": "science_first", "tool_focus": "interactive_tool_copernicus_notebook"}}
{"id": "ndvi_openeo-q03", "tutorial_id": "topics/ecology/tutorials/ndvi_openeo", "query": "Which Galaxy tool should I use to access Copernicus Data Space Ecosystem data?", "tools": ["interactive_tool_copernicus_notebook"], "workflows": ["NDVI-with-OpenEO", "main_workflow"], "metadata": {"topic": "ecology", "tutorial_title": "From NDVI data with OpenEO to time series visualisation with Holoviews", "datasets": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_paths": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_count": 3, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 3, "version": "v0", "workflow_steps": {"NDVI-with-OpenEO": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"], "main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_copernicus_notebook"}}
{"id": "ndvi_openeo-q04", "tutorial_id": "topics/ecology/tutorials/ndvi_openeo", "query": "How do I launch the Copernicus Data Space Ecosystem tool in Galaxy?", "tools": ["interactive_tool_copernicus_notebook"], "workflows": ["NDVI-with-OpenEO", "main_workflow"], "metadata": {"topic": "ecology", "tutorial_title": "From NDVI data with OpenEO to time series visualisation with Holoviews", "datasets": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_paths": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_count": 3, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 4, "version": "v0", "workflow_steps": {"NDVI-with-OpenEO": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"], "main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_copernicus_notebook"}}
{"id": "ndvi_openeo-q05", "tutorial_id": "topics/ecology/tutorials/ndvi_openeo", "query": "I have NDVI data and want to visualize it using Holoviz. What should I do?", "tools": ["interactive_tool_holoviz"], "workflows": ["NDVI-with-OpenEO", "main_workflow"], "metadata": {"topic": "ecology", "tutorial_title": "From NDVI data with OpenEO to time series visualisation with Holoviews", "datasets": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_paths": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_count": 3, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 5, "version": "v0", "workflow_steps": {"NDVI-with-OpenEO": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"], "main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"]}, "query_type": "science_first", "tool_focus": "interactive_tool_holoviz"}}
{"id": "ndvi_openeo-q06", "tutorial_id": "topics/ecology/tutorials/ndvi_openeo", "query": "How can I plot and visualize NDVI time series data using Holoviz?", "tools": ["interactive_tool_holoviz"], "workflows": ["NDVI-with-OpenEO", "main_workflow"], "metadata": {"topic": "ecology", "tutorial_title": "From NDVI data with OpenEO to time series visualisation with Holoviews", "datasets": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_paths": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_count": 3, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 6, "version": "v0", "workflow_steps": {"NDVI-with-OpenEO": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"], "main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"]}, "query_type": "science_first", "tool_focus": "interactive_tool_holoviz"}}
{"id": "ndvi_openeo-q07", "tutorial_id": "topics/ecology/tutorials/ndvi_openeo", "query": "Which Galaxy tool should I use to visualize NDVI data using Holoviz?", "tools": ["interactive_tool_holoviz"], "workflows": ["NDVI-with-OpenEO", "main_workflow"], "metadata": {"topic": "ecology", "tutorial_title": "From NDVI data with OpenEO to time series visualisation with Holoviews", "datasets": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_paths": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_count": 3, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 7, "version": "v0", "workflow_steps": {"NDVI-with-OpenEO": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"], "main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_holoviz"}}
{"id": "ndvi_openeo-q08", "tutorial_id": "topics/ecology/tutorials/ndvi_openeo", "query": "How do I launch the Holoviz tool in Galaxy with my NDVI data?", "tools": ["interactive_tool_holoviz"], "workflows": ["NDVI-with-OpenEO", "main_workflow"], "metadata": {"topic": "ecology", "tutorial_title": "From NDVI data with OpenEO to time series visualisation with Holoviews", "datasets": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_paths": ["timeseries-basic.csv", "timeseries-masked.csv", "timeseries-smoothed.csv"], "dataset_count": 3, "context_summary": "Through this tutorial you will learn here how to access and download Copernicus Data Space Ecosystem (CDSE) data through a jupyterlab Galaxy interactive tool :", "priority": 8, "version": "v0", "workflow_steps": {"NDVI-with-OpenEO": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"], "main_workflow": ["interactive_tool_copernicus_notebook", "interactive_tool_holoviz"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_holoviz"}}
{"id": "openrefine_gbif-q01", "tutorial_id": "topics/ecology/tutorials/openrefine_gbif", "query": "I have a dataset of occurrence records retrieved from GBIF and I want to clean it. Which tool should I use to deploy an OpenRefine instance and push my data into it?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Cleaning GBIF data using OpenRefine", "datasets": ["UC1-3c-open-refine-tabular"], "dataset_paths": ["UC1-3c-open-refine-tabular"], "dataset_count": 1, "context_summary": "In this tutorial we will use OpenRefine tool to clean occurrence records retrieved from GBIF (Global Biodiversity Information Facility).", "priority": 1, "version": "v0", "query_type": "tool_first"}}
{"id": "openrefine_gbif-q02", "tutorial_id": "topics/ecology/tutorials/openrefine_gbif", "query": "I need to perform data cleaning on my occurrence records from GBIF using OpenRefine in Galaxy. How can I export my cleaned data into my Galaxy history?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Cleaning GBIF data using OpenRefine", "datasets": ["openrefine-Galaxt file.tsv"], "dataset_paths": ["openrefine-Galaxt file.tsv"], "dataset_count": 1, "context_summary": "In this tutorial we will use OpenRefine tool to clean occurrence records retrieved from GBIF (Global Biodiversity Information Facility).", "priority": 2, "version": "v0", "query_type": "science_first"}}
{"id": "openrefine_gbif-q03", "tutorial_id": "topics/ecology/tutorials/openrefine_gbif", "query": "I want to use OpenRefine to clean my GBIF occurrence records in Galaxy. What tool do I need to use to apply a Text facet to a column and then sort the values alphabetically?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Cleaning GBIF data using OpenRefine", "datasets": ["UC1-3c-open-refine-tabular"], "dataset_paths": ["UC1-3c-open-refine-tabular"], "dataset_count": 1, "context_summary": "In this tutorial we will use OpenRefine tool to clean occurrence records retrieved from GBIF (Global Biodiversity Information Facility).", "priority": 3, "version": "v0", "query_type": "tool_first"}}
{"id": "openrefine_gbif-q04", "tutorial_id": "topics/ecology/tutorials/openrefine_gbif", "query": "I have cleaned my GBIF occurrence records using OpenRefine in Galaxy and now I want to export the data. How can I export my cleaned data into a tabular file?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Cleaning GBIF data using OpenRefine", "datasets": ["openrefine-Galaxt file.tsv"], "dataset_paths": ["openrefine-Galaxt file.tsv"], "dataset_count": 1, "context_summary": "In this tutorial we will use OpenRefine tool to clean occurrence records retrieved from GBIF (Global Biodiversity Information Facility).", "priority": 4, "version": "v0", "query_type": "science_first"}}
{"id": "panoply_ebv-q01", "tutorial_id": "topics/ecology/tutorials/panoply_ebv", "query": "I have a netCDF file containing EBV cube data, want to visualize it as a geographical map. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Visualize EBV cube data with Panoply netCDF viewer", "datasets": ["martins_comcom_id1_20220208_v1.nc"], "dataset_paths": ["martins_comcom_id1_20220208_v1.nc"], "dataset_count": 1, "context_summary": "The practical aims at familiarzing you with the [Panoply](https://www.giss.nasa.gov/tools/panoply/) Galaxy interactive tool. Panoply is among the most popular tool to visualize geo-referenced data stored in [Network Common Data Form](https://en.wikipedia.org/wiki/NetCDF) (netCDF). It provides a graphical interface for inspecting (show metadata) and visualizing netCDF data. It supports many features to customize your plots and we will introduce some of them in this lesson.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "panoply_ebv-q02", "tutorial_id": "topics/ecology/tutorials/panoply_ebv", "query": "Which Galaxy tool can I use to change the map projection of my EBV cube data visualization?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Visualize EBV cube data with Panoply netCDF viewer", "datasets": ["martins_comcom_id1_20220208_v1.nc"], "dataset_paths": ["martins_comcom_id1_20220208_v1.nc"], "dataset_count": 1, "context_summary": "The practical aims at familiarzing you with the [Panoply](https://www.giss.nasa.gov/tools/panoply/) Galaxy interactive tool. Panoply is among the most popular tool to visualize geo-referenced data stored in [Network Common Data Form](https://en.wikipedia.org/wiki/NetCDF) (netCDF). It provides a graphical interface for inspecting (show metadata) and visualizing netCDF data. It supports many features to customize your plots and we will introduce some of them in this lesson.", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "panoply_ebv-q03", "tutorial_id": "topics/ecology/tutorials/panoply_ebv", "query": "I want to export an animation of my EBV cube data visualization over time. How can I do that in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Visualize EBV cube data with Panoply netCDF viewer", "datasets": ["martins_comcom_id1_20220208_v1.nc"], "dataset_paths": ["martins_comcom_id1_20220208_v1.nc"], "dataset_count": 1, "context_summary": "The practical aims at familiarzing you with the [Panoply](https://www.giss.nasa.gov/tools/panoply/) Galaxy interactive tool. Panoply is among the most popular tool to visualize geo-referenced data stored in [Network Common Data Form](https://en.wikipedia.org/wiki/NetCDF) (netCDF). It provides a graphical interface for inspecting (show metadata) and visualizing netCDF data. It supports many features to customize your plots and we will introduce some of them in this lesson.", "priority": 3, "version": "v0", "query_type": "science_first"}}
{"id": "panoply_ebv-q04", "tutorial_id": "topics/ecology/tutorials/panoply_ebv", "query": "How can I inspect the metadata of my EBV cube data in Galaxy, specifically the unit of the 'ebv_cube' variable?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Visualize EBV cube data with Panoply netCDF viewer", "datasets": ["martins_comcom_id1_20220208_v1.nc"], "dataset_paths": ["martins_comcom_id1_20220208_v1.nc"], "dataset_count": 1, "context_summary": "The practical aims at familiarzing you with the [Panoply](https://www.giss.nasa.gov/tools/panoply/) Galaxy interactive tool. Panoply is among the most popular tool to visualize geo-referenced data stored in [Network Common Data Form](https://en.wikipedia.org/wiki/NetCDF) (netCDF). It provides a graphical interface for inspecting (show metadata) and visualizing netCDF data. It supports many features to customize your plots and we will introduce some of them in this lesson.", "priority": 4, "version": "v0", "query_type": "science_first"}}
{"id": "phylodiversity_workflow-q01", "tutorial_id": "topics/ecology/tutorials/phylodiversity_workflow", "query": "I have a phylogenetic tree file and an occupancy file, and I want to match them. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Phylodiversity analysis quick tutorial", "datasets": ["phylogeny_test", "grid_test.tabular"], "dataset_paths": ["phylogeny_test", "grid_test.tabular"], "dataset_count": 2, "context_summary": "This tutorial is designed to guide you through the Phylodiversity Galaxy workflow, demonstrating how to easily compute phylodiversity and create phyloregions from phylogeny, occupency and spatial files.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "phylodiversity_workflow-q02", "tutorial_id": "topics/ecology/tutorials/phylodiversity_workflow", "query": "I have a shapefile and I want to modify its projection. Which Galaxy tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Phylodiversity analysis quick tutorial", "datasets": ["shapefile"], "dataset_paths": ["shapefile"], "dataset_count": 1, "context_summary": "This tutorial is designed to guide you through the Phylodiversity Galaxy workflow, demonstrating how to easily compute phylodiversity and create phyloregions from phylogeny, occupency and spatial files.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "phylodiversity_workflow-q03", "tutorial_id": "topics/ecology/tutorials/phylodiversity_workflow", "query": "How can I compute the phylodiversity index using a phylogenetic tree and occupancy data in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Phylodiversity analysis quick tutorial", "datasets": ["Phylogeny with occupancy data", "Matched output data"], "dataset_paths": ["Phylogeny with occupancy data", "Matched output data"], "dataset_count": 2, "context_summary": "This tutorial is designed to guide you through the Phylodiversity Galaxy workflow, demonstrating how to easily compute phylodiversity and create phyloregions from phylogeny, occupency and spatial files.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "phylodiversity_workflow-q04", "tutorial_id": "topics/ecology/tutorials/phylodiversity_workflow", "query": "I want to estimate endemism using a phylogenetic tree, occupancy data, and a shapefile. What steps should I follow in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "ecology", "tutorial_title": "Phylodiversity analysis quick tutorial", "datasets": ["Phylogeny with occupancy data", "Matched output data", "shapefile"], "dataset_paths": ["Phylogeny with occupancy data", "Matched output data", "shapefile"], "dataset_count": 3, "context_summary": "This tutorial is designed to guide you through the Phylodiversity Galaxy workflow, demonstrating how to easily compute phylodiversity and create phyloregions from phylogeny, occupency and spatial files.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bacterial-comparative-genomics-q01", "tutorial_id": "topics/evolution/tutorials/bacterial-comparative-genomics", "query": "I have a contig file from a bacterial comparative genomics study and I want to build a phylogenetic tree. What tools should I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "evolution", "tutorial_title": "Phylogenetic analysis for bacterial comparative genomics", "datasets": ["DRR187559_contigs.fasta"], "dataset_paths": ["DRR187559_contigs.fasta"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bacterial-comparative-genomics-q02", "tutorial_id": "topics/evolution/tutorials/bacterial-comparative-genomics", "query": "I want to perform a phylogenetic analysis for bacterial comparative genomics. How can I prepare my data for this analysis in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "evolution", "tutorial_title": "Phylogenetic analysis for bacterial comparative genomics", "datasets": ["DRR187559_contigs.fasta"], "dataset_paths": ["DRR187559_contigs.fasta"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bacterial-comparative-genomics-q03", "tutorial_id": "topics/evolution/tutorials/bacterial-comparative-genomics", "query": "Which Galaxy tool can I use to build a phylogenetic tree from a multiple sequence alignment file?", "tools": [], "workflows": [], "metadata": {"topic": "evolution", "tutorial_title": "Phylogenetic analysis for bacterial comparative genomics", "datasets": ["DRR187559_contigs.fasta"], "dataset_paths": ["DRR187559_contigs.fasta"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bacterial-comparative-genomics-q04", "tutorial_id": "topics/evolution/tutorials/bacterial-comparative-genomics", "query": "How can I upload and rename my contig file in Galaxy to start a phylogenetic analysis?", "tools": [], "workflows": [], "metadata": {"topic": "evolution", "tutorial_title": "Phylogenetic analysis for bacterial comparative genomics", "datasets": ["DRR187559_contigs.fasta"], "dataset_paths": ["DRR187559_contigs.fasta"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "mtb_phylogeny-q01", "tutorial_id": "topics/evolution/tutorials/mtb_phylogeny", "query": "I have a phylogenetic tree in Newick format and want to visualize it with branch lengths and node labels. What should I do?", "tools": ["interactive_tool_rstudio"], "workflows": ["main_workflow"], "metadata": {"topic": "evolution", "tutorial_title": "Tree thinking for tuberculosis evolution and epidemiology", "datasets": ["SNP_alignment.fasta"], "dataset_paths": ["SNP_alignment.fasta"], "dataset_count": 1, "context_summary": "> \"Nothing in biology makes sense except in the light of evolution.\"", "priority": 1, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_rstudio", "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"]}, "query_type": "science_first", "tool_focus": "interactive_tool_rstudio"}}
{"id": "mtb_phylogeny-q02", "tutorial_id": "topics/evolution/tutorials/mtb_phylogeny", "query": "I need to root a phylogenetic tree using an outgroup. How can I do this in Galaxy?", "tools": ["interactive_tool_rstudio"], "workflows": ["main_workflow"], "metadata": {"topic": "evolution", "tutorial_title": "Tree thinking for tuberculosis evolution and epidemiology", "datasets": ["SNP_alignment.fasta"], "dataset_paths": ["SNP_alignment.fasta"], "dataset_count": 1, "context_summary": "> \"Nothing in biology makes sense except in the light of evolution.\"", "priority": 2, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_rstudio", "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"]}, "query_type": "science_first", "tool_focus": "interactive_tool_rstudio"}}
{"id": "mtb_phylogeny-q03", "tutorial_id": "topics/evolution/tutorials/mtb_phylogeny", "query": "Which Galaxy tool can I use to estimate a phylogenetic tree from a multiple sequence alignment?", "tools": ["interactive_tool_rstudio"], "workflows": ["main_workflow"], "metadata": {"topic": "evolution", "tutorial_title": "Tree thinking for tuberculosis evolution and epidemiology", "datasets": ["SNP_alignment.fasta"], "dataset_paths": ["SNP_alignment.fasta"], "dataset_count": 1, "context_summary": "> \"Nothing in biology makes sense except in the light of evolution.\"", "priority": 3, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_rstudio", "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_rstudio"}}
{"id": "mtb_phylogeny-q04", "tutorial_id": "topics/evolution/tutorials/mtb_phylogeny", "query": "I have a tree and want to add a trait as a tip label. How can I do this in Galaxy?", "tools": ["interactive_tool_rstudio"], "workflows": ["main_workflow"], "metadata": {"topic": "evolution", "tutorial_title": "Tree thinking for tuberculosis evolution and epidemiology", "datasets": ["SNP_alignment.fasta"], "dataset_paths": ["SNP_alignment.fasta"], "dataset_count": 1, "context_summary": "> \"Nothing in biology makes sense except in the light of evolution.\"", "priority": 4, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_rstudio", "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"]}, "query_type": "tool_first", "tool_focus": "interactive_tool_rstudio"}}
{"id": "mtb_phylogeny-q05", "tutorial_id": "topics/evolution/tutorials/mtb_phylogeny", "query": "I want to perform bootstrapping to assess the robustness of my phylogenetic tree. Can I do this in Galaxy?", "tools": ["toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"], "workflows": ["main_workflow"], "metadata": {"topic": "evolution", "tutorial_title": "Tree thinking for tuberculosis evolution and epidemiology", "datasets": ["SNP_alignment.fasta"], "dataset_paths": ["SNP_alignment.fasta"], "dataset_count": 1, "context_summary": "> \"Nothing in biology makes sense except in the light of evolution.\"", "priority": 5, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_rstudio", "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"}}
{"id": "mtb_phylogeny-q06", "tutorial_id": "topics/evolution/tutorials/mtb_phylogeny", "query": "I have a set of phylogenetic trees and want to compare them. What tools are available in Galaxy for this purpose?", "tools": ["toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"], "workflows": ["main_workflow"], "metadata": {"topic": "evolution", "tutorial_title": "Tree thinking for tuberculosis evolution and epidemiology", "datasets": ["SNP_alignment.fasta"], "dataset_paths": ["SNP_alignment.fasta"], "dataset_count": 1, "context_summary": "> \"Nothing in biology makes sense except in the light of evolution.\"", "priority": 6, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_rstudio", "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"}}
{"id": "mtb_phylogeny-q07", "tutorial_id": "topics/evolution/tutorials/mtb_phylogeny", "query": "Which Galaxy tool can I use to manipulate and edit phylogenetic trees?", "tools": ["toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"], "workflows": ["main_workflow"], "metadata": {"topic": "evolution", "tutorial_title": "Tree thinking for tuberculosis evolution and epidemiology", "datasets": ["SNP_alignment.fasta"], "dataset_paths": ["SNP_alignment.fasta"], "dataset_count": 1, "context_summary": "> \"Nothing in biology makes sense except in the light of evolution.\"", "priority": 7, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_rstudio", "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"}}
{"id": "mtb_phylogeny-q08", "tutorial_id": "topics/evolution/tutorials/mtb_phylogeny", "query": "I want to visualize my phylogenetic tree with a specific layout and branch length. What Galaxy tool can I use?", "tools": ["toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"], "workflows": ["main_workflow"], "metadata": {"topic": "evolution", "tutorial_title": "Tree thinking for tuberculosis evolution and epidemiology", "datasets": ["SNP_alignment.fasta"], "dataset_paths": ["SNP_alignment.fasta"], "dataset_count": 1, "context_summary": "> \"Nothing in biology makes sense except in the light of evolution.\"", "priority": 8, "version": "v0", "workflow_steps": {"main_workflow": ["interactive_tool_rstudio", "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/iuc/raxml/raxml/8.2.4+galaxy2"}}
{"id": "bioimage-REMBI-q01", "tutorial_id": "topics/fair/tutorials/bioimage-REMBI", "query": "I want to use an ontology to find a suitable study type for my research. Which Galaxy tool can help me with that?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "REMBI - Recommended Metadata for Biological Images – metadata guidelines for bioimaging data", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Metadata guidelines for bioimaging data", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bioimage-REMBI-q02", "tutorial_id": "topics/fair/tutorials/bioimage-REMBI", "query": "I have a set of image data and I want to make it FAIR. How can I collect and organize the metadata according to the REMBI guidelines in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "REMBI - Recommended Metadata for Biological Images – metadata guidelines for bioimaging data", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Metadata guidelines for bioimaging data", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bioimage-REMBI-q03", "tutorial_id": "topics/fair/tutorials/bioimage-REMBI", "query": "I need to describe the imaging method used to acquire my image data. What tool can I use to find the correct terms from a relevant ontology?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "REMBI - Recommended Metadata for Biological Images – metadata guidelines for bioimaging data", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Metadata guidelines for bioimaging data", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bioimage-REMBI-q04", "tutorial_id": "topics/fair/tutorials/bioimage-REMBI", "query": "I want to store my metadata in a file and share it with my collaborators. How can I structure the metadata file according to the REMBI guidelines and ensure it is easily accessible and interoperable?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "REMBI - Recommended Metadata for Biological Images – metadata guidelines for bioimaging data", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Metadata guidelines for bioimaging data", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bioimage-metadata-q01", "tutorial_id": "topics/fair/tutorials/bioimage-metadata", "query": "I want to collect metadata alongside my imaging experiments. What tools or software can I use to store and manage this metadata?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR Bioimage Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# FAIR Bioimaging", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bioimage-metadata-q02", "tutorial_id": "topics/fair/tutorials/bioimage-metadata", "query": "I have chosen a bioimage data repository and want to submit my data. What tools do I need to use to prepare my data for submission?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR Bioimage Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# FAIR Bioimaging", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bioimage-metadata-q03", "tutorial_id": "topics/fair/tutorials/bioimage-metadata", "query": "How can I ensure that my bioimage data is findable, accessible, interoperable, and reusable (FAIR) when submitting it to a repository?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR Bioimage Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# FAIR Bioimaging", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bioimage-metadata-q04", "tutorial_id": "topics/fair/tutorials/bioimage-metadata", "query": "What are the steps to choose a suitable bioimage data repository for my data and how can I prepare my data for submission?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR Bioimage Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# FAIR Bioimaging", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "data-management-q01", "tutorial_id": "topics/fair/tutorials/data-management", "query": "I need to store and backup my research data. What tools or strategies can I use to ensure that my data is safely stored and backed up?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR data management solutions", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The FAIR (Findable, Accessible, Interoperable, Reusable)  data stewardship created the foundation for sharing and publishing digital assets, especially data. This apply to machine accessibility and emphasize that all digital assets should share data in a way that will enable maximum use and reuse.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "data-management-q02", "tutorial_id": "topics/fair/tutorials/data-management", "query": "How can I make my dataset findable and accessible to others, and what tools or services can help me achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR data management solutions", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The FAIR (Findable, Accessible, Interoperable, Reusable)  data stewardship created the foundation for sharing and publishing digital assets, especially data. This apply to machine accessibility and emphasize that all digital assets should share data in a way that will enable maximum use and reuse.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "data-management-q03", "tutorial_id": "topics/fair/tutorials/data-management", "query": "What tools or services can I use to create a data management plan (DMP) for my research project?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR data management solutions", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The FAIR (Findable, Accessible, Interoperable, Reusable)  data stewardship created the foundation for sharing and publishing digital assets, especially data. This apply to machine accessibility and emphasize that all digital assets should share data in a way that will enable maximum use and reuse.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "data-management-q04", "tutorial_id": "topics/fair/tutorials/data-management", "query": "How can I ensure that my data is properly documented and of high quality, and what tools or guidelines can help me achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR data management solutions", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The FAIR (Findable, Accessible, Interoperable, Reusable)  data stewardship created the foundation for sharing and publishing digital assets, especially data. This apply to machine accessibility and emphasize that all digital assets should share data in a way that will enable maximum use and reuse.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "data-management-peatlands-q01", "tutorial_id": "topics/fair/tutorials/data-management-peatlands", "query": "I need to create a Data Management Plan for my peatland research project. What tools or resources would I need to use to fill in the DMP template?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Introduction to Data Management Plan (DMP) for Peatland Research and PeatDataHub", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Peatland monitoring and research generates data that is used for management, conservation and policy related to these ecosystems. To ensure that your project data is collected systematically and can be analysed, shared, and re-used it is important to have a data management plan.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "data-management-peatlands-q02", "tutorial_id": "topics/fair/tutorials/data-management-peatlands", "query": "How can I make my Data Management Plan FAIR (Findable, Accessible, Interoperable, Reusable) for my peatland research data?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Introduction to Data Management Plan (DMP) for Peatland Research and PeatDataHub", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Peatland monitoring and research generates data that is used for management, conservation and policy related to these ecosystems. To ensure that your project data is collected systematically and can be analysed, shared, and re-used it is important to have a data management plan.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "data-management-peatlands-q03", "tutorial_id": "topics/fair/tutorials/data-management-peatlands", "query": "I want to review and discuss my Data Management Plan with my team and collaborators. What tools or platforms can I use to share and collaborate on the plan?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Introduction to Data Management Plan (DMP) for Peatland Research and PeatDataHub", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Peatland monitoring and research generates data that is used for management, conservation and policy related to these ecosystems. To ensure that your project data is collected systematically and can be analysed, shared, and re-used it is important to have a data management plan.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "data-management-peatlands-q04", "tutorial_id": "topics/fair/tutorials/data-management-peatlands", "query": "How can I ensure that my Data Management Plan is properly implemented and maintained throughout my peatland research project?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Introduction to Data Management Plan (DMP) for Peatland Research and PeatDataHub", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Peatland monitoring and research generates data that is used for management, conservation and policy related to these ecosystems. To ensure that your project data is collected systematically and can be analysed, shared, and re-used it is important to have a data management plan.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "dataplant-arcs-q01", "tutorial_id": "topics/fair/tutorials/dataplant-arcs", "query": "I want to create an ARC for my plant research data. What tools do I need to install to work with ARCs?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "DataPLANT ARCs", "datasets": ["https://zenodo.org/records/13970369"], "dataset_paths": ["https://zenodo.org/records/13970369"], "dataset_count": 1, "context_summary": "In this tutorial we will guide you through the process of creating your ARC (Annotated Research Context)", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "dataplant-arcs-q02", "tutorial_id": "topics/fair/tutorials/dataplant-arcs", "query": "I have some research data and I want to bundle and annotate it in a standardized and FAIR manner using ARCs. How do I achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "DataPLANT ARCs", "datasets": ["https://zenodo.org/records/13970369"], "dataset_paths": ["https://zenodo.org/records/13970369"], "dataset_count": 1, "context_summary": "In this tutorial we will guide you through the process of creating your ARC (Annotated Research Context)", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "dataplant-arcs-q03", "tutorial_id": "topics/fair/tutorials/dataplant-arcs", "query": "I am trying to initialize my ARC structure using ARCitect. What are the steps to do this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "DataPLANT ARCs", "datasets": ["https://zenodo.org/records/13970369"], "dataset_paths": ["https://zenodo.org/records/13970369"], "dataset_count": 1, "context_summary": "In this tutorial we will guide you through the process of creating your ARC (Annotated Research Context)", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "dataplant-arcs-q04", "tutorial_id": "topics/fair/tutorials/dataplant-arcs", "query": "I want to add computational workflows to my ARC. What are the options for doing this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "DataPLANT ARCs", "datasets": ["https://zenodo.org/records/13970369"], "dataset_paths": ["https://zenodo.org/records/13970369"], "dataset_count": 1, "context_summary": "In this tutorial we will guide you through the process of creating your ARC (Annotated Research Context)", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-access-q01", "tutorial_id": "topics/fair/tutorials/fair-access", "query": "I need to make my dataset openly accessible, but I'm not sure what data usage license to choose. How do I select a suitable license?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Access", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Data access including levels of access are described.  Learners will be able to illustrate data access in terms of the FAIR Principles using companion terms including communications protocol and authentication.  Learners will also be able to interpret the data usage licence associated with different data sets", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fair-access-q02", "tutorial_id": "topics/fair/tutorials/fair-access", "query": "I have sensitive data that I want to make accessible to researchers. What are the best practices for de-identifying and sharing this type of data?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Access", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Data access including levels of access are described.  Learners will be able to illustrate data access in terms of the FAIR Principles using companion terms including communications protocol and authentication.  Learners will also be able to interpret the data usage licence associated with different data sets", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fair-access-q03", "tutorial_id": "topics/fair/tutorials/fair-access", "query": "Which communication protocol should I use to ensure secure data transfer when accessing my dataset?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Access", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Data access including levels of access are described.  Learners will be able to illustrate data access in terms of the FAIR Principles using companion terms including communications protocol and authentication.  Learners will also be able to interpret the data usage licence associated with different data sets", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-access-q04", "tutorial_id": "topics/fair/tutorials/fair-access", "query": "I want to make my metadata accessible even if my data are no longer available. How can I achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Access", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Data access including levels of access are described.  Learners will be able to illustrate data access in terms of the FAIR Principles using companion terms including communications protocol and authentication.  Learners will also be able to interpret the data usage licence associated with different data sets", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-clinical-q01", "tutorial_id": "topics/fair/tutorials/fair-clinical", "query": "I have a clinical dataset with dates and I want to convert them into time periods for easier analysis. What tools or methods can I use to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Making clinical datasets FAIR", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The life science community is generally very good at sharing omics data on platforms such as [GEO](https://www.ncbi.nlm.nih.gov/geo/) and [ArrayExpress](https://www.ebi.ac.uk/biostudies/arrayexpress).  However, the metadata and clinical data associated with the omics datasets are often incredibly sparse.  Tracking down the meta- and clinical data of omics datasets can be time-consuming for both data owner and researcher and is a significant hurdle when trying to explore enriched omics data.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fair-clinical-q02", "tutorial_id": "topics/fair/tutorials/fair-clinical", "query": "I need to create a data dictionary for my clinical dataset. What are the essential elements that I should include in it?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Making clinical datasets FAIR", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The life science community is generally very good at sharing omics data on platforms such as [GEO](https://www.ncbi.nlm.nih.gov/geo/) and [ArrayExpress](https://www.ebi.ac.uk/biostudies/arrayexpress).  However, the metadata and clinical data associated with the omics datasets are often incredibly sparse.  Tracking down the meta- and clinical data of omics datasets can be time-consuming for both data owner and researcher and is a significant hurdle when trying to explore enriched omics data.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fair-clinical-q03", "tutorial_id": "topics/fair/tutorials/fair-clinical", "query": "I want to make my clinical dataset FAIR (Findable, Accessible, Interoperable, and Reusable). What are the steps I should take to achieve this goal?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Making clinical datasets FAIR", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The life science community is generally very good at sharing omics data on platforms such as [GEO](https://www.ncbi.nlm.nih.gov/geo/) and [ArrayExpress](https://www.ebi.ac.uk/biostudies/arrayexpress).  However, the metadata and clinical data associated with the omics datasets are often incredibly sparse.  Tracking down the meta- and clinical data of omics datasets can be time-consuming for both data owner and researcher and is a significant hurdle when trying to explore enriched omics data.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-clinical-q04", "tutorial_id": "topics/fair/tutorials/fair-clinical", "query": "I have a collection of clinical datasets and I want to manage data access requests efficiently. What are some best practices or tools that I can use to streamline this process?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Making clinical datasets FAIR", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The life science community is generally very good at sharing omics data on platforms such as [GEO](https://www.ncbi.nlm.nih.gov/geo/) and [ArrayExpress](https://www.ebi.ac.uk/biostudies/arrayexpress).  However, the metadata and clinical data associated with the omics datasets are often incredibly sparse.  Tracking down the meta- and clinical data of omics datasets can be time-consuming for both data owner and researcher and is a significant hurdle when trying to explore enriched omics data.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-data-registration-q01", "tutorial_id": "topics/fair/tutorials/fair-data-registration", "query": "I want to deposit my data to Zenodo, but I've never done it before. What steps should I follow?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Data Registration", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The concept of data registration is defined as well as ways in which data registration can be achieved.  Learners will be able to describe why indexed data repositories are important as well as resources enabling you to choose a searchable repository.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fair-data-registration-q02", "tutorial_id": "topics/fair/tutorials/fair-data-registration", "query": "Which data repository would be suitable for storing and sharing my proteomic data?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Data Registration", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The concept of data registration is defined as well as ways in which data registration can be achieved.  Learners will be able to describe why indexed data repositories are important as well as resources enabling you to choose a searchable repository.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fair-data-registration-q03", "tutorial_id": "topics/fair/tutorials/fair-data-registration", "query": "I need to register my dataset with Wikidata. Can you guide me through the process?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Data Registration", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The concept of data registration is defined as well as ways in which data registration can be achieved.  Learners will be able to describe why indexed data repositories are important as well as resources enabling you to choose a searchable repository.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-data-registration-q04", "tutorial_id": "topics/fair/tutorials/fair-data-registration", "query": "What are some useful resources for finding data repositories, standards, and policies for my research data?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Data Registration", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The concept of data registration is defined as well as ways in which data registration can be achieved.  Learners will be able to describe why indexed data repositories are important as well as resources enabling you to choose a searchable repository.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-ena-q01", "tutorial_id": "topics/fair/tutorials/fair-ena", "query": "I have paired-end FASTQ reads from a ChIP-seq experiment and want to assess library quality before alignment. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Sequence data submission to ENA", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "DNA sequencing has become one of the key technologies in molecular biology, with applications in diagnostics, evolutionary biology, drug discovery, forensics and much more. Drop in sequencing costs and breakthroughs in sequencing technologies has seen increasing utilization of sequencing as a research tool, featuring in thousands of life-science publications every year.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "fair-ena-q02", "tutorial_id": "topics/fair/tutorials/fair-ena", "query": "Which tool can I use to calculate the md5 checksum of my FASTQ files for ENA submission?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Sequence data submission to ENA", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "DNA sequencing has become one of the key technologies in molecular biology, with applications in diagnostics, evolutionary biology, drug discovery, forensics and much more. Drop in sequencing costs and breakthroughs in sequencing technologies has seen increasing utilization of sequencing as a research tool, featuring in thousands of life-science publications every year.", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "fair-ena-q03", "tutorial_id": "topics/fair/tutorials/fair-ena", "query": "How do I register a study and obtain a BioProject accession (PRJEB*) and a study accession (ERP*) for ENA submission?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Sequence data submission to ENA", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "DNA sequencing has become one of the key technologies in molecular biology, with applications in diagnostics, evolutionary biology, drug discovery, forensics and much more. Drop in sequencing costs and breakthroughs in sequencing technologies has seen increasing utilization of sequencing as a research tool, featuring in thousands of life-science publications every year.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-ena-q04", "tutorial_id": "topics/fair/tutorials/fair-ena", "query": "What is the recommended method for uploading large numbers of FASTQ files to ENA's FTP server?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Sequence data submission to ENA", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "DNA sequencing has become one of the key technologies in molecular biology, with applications in diagnostics, evolutionary biology, drug discovery, forensics and much more. Drop in sequencing costs and breakthroughs in sequencing technologies has seen increasing utilization of sequencing as a research tool, featuring in thousands of life-science publications every year.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-gtn-q01", "tutorial_id": "topics/fair/tutorials/fair-gtn", "query": "I want to make my training materials FAIR by adding metadata, what tools or formats should I use to describe them properly?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR Galaxy Training Material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Encouraging computational reproducibility in research, we will present a variety of data stewardship recommendations that we have found useful in the process of training development. As part of that process, we are exploring the application of the FAIR (Findable, Accessible, Interoperable, Reusable) guidelines to the Galaxy Training Network (GTN) materials, in order to improve their secondary use and adaptation.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fair-gtn-q02", "tutorial_id": "topics/fair/tutorials/fair-gtn", "query": "How can I assign a unique identity to my training materials to make them easily citable and trackable?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR Galaxy Training Material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Encouraging computational reproducibility in research, we will present a variety of data stewardship recommendations that we have found useful in the process of training development. As part of that process, we are exploring the application of the FAIR (Findable, Accessible, Interoperable, Reusable) guidelines to the Galaxy Training Network (GTN) materials, in order to improve their secondary use and adaptation.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fair-gtn-q03", "tutorial_id": "topics/fair/tutorials/fair-gtn", "query": "What is the best way to ensure my training materials are findable and accessible by others, and what tools can help me achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR Galaxy Training Material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Encouraging computational reproducibility in research, we will present a variety of data stewardship recommendations that we have found useful in the process of training development. As part of that process, we are exploring the application of the FAIR (Findable, Accessible, Interoperable, Reusable) guidelines to the Galaxy Training Network (GTN) materials, in order to improve their secondary use and adaptation.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-gtn-q04", "tutorial_id": "topics/fair/tutorials/fair-gtn", "query": "I want to make my training materials reusable and contribution-friendly, what steps should I take and are there any specific tools or guidelines I should follow?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR Galaxy Training Material", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Encouraging computational reproducibility in research, we will present a variety of data stewardship recommendations that we have found useful in the process of training development. As part of that process, we are exploring the application of the FAIR (Findable, Accessible, Interoperable, Reusable) guidelines to the Galaxy Training Network (GTN) materials, in order to improve their secondary use and adaptation.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-intro-q01", "tutorial_id": "topics/fair/tutorials/fair-intro", "query": "I need to make my dataset FAIR compatible, what tools are required to adopt the 15 guiding principles of FAIR?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR in a nutshell", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The FAIR (Findable, Accessible, Interoperable, Reusable) principles emphasize machine-actionability. The main objective of FAIR is to increase data reuse by researchers. The core concepts of the FAIR principles are based on good scientific practice and intuitively grounded.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fair-intro-q02", "tutorial_id": "topics/fair/tutorials/fair-intro", "query": "How can I ensure that my metadata is accessible and reusable according to the FAIR principles?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR in a nutshell", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The FAIR (Findable, Accessible, Interoperable, Reusable) principles emphasize machine-actionability. The main objective of FAIR is to increase data reuse by researchers. The core concepts of the FAIR principles are based on good scientific practice and intuitively grounded.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fair-intro-q03", "tutorial_id": "topics/fair/tutorials/fair-intro", "query": "What tools can I use to assign globally unique and persistent identifiers to my datasets?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR in a nutshell", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The FAIR (Findable, Accessible, Interoperable, Reusable) principles emphasize machine-actionability. The main objective of FAIR is to increase data reuse by researchers. The core concepts of the FAIR principles are based on good scientific practice and intuitively grounded.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-intro-q04", "tutorial_id": "topics/fair/tutorials/fair-intro", "query": "How can I make my data findable and citable according to the FAIR principles?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR in a nutshell", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The FAIR (Findable, Accessible, Interoperable, Reusable) principles emphasize machine-actionability. The main objective of FAIR is to increase data reuse by researchers. The core concepts of the FAIR principles are based on good scientific practice and intuitively grounded.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-metadata-q01", "tutorial_id": "topics/fair/tutorials/fair-metadata", "query": "I have a spreadsheet with clinical observations for a cohort of patients and I want to make it FAIR compliant. What tools would I need to use to add rich metadata to my dataset?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The term metadata is defined along with what constitutes rich metadata.  Learners will be able to recall examples of community/domain standards that apply to data and metadata.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fair-metadata-q02", "tutorial_id": "topics/fair/tutorials/fair-metadata", "query": "I want to use a community standard ontology to annotate my metadata. How can I find a suitable ontology for my research domain?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The term metadata is defined along with what constitutes rich metadata.  Learners will be able to recall examples of community/domain standards that apply to data and metadata.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fair-metadata-q03", "tutorial_id": "topics/fair/tutorials/fair-metadata", "query": "I have a dataset with disease types and I want to make it machine-readable. How can I use controlled vocabularies and cross-references to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The term metadata is defined along with what constitutes rich metadata.  Learners will be able to recall examples of community/domain standards that apply to data and metadata.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-metadata-q04", "tutorial_id": "topics/fair/tutorials/fair-metadata", "query": "I want to deposit my dataset in a public data repository and make it FAIR compliant. What steps should I take to ensure that my metadata is properly composed and linked?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Metadata", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The term metadata is defined along with what constitutes rich metadata.  Learners will be able to recall examples of community/domain standards that apply to data and metadata.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-origin-q01", "tutorial_id": "topics/fair/tutorials/fair-origin", "query": "I want to make my data FAIR compliant by applying the 15 Guiding Principles, what tools would I need to use to assign a globally unique and persistent identifier to my dataset?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR and its Origins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "FAIR as an acronym, its origins and its guiding principles are introduced.  Learners will be able to explain the difference between FAIR and open data and contextualise the main principles of FAIR around the common characteristics of identifiers, access, metadata and registration.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fair-origin-q02", "tutorial_id": "topics/fair/tutorials/fair-origin", "query": "How can I make my metadata accessible, even when the data are no longer available, and what tools would I need to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR and its Origins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "FAIR as an acronym, its origins and its guiding principles are introduced.  Learners will be able to explain the difference between FAIR and open data and contextualise the main principles of FAIR around the common characteristics of identifiers, access, metadata and registration.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fair-origin-q03", "tutorial_id": "topics/fair/tutorials/fair-origin", "query": "What tools would I need to use to make my data and its metadata findable by humans and computers, and to make rich metadata and keywords available to search engines and data repositories?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR and its Origins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "FAIR as an acronym, its origins and its guiding principles are introduced.  Learners will be able to explain the difference between FAIR and open data and contextualise the main principles of FAIR around the common characteristics of identifiers, access, metadata and registration.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-origin-q04", "tutorial_id": "topics/fair/tutorials/fair-origin", "query": "How can I ensure that my data and metadata are supplied in formats that can be easily used and interpreted by humans and computers, and what tools would I need to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIR and its Origins", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "FAIR as an acronym, its origins and its guiding principles are introduced.  Learners will be able to explain the difference between FAIR and open data and contextualise the main principles of FAIR around the common characteristics of identifiers, access, metadata and registration.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-persistent-identifiers-q01", "tutorial_id": "topics/fair/tutorials/fair-persistent-identifiers", "query": "I want to ensure my dataset has a persistent identifier, what tools or services can I use to create one?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Persistent Identifiers", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The persistent identifier is defined.  Learners will be able to define the structure of an identifier and explain its importance.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fair-persistent-identifiers-q02", "tutorial_id": "topics/fair/tutorials/fair-persistent-identifiers", "query": "How can I construct a persistent identifier for my dataset using a resolver service like identifiers.org?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Persistent Identifiers", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The persistent identifier is defined.  Learners will be able to define the structure of an identifier and explain its importance.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fair-persistent-identifiers-q03", "tutorial_id": "topics/fair/tutorials/fair-persistent-identifiers", "query": "What tool can I use to verify if a persistent identifier is properly formatted and resolvable?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Persistent Identifiers", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The persistent identifier is defined.  Learners will be able to define the structure of an identifier and explain its importance.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fair-persistent-identifiers-q04", "tutorial_id": "topics/fair/tutorials/fair-persistent-identifiers", "query": "I need to ensure that my metadata remains accessible even if the data is no longer available, what steps should I take?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Persistent Identifiers", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The persistent identifier is defined.  Learners will be able to define the structure of an identifier and explain its importance.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fair-rna-q01", "tutorial_id": "topics/fair/tutorials/fair-rna", "query": "I want to assess the quality of my RNA-seq data and check for any potential issues before proceeding with analysis. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIRification of an RNAseq dataset", "datasets": ["E-MTAB-8316"], "dataset_paths": ["E-MTAB-8316"], "dataset_count": 1, "context_summary": "[RNA sequencing](https://en.wikipedia.org/wiki/RNA-Seq) is chosen here as an example of how to FAIRify data for a popular assay in the Life Sciences. RNAseq data can be shared and curated in designated public repositories using established ontologies (and controlled vocabularies) for describing protocols and biological material (metadata).", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "fair-rna-q02", "tutorial_id": "topics/fair/tutorials/fair-rna", "query": "I need to download and re-analyze an RNA-seq dataset from ArrayExpress. How can I access and download the data for further analysis?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIRification of an RNAseq dataset", "datasets": ["E-MTAB-8316"], "dataset_paths": ["E-MTAB-8316"], "dataset_count": 1, "context_summary": "[RNA sequencing](https://en.wikipedia.org/wiki/RNA-Seq) is chosen here as an example of how to FAIRify data for a popular assay in the Life Sciences. RNAseq data can be shared and curated in designated public repositories using established ontologies (and controlled vocabularies) for describing protocols and biological material (metadata).", "priority": 2, "version": "v0", "query_type": "science_first"}}
{"id": "fair-rna-q03", "tutorial_id": "topics/fair/tutorials/fair-rna", "query": "Which tool can I use to download and extract metadata from an RNA-seq dataset in ArrayExpress?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIRification of an RNAseq dataset", "datasets": ["E-MTAB-8316"], "dataset_paths": ["E-MTAB-8316"], "dataset_count": 1, "context_summary": "[RNA sequencing](https://en.wikipedia.org/wiki/RNA-Seq) is chosen here as an example of how to FAIRify data for a popular assay in the Life Sciences. RNAseq data can be shared and curated in designated public repositories using established ontologies (and controlled vocabularies) for describing protocols and biological material (metadata).", "priority": 3, "version": "v0", "query_type": "tool_first"}}
{"id": "fair-rna-q04", "tutorial_id": "topics/fair/tutorials/fair-rna", "query": "How can I use a tool to automate the process of checking the quality of RNA-seq data and generating reports?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "FAIRification of an RNAseq dataset", "datasets": ["E-MTAB-8316"], "dataset_paths": ["E-MTAB-8316"], "dataset_count": 1, "context_summary": "[RNA sequencing](https://en.wikipedia.org/wiki/RNA-Seq) is chosen here as an example of how to FAIRify data for a popular assay in the Life Sciences. RNAseq data can be shared and curated in designated public repositories using established ontologies (and controlled vocabularies) for describing protocols and biological material (metadata).", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "inveniordm-integration-q01", "tutorial_id": "topics/fair/tutorials/inveniordm-integration", "query": "I want to export my Galaxy history to Zenodo, but I'm not sure which tool I need to use. Can someone help me?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Integrating InvenioRDM-compatible Repositories with Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Overview", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "inveniordm-integration-q02", "tutorial_id": "topics/fair/tutorials/inveniordm-integration", "query": "How do I integrate my institution's InvenioRDM repository with Galaxy so I can import and export files?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Integrating InvenioRDM-compatible Repositories with Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Overview", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "inveniordm-integration-q03", "tutorial_id": "topics/fair/tutorials/inveniordm-integration", "query": "What tool do I need to use to import files from Zenodo into Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Integrating InvenioRDM-compatible Repositories with Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Overview", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "inveniordm-integration-q04", "tutorial_id": "topics/fair/tutorials/inveniordm-integration", "query": "I want to publish my Galaxy history on Zenodo and get a DOI, but I'm not sure how to do it. Can someone walk me through the steps?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Integrating InvenioRDM-compatible Repositories with Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Overview", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-galaxy-best-practices-q01", "tutorial_id": "topics/fair/tutorials/ro-crate-galaxy-best-practices", "query": "I want to generate a test layout for my Galaxy workflow using Planemo. What tools do I need to install?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Best practices for workflows in GitHub repositories", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "A workflow, just like any other piece of software, can be formally correct and runnable but still lack a number of additional features that might help its reusability, interoperability, understandability, etc.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-galaxy-best-practices-q02", "tutorial_id": "topics/fair/tutorials/ro-crate-galaxy-best-practices", "query": "How can I create a GitHub workflow to test my Galaxy workflow automatically?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Best practices for workflows in GitHub repositories", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "A workflow, just like any other piece of software, can be formally correct and runnable but still lack a number of additional features that might help its reusability, interoperability, understandability, etc.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-galaxy-best-practices-q03", "tutorial_id": "topics/fair/tutorials/ro-crate-galaxy-best-practices", "query": "What tool can I use to generate a Workflow Testing RO-Crate for my workflow repository?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Best practices for workflows in GitHub repositories", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "A workflow, just like any other piece of software, can be formally correct and runnable but still lack a number of additional features that might help its reusability, interoperability, understandability, etc.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-galaxy-best-practices-q04", "tutorial_id": "topics/fair/tutorials/ro-crate-galaxy-best-practices", "query": "How do I apply best practices for workflow structure to my existing Galaxy workflow?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Best practices for workflows in GitHub repositories", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "A workflow, just like any other piece of software, can be formally correct and runnable but still lack a number of additional features that might help its reusability, interoperability, understandability, etc.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-in-galaxy-q01", "tutorial_id": "topics/fair/tutorials/ro-crate-in-galaxy", "query": "I want to update my Galaxy configuration to enable RO-Crate export. What changes do I need to make to my galaxy.yml file?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Exporting Workflow Run RO-Crates from Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Workflows are a powerful Galaxy feature that allows you to scale up your analysis by performing an end-to-end analysis with a single click of a button. In order to keep provenance of the workflow invocation (an invocation of a workflow means one run or execution of the workflow) it can be exported from Galaxy in the form of a [Workflow Run Crate](https://w3id.org/ro/wfrun/workflow) RO-Crate profile.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-in-galaxy-q02", "tutorial_id": "topics/fair/tutorials/ro-crate-in-galaxy", "query": "How do I export a Workflow Run Crate from Galaxy after running a workflow?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Exporting Workflow Run RO-Crates from Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Workflows are a powerful Galaxy feature that allows you to scale up your analysis by performing an end-to-end analysis with a single click of a button. In order to keep provenance of the workflow invocation (an invocation of a workflow means one run or execution of the workflow) it can be exported from Galaxy in the form of a [Workflow Run Crate](https://w3id.org/ro/wfrun/workflow) RO-Crate profile.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-in-galaxy-q03", "tutorial_id": "topics/fair/tutorials/ro-crate-in-galaxy", "query": "What should I do to enable celery tasks in my Galaxy configuration for RO-Crate export?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Exporting Workflow Run RO-Crates from Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Workflows are a powerful Galaxy feature that allows you to scale up your analysis by performing an end-to-end analysis with a single click of a button. In order to keep provenance of the workflow invocation (an invocation of a workflow means one run or execution of the workflow) it can be exported from Galaxy in the form of a [Workflow Run Crate](https://w3id.org/ro/wfrun/workflow) RO-Crate profile.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-in-galaxy-q04", "tutorial_id": "topics/fair/tutorials/ro-crate-in-galaxy", "query": "How can I access the export options for a workflow run in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Exporting Workflow Run RO-Crates from Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Workflows are a powerful Galaxy feature that allows you to scale up your analysis by performing an end-to-end analysis with a single click of a button. In order to keep provenance of the workflow invocation (an invocation of a workflow means one run or execution of the workflow) it can be exported from Galaxy in the form of a [Workflow Run Crate](https://w3id.org/ro/wfrun/workflow) RO-Crate profile.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-in-python-q01", "tutorial_id": "topics/fair/tutorials/ro-crate-in-python", "query": "I want to create an RO-Crate to represent my research project. What tools would I need to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "RO-Crate in Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will show you how to manipulate [RO-Crates](https://w3id.org/ro/crate/) in Python using the [ro-crate-py](https://github.com/ResearchObject/ro-crate-py) package. It is based on the [ro-crate-py documentation](https://github.com/ResearchObject/ro-crate-py/blob/e1218fbca595f4c33059cfe15849ee2ae9e6896b/README.md).", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-in-python-q02", "tutorial_id": "topics/fair/tutorials/ro-crate-in-python", "query": "How can I add a file to an existing RO-Crate using the ro-crate-py library?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "RO-Crate in Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will show you how to manipulate [RO-Crates](https://w3id.org/ro/crate/) in Python using the [ro-crate-py](https://github.com/ResearchObject/ro-crate-py) package. It is based on the [ro-crate-py documentation](https://github.com/ResearchObject/ro-crate-py/blob/e1218fbca595f4c33059cfe15849ee2ae9e6896b/README.md).", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-in-python-q03", "tutorial_id": "topics/fair/tutorials/ro-crate-in-python", "query": "What tools are required to initialize a directory tree as an RO-Crate?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "RO-Crate in Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will show you how to manipulate [RO-Crates](https://w3id.org/ro/crate/) in Python using the [ro-crate-py](https://github.com/ResearchObject/ro-crate-py) package. It is based on the [ro-crate-py documentation](https://github.com/ResearchObject/ro-crate-py/blob/e1218fbca595f4c33059cfe15849ee2ae9e6896b/README.md).", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-in-python-q04", "tutorial_id": "topics/fair/tutorials/ro-crate-in-python", "query": "How can I add a remote file to an RO-Crate using the ro-crate-py library?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "RO-Crate in Python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial will show you how to manipulate [RO-Crates](https://w3id.org/ro/crate/) in Python using the [ro-crate-py](https://github.com/ResearchObject/ro-crate-py) package. It is based on the [ro-crate-py documentation](https://github.com/ResearchObject/ro-crate-py/blob/e1218fbca595f4c33059cfe15849ee2ae9e6896b/README.md).", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-intro-q01", "tutorial_id": "topics/fair/tutorials/ro-crate-intro", "query": "What tool can I use to validate and visualize the RO-Crate Metadata File?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "RO-Crate - Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial assumes you have already completed [An overview of the RO-Crate concept and its implementations](https://gallantries.github.io/video-library/videos/ro-crates/intro/slides/) and have a basic understanding of working with JSON.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-intro-q02", "tutorial_id": "topics/fair/tutorials/ro-crate-intro", "query": "How can I generate an HTML preview of my RO-Crate?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "RO-Crate - Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial assumes you have already completed [An overview of the RO-Crate concept and its implementations](https://gallantries.github.io/video-library/videos/ro-crates/intro/slides/) and have a basic understanding of working with JSON.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-intro-q03", "tutorial_id": "topics/fair/tutorials/ro-crate-intro", "query": "What are the required properties for the RO-Crate Root entity?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "RO-Crate - Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial assumes you have already completed [An overview of the RO-Crate concept and its implementations](https://gallantries.github.io/video-library/videos/ro-crates/intro/slides/) and have a basic understanding of working with JSON.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-intro-q04", "tutorial_id": "topics/fair/tutorials/ro-crate-intro", "query": "How can be I add authors to my RO-Crate?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "RO-Crate - Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This tutorial assumes you have already completed [An overview of the RO-Crate concept and its implementations](https://gallantries.github.io/video-library/videos/ro-crates/intro/slides/) and have a basic understanding of working with JSON.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-submitting-life-monitor-q01", "tutorial_id": "topics/fair/tutorials/ro-crate-submitting-life-monitor", "query": "I have a Galaxy workflow and I want to monitor its tests and register new releases with LifeMonitor. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Submitting workflows to LifeMonitor", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[{LM}](https://www.lifemonitor.eu/) is a service to support the", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-submitting-life-monitor-q02", "tutorial_id": "topics/fair/tutorials/ro-crate-submitting-life-monitor", "query": "How can I configure LifeMonitor to send me email notifications when my workflow tests fail or when a new release is registered?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Submitting workflows to LifeMonitor", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[{LM}](https://www.lifemonitor.eu/) is a service to support the", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-submitting-life-monitor-q03", "tutorial_id": "topics/fair/tutorials/ro-crate-submitting-life-monitor", "query": "What tools are required to create a GitHub Actions workflow to automatically run tests for my Galaxy workflow?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Submitting workflows to LifeMonitor", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[{LM}](https://www.lifemonitor.eu/) is a service to support the", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-submitting-life-monitor-q04", "tutorial_id": "topics/fair/tutorials/ro-crate-submitting-life-monitor", "query": "How can I use LifeMonitor to automate the generation of RO-Crate metadata for my Galaxy workflow and register it with WorkflowHub?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Submitting workflows to LifeMonitor", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "[{LM}](https://www.lifemonitor.eu/) is a service to support the", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-workflow-run-ro-crate-q01", "tutorial_id": "topics/fair/tutorials/ro-crate-workflow-run-ro-crate", "query": "I want to create a git repo and begin working with it as mentioned in the Workflow Run RO-Crate tutorial. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Workflow Run RO-Crate Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The [Workflow Run RO-Crate](https://www.researchobject.org/workflow-run-crate/) working group is developing a series of [RO-Crate profiles](https://www.researchobject.org/ro-crate/profiles.html) for representing the provenance of computational workflow executions. The set includes three profiles, which represent provenance with increasing level of detail:", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-workflow-run-ro-crate-q02", "tutorial_id": "topics/fair/tutorials/ro-crate-workflow-run-ro-crate", "query": "How can I export a Galaxy workflow invocation as a Workflow Run Crate as mentioned in the Workflow Run RO-Crate tutorial?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Workflow Run RO-Crate Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The [Workflow Run RO-Crate](https://www.researchobject.org/workflow-run-crate/) working group is developing a series of [RO-Crate profiles](https://www.researchobject.org/ro-crate/profiles.html) for representing the provenance of computational workflow executions. The set includes three profiles, which represent provenance with increasing level of detail:", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-workflow-run-ro-crate-q03", "tutorial_id": "topics/fair/tutorials/ro-crate-workflow-run-ro-crate", "query": "What tool can I use to run a bash script like head_tail.sh in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Workflow Run RO-Crate Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The [Workflow Run RO-Crate](https://www.researchobject.org/workflow-run-crate/) working group is developing a series of [RO-Crate profiles](https://www.researchobject.org/ro-crate/profiles.html) for representing the provenance of computational workflow executions. The set includes three profiles, which represent provenance with increasing level of detail:", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "ro-crate-workflow-run-ro-crate-q04", "tutorial_id": "topics/fair/tutorials/ro-crate-workflow-run-ro-crate", "query": "How can I generate a RO-Crate for a workflow run in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Workflow Run RO-Crate Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "The [Workflow Run RO-Crate](https://www.researchobject.org/workflow-run-crate/) working group is developing a series of [RO-Crate profiles](https://www.researchobject.org/ro-crate/profiles.html) for representing the provenance of computational workflow executions. The set includes three profiles, which represent provenance with increasing level of detail:", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "zenodo-in-galaxy-q01", "tutorial_id": "topics/fair/tutorials/zenodo-in-galaxy", "query": "I want to export my Galaxy history to Zenodo, but I'm not sure which tools I need to use. Can you help me?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Uploading Data to Zenodo from Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Discover a more streamlined approach to research data management with Galaxy's integration with Zenodo.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "zenodo-in-galaxy-q02", "tutorial_id": "topics/fair/tutorials/zenodo-in-galaxy", "query": "How do I connect my Zenodo account to Galaxy so I can import and export files?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Uploading Data to Zenodo from Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Discover a more streamlined approach to research data management with Galaxy's integration with Zenodo.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "zenodo-in-galaxy-q03", "tutorial_id": "topics/fair/tutorials/zenodo-in-galaxy", "query": "What tools are required to import records and files from Zenodo into Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Uploading Data to Zenodo from Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Discover a more streamlined approach to research data management with Galaxy's integration with Zenodo.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "zenodo-in-galaxy-q04", "tutorial_id": "topics/fair/tutorials/zenodo-in-galaxy", "query": "How can I export my Galaxy history as a DOI citable record on Zenodo?", "tools": [], "workflows": [], "metadata": {"topic": "fair", "tutorial_title": "Uploading Data to Zenodo from Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Discover a more streamlined approach to research data management with Galaxy's integration with Zenodo.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "apollo-euk-q01", "tutorial_id": "topics/genome-annotation/tutorials/apollo-euk", "query": "I have a genome sequence in FASTA format ([genome.fasta]) and I want to visualize it along with some evidence tracks like RNA-Seq data ([rnaseq.bam]) and gene predictions ([annotation.gff3]). Which Galaxy tool should I use to create a JBrowse instance for this?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Refining Genome Annotations with Apollo (eukaryotes)", "datasets": ["genome.fasta", "rnaseq.bam", "annotation.gff3"], "dataset_paths": ["genome.fasta", "rnaseq.bam", "annotation.gff3"], "dataset_count": 3, "context_summary": "After automatically annotating your genome using [Funannotate](../funannotate/tutorial.html) or [Maker](../annotation-with-maker/tutorial.html) for example, it is important to visualize your results so you can understand what your organism looks like, and then to manually refine these annotations along with any additional data you might have. This process is most often done as part of a group, smaller organisms may be annotated individually though.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "apollo-euk-q02", "tutorial_id": "topics/genome-annotation/tutorials/apollo-euk", "query": "I have created a JBrowse instance with my genome sequence and evidence tracks, and I want to load it into Apollo to make manual annotations. What tool can I use in Galaxy to import this data into Apollo?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Refining Genome Annotations with Apollo (eukaryotes)", "datasets": ["https://zenodo.org/record/6920962"], "dataset_paths": ["https://zenodo.org/record/6920962"], "dataset_count": 1, "context_summary": "After automatically annotating your genome using [Funannotate](../funannotate/tutorial.html) or [Maker](../annotation-with-maker/tutorial.html) for example, it is important to visualize your results so you can understand what your organism looks like, and then to manually refine these annotations along with any additional data you might have. This process is most often done as part of a group, smaller organisms may be annotated individually though.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "apollo-euk-q03", "tutorial_id": "topics/genome-annotation/tutorials/apollo-euk", "query": "How can I edit the structure of a gene predicted by Funannotate in Apollo? Specifically, I want to add a 5' untranslated region and change the start codon.", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Refining Genome Annotations with Apollo (eukaryotes)", "datasets": ["https://zenodo.org/record/6920962"], "dataset_paths": ["https://zenodo.org/record/6920962"], "dataset_count": 1, "context_summary": "After automatically annotating your genome using [Funannotate](../funannotate/tutorial.html) or [Maker](../annotation-with-maker/tutorial.html) for example, it is important to visualize your results so you can understand what your organism looks like, and then to manually refine these annotations along with any additional data you might have. This process is most often done as part of a group, smaller organisms may be annotated individually though.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "apollo-euk-q04", "tutorial_id": "topics/genome-annotation/tutorials/apollo-euk", "query": "I have made some manual annotations in Apollo and I want to export them in a standard format like GFF3. How can I do this in Apollo?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Refining Genome Annotations with Apollo (eukaryotes)", "datasets": ["https://zenodo.org/record/6920962"], "dataset_paths": ["https://zenodo.org/record/6920962"], "dataset_count": 1, "context_summary": "After automatically annotating your genome using [Funannotate](../funannotate/tutorial.html) or [Maker](../annotation-with-maker/tutorial.html) for example, it is important to visualize your results so you can understand what your organism looks like, and then to manually refine these annotations along with any additional data you might have. This process is most often done as part of a group, smaller organisms may be annotated individually though.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bacterial-comparative-genomics-dataset-construction-q01", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-comparative-genomics-dataset-construction", "query": "I have a list of NCBI Assembly accessions and I want to download the corresponding genomes from NCBI. What tool should I use in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Dataset construction for bacterial comparative genomics", "datasets": ["https://zenodo.org/records/1"], "dataset_paths": ["https://zenodo.org/records/1"], "dataset_count": 1, "context_summary": "Introduction", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bacterial-comparative-genomics-dataset-construction-q02", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-comparative-genomics-dataset-construction", "query": "How can I extract IDs from a dataset in Galaxy for use in a subsequent analysis?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Dataset construction for bacterial comparative genomics", "datasets": ["https://zenodo.org/records/1"], "dataset_paths": ["https://zenodo.org/records/1"], "dataset_count": 1, "context_summary": "Introduction", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bacterial-comparative-genomics-dataset-construction-q03", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-comparative-genomics-dataset-construction", "query": "Which Galaxy tool can I use to sort a dataset by a specific column?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Dataset construction for bacterial comparative genomics", "datasets": ["https://zenodo.org/records/1"], "dataset_paths": ["https://zenodo.org/records/1"], "dataset_count": 1, "context_summary": "Introduction", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bacterial-comparative-genomics-dataset-construction-q04", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-comparative-genomics-dataset-construction", "query": "I have a FASTA file and I want to remove the first two lines from it in Galaxy. What tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Dataset construction for bacterial comparative genomics", "datasets": ["https://zenodo.org/records/1"], "dataset_paths": ["https://zenodo.org/records/1"], "dataset_count": 1, "context_summary": "Introduction", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bacterial-genome-quality-control-q01", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-genome-quality-control", "query": "I have a contig file from a bacterial genome sequencing experiment and I want to assess its quality. Which Galaxy tool should I use to perform quality control?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Bacterial genome quality control", "datasets": ["DRR187559_contigs.fasta"], "dataset_paths": ["DRR187559_contigs.fasta"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bacterial-genome-quality-control-q02", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-genome-quality-control", "query": "How can I dereplicate a collection of bacterial genomes in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Bacterial genome quality control", "datasets": ["output"], "dataset_paths": ["output"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bacterial-genome-quality-control-q03", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-genome-quality-control", "query": "Which Galaxy tool is suitable for checking the quality of a bacterial genome assembly?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Bacterial genome quality control", "datasets": ["DRR187559_contigs.fasta"], "dataset_paths": ["DRR187559_contigs.fasta"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bacterial-genome-quality-control-q04", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-genome-quality-control", "query": "I have a collection of bacterial genomes and I want to remove duplicates. What steps should I follow in Galaxy to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Bacterial genome quality control", "datasets": ["output"], "dataset_paths": ["output"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bacterial-pangenomics-q01", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-pangenomics", "query": "I have a set of contig files and want to perform pangenomics analysis. What tools should I use to prepare my data and run the analysis?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Bacterial pangenomics", "datasets": ["DRR187559_contigs.fasta"], "dataset_paths": ["DRR187559_contigs.fasta"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bacterial-pangenomics-q02", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-pangenomics", "query": "How can I perform a multi-sequence alignment on a pangenome h5 file in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Bacterial pangenomics", "datasets": ["pangenome_h5"], "dataset_paths": ["pangenome_h5"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bacterial-pangenomics-q03", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-pangenomics", "query": "Which Galaxy tool should I use to run PPanGGOLiN all on my input dataset collection?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Bacterial pangenomics", "datasets": ["Input dataset collection"], "dataset_paths": ["Input dataset collection"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bacterial-pangenomics-q04", "tutorial_id": "topics/genome-annotation/tutorials/bacterial-pangenomics", "query": "How can I use Galaxy to generate a multi-sequence alignment from a pangenome h5 file with a specific partition?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Bacterial pangenomics", "datasets": ["pangenome_h5"], "dataset_paths": ["pangenome_h5"], "dataset_count": 1, "context_summary": "General introduction about the topic and then an introduction of the", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "genome-annotation-q01", "tutorial_id": "topics/genome-annotation/tutorials/genome-annotation", "query": "I have a genome sequence in FASTA format and want to predict genes. What tool should I use for gene prediction in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Genome Annotation", "datasets": ["Aspergillus_sequence.fasta"], "dataset_paths": ["Aspergillus_sequence.fasta"], "dataset_count": 1, "context_summary": "Genome annotation is the process of attaching biological information to sequences.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "genome-annotation-q02", "tutorial_id": "topics/genome-annotation/tutorials/genome-annotation", "query": "How can I perform a similarity search for my protein sequences against the SwissProt database in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Genome Annotation", "datasets": ["protein sequences"], "dataset_paths": ["protein sequences"], "dataset_count": 1, "context_summary": "Genome annotation is the process of attaching biological information to sequences.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "genome-annotation-q03", "tutorial_id": "topics/genome-annotation/tutorials/genome-annotation", "query": "Which tool can I use to identify gene clusters in a genome sequence in genbank format?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Genome Annotation", "datasets": ["Streptomyces_coelicolor_part.genbank"], "dataset_paths": ["Streptomyces_coelicolor_part.genbank"], "dataset_count": 1, "context_summary": "Genome annotation is the process of attaching biological information to sequences.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "genome-annotation-q04", "tutorial_id": "topics/genome-annotation/tutorials/genome-annotation", "query": "I have a set of protein sequences and want to find similar proteins in a database. How can I filter the BLAST results to get only the best hit for each protein in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Genome Annotation", "datasets": ["protein sequences"], "dataset_paths": ["protein sequences"], "dataset_count": 1, "context_summary": "Genome annotation is the process of attaching biological information to sequences.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "official-gene-set-q01", "tutorial_id": "topics/genome-annotation/tutorials/official-gene-set", "query": "I have a GFF file containing gene annotations and I want to merge it with an automatic annotation in Galaxy. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Creating an Official Gene Set", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here's how we manage annotations at BIPAA:", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "official-gene-set-q02", "tutorial_id": "topics/genome-annotation/tutorials/official-gene-set", "query": "How can I convert a GFF file to EMBL format for submission to ENA in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Creating an Official Gene Set", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here's how we manage annotations at BIPAA:", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "official-gene-set-q03", "tutorial_id": "topics/genome-annotation/tutorials/official-gene-set", "query": "Which Galaxy tool can I use to perform automatic gene annotation with Maker?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Creating an Official Gene Set", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here's how we manage annotations at BIPAA:", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "official-gene-set-q04", "tutorial_id": "topics/genome-annotation/tutorials/official-gene-set", "query": "I have a set of annotated genes in Apollo and I want to generate an official gene set (OGS) by merging them with an automatic annotation. What is the recommended workflow in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "genome-annotation", "tutorial_title": "Creating an Official Gene Set", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Here's how we manage annotations at BIPAA:", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "omero-suite-q01", "tutorial_id": "topics/imaging/tutorials/omero-suite", "query": "I have images and metadata that I want to upload to OMERO using Galaxy. Which tools should I use to accomplish this task?", "tools": [], "workflows": [], "metadata": {"topic": "imaging", "tutorial_title": "Overview of the Galaxy OMERO-suite - Upload images and metadata in OMERO using Galaxy", "datasets": ["14205500"], "dataset_paths": ["14205500"], "dataset_count": 1, "context_summary": "The efficient and accurate treatment of microscopy metadata is of great importance, as it", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "omero-suite-q02", "tutorial_id": "topics/imaging/tutorials/omero-suite", "query": "How can I upload images, metadata, and regions of interest (ROIs) into OMERO using Galaxy, and then filter OMERO objects based on filename, tags, and Key-Value Pairs?", "tools": [], "workflows": [], "metadata": {"topic": "imaging", "tutorial_title": "Overview of the Galaxy OMERO-suite - Upload images and metadata in OMERO using Galaxy", "datasets": ["14205500"], "dataset_paths": ["14205500"], "dataset_count": 1, "context_summary": "The efficient and accurate treatment of microscopy metadata is of great importance, as it", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "omero-suite-q03", "tutorial_id": "topics/imaging/tutorials/omero-suite", "query": "What tools are required to upload images into OMERO and then annotate them with regions of interest (ROIs) using Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "imaging", "tutorial_title": "Overview of the Galaxy OMERO-suite - Upload images and metadata in OMERO using Galaxy", "datasets": ["14205500"], "dataset_paths": ["14205500"], "dataset_count": 1, "context_summary": "The efficient and accurate treatment of microscopy metadata is of great importance, as it", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "omero-suite-q04", "tutorial_id": "topics/imaging/tutorials/omero-suite", "query": "How can I build a workflow in Galaxy to integrate the upload of images, metadata, and ROIs into OMERO, and then retrieve image IDs and annotations?", "tools": [], "workflows": [], "metadata": {"topic": "imaging", "tutorial_title": "Overview of the Galaxy OMERO-suite - Upload images and metadata in OMERO using Galaxy", "datasets": ["14205500"], "dataset_paths": ["14205500"], "dataset_count": 1, "context_summary": "The efficient and accurate treatment of microscopy metadata is of great importance, as it", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "dummy-q01", "tutorial_id": "topics/introduction/tutorials/dummy", "query": "I want to upload a file to Galaxy from my computer. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Upload data to Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "There are several ways to get data into Galaxy:", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "dummy-q02", "tutorial_id": "topics/introduction/tutorials/dummy", "query": "Which method should I use to upload a large number of files to Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Upload data to Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "There are several ways to get data into Galaxy:", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "dummy-q03", "tutorial_id": "topics/introduction/tutorials/dummy", "query": "How can I import data into Galaxy from a shared library?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Upload data to Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "There are several ways to get data into Galaxy:", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "dummy-q04", "tutorial_id": "topics/introduction/tutorials/dummy", "query": "I have a URL of a file I want to upload to Galaxy. What is the easiest way to do this?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Upload data to Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "There are several ways to get data into Galaxy:", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "galaxy-cite-q01", "tutorial_id": "topics/introduction/tutorials/galaxy-cite", "query": "I have a Galaxy history with several datasets and tools used for analysis. How can I extract a list of tool citations from this history?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Best Practices for Citing Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Overview", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "galaxy-cite-q02", "tutorial_id": "topics/introduction/tutorials/galaxy-cite", "query": "I want to make my Galaxy history public and citable by exporting it to Zenodo. What steps should I follow?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Best Practices for Citing Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Overview", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "galaxy-cite-q03", "tutorial_id": "topics/introduction/tutorials/galaxy-cite", "query": "Which tool or method can I use to automatically create a workflow based on the analysis I have performed in a Galaxy history?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Best Practices for Citing Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Overview", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "galaxy-cite-q04", "tutorial_id": "topics/introduction/tutorials/galaxy-cite", "query": "How can I share my Galaxy history with others so they can import and access the datasets, parameters, and steps of my history?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Best Practices for Citing Galaxy", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Overview", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "igv-introduction-q01", "tutorial_id": "topics/introduction/tutorials/igv-introduction", "query": "I want to load a genome into IGV from a URL, what tool or option should I use?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "IGV Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Using the Integrative Genomics Viewer", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "igv-introduction-q02", "tutorial_id": "topics/introduction/tutorials/igv-introduction", "query": "How can I save a snapshot of the IGV window to a graphics file?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "IGV Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Using the Integrative Genomics Viewer", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "igv-introduction-q03", "tutorial_id": "topics/introduction/tutorials/igv-introduction", "query": "I have a BED file with regions of interest and I want to take multiple images from these regions in IGV. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "IGV Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Using the Integrative Genomics Viewer", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "igv-introduction-q04", "tutorial_id": "topics/introduction/tutorials/igv-introduction", "query": "How can I change the track colors, name and chart type (line, bar, heatmap) for a track in IGV?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "IGV Introduction", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Using the Integrative Genomics Viewer", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "vsi_qc-q01", "tutorial_id": "topics/introduction/tutorials/vsi_qc", "query": "I have paired-end FASTQ reads from a ChIP-seq experiment (M117-bl_1.fq.gz, M117-bl_2.fq.gz); want to assess library quality before alignment. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Very Short Introductions: QC", "datasets": ["M117-bl_1.fq.gz", "M117-bl_2.fq.gz"], "dataset_paths": ["M117-bl_1.fq.gz", "M117-bl_2.fq.gz"], "dataset_count": 2, "context_summary": "In this tutorial we will look at assessing quality of data from two short read technologies: [Illumina](http://www.nature.com/doifinder/10.1038/nature07517) and [Element Biosciences](http://dx.doi.org/10.1038/s41587-023-01750-7).", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "vsi_qc-q02", "tutorial_id": "topics/introduction/tutorials/vsi_qc", "query": "Which Galaxy tool should I use to assess read quality for elem_s1_r1.fq.gz and elem_s1_r2.fq.gz?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Very Short Introductions: QC", "datasets": ["elem_s1_r1.fq.gz", "elem_s1_r2.fq.gz"], "dataset_paths": ["elem_s1_r1.fq.gz", "elem_s1_r2.fq.gz"], "dataset_count": 2, "context_summary": "In this tutorial we will look at assessing quality of data from two short read technologies: [Illumina](http://www.nature.com/doifinder/10.1038/nature07517) and [Element Biosciences](http://dx.doi.org/10.1038/s41587-023-01750-7).", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "vsi_qc-q03", "tutorial_id": "topics/introduction/tutorials/vsi_qc", "query": "My single-cell FASTQ files (elem_s1_r1.fq.gz, elem_s1_r2.fq.gz) show variable read quality; how can I clean them for downstream analysis?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Very Short Introductions: QC", "datasets": ["elem_s1_r1.fq.gz", "elem_s1_r2.fq.gz"], "dataset_paths": ["elem_s1_r1.fq.gz", "elem_s1_r2.fq.gz"], "dataset_count": 2, "context_summary": "In this tutorial we will look at assessing quality of data from two short read technologies: [Illumina](http://www.nature.com/doifinder/10.1038/nature07517) and [Element Biosciences](http://dx.doi.org/10.1038/s41587-023-01750-7).", "priority": 3, "version": "v0", "query_type": "science_first"}}
{"id": "vsi_qc-q04", "tutorial_id": "topics/introduction/tutorials/vsi_qc", "query": "How can I trim adapters and low-quality bases on M117-bl_1.fq.gz and M117-bl_2.fq.gz in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "introduction", "tutorial_title": "Very Short Introductions: QC", "datasets": ["M117-bl_1.fq.gz", "M117-bl_2.fq.gz"], "dataset_paths": ["M117-bl_1.fq.gz", "M117-bl_2.fq.gz"], "dataset_count": 2, "context_summary": "In this tutorial we will look at assessing quality of data from two short read technologies: [Illumina](http://www.nature.com/doifinder/10.1038/nature07517) and [Element Biosciences](http://dx.doi.org/10.1038/s41587-023-01750-7).", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "gcms-q01", "tutorial_id": "topics/metabolomics/tutorials/gcms", "query": "I have GC-MS data and want to detect peaks using XCMS. What tools would be needed for this task?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: GC-MS analysis with the metaMS package", "datasets": ["alg11.mzML", "alg2.mzML", "alg3.mzML", "alg7.mzML", "alg8.mzML", "alg9.mzML"], "dataset_paths": ["alg11.mzML", "alg2.mzML", "alg3.mzML", "alg7.mzML", "alg8.mzML", "alg9.mzML"], "dataset_count": 6, "context_summary": "You may already know that there are different types of *-omic* sciences; out of these, metabolomics is most closely related to phenotypes. Metabolomics involves the study of different types of matrices, such as blood, urine, tissues, in various organisms including plants. It  focuses on studying the very small molecules which are called *metabolites*, to better understand matters linked to the metabolism. However, studying metabolites is not a piece of cake since it requires several critical steps which still have some major bottlenecks. Metabolomics is still quite a young science, and has many kinds of specific challenges.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "gcms-q02", "tutorial_id": "topics/metabolomics/tutorials/gcms", "query": "I have GC-MS data and want to perform peak deconvolution and alignment using metaMS. What tools would be needed for this task?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: GC-MS analysis with the metaMS package", "datasets": ["xset.merged.RData", "reference_alkanes.csv", "W4M0004_database_small.msp"], "dataset_paths": ["xset.merged.RData", "reference_alkanes.csv", "W4M0004_database_small.msp"], "dataset_count": 3, "context_summary": "You may already know that there are different types of *-omic* sciences; out of these, metabolomics is most closely related to phenotypes. Metabolomics involves the study of different types of matrices, such as blood, urine, tissues, in various organisms including plants. It  focuses on studying the very small molecules which are called *metabolites*, to better understand matters linked to the metabolism. However, studying metabolites is not a piece of cake since it requires several critical steps which still have some major bottlenecks. Metabolomics is still quite a young science, and has many kinds of specific challenges.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "gcms-q03", "tutorial_id": "topics/metabolomics/tutorials/gcms", "query": "How can I create a dataset collection for my GC-MS data in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: GC-MS analysis with the metaMS package", "datasets": ["alg11.mzML", "alg2.mzML", "alg3.mzML", "alg7.mzML", "alg8.mzML", "alg9.mzML"], "dataset_paths": ["alg11.mzML", "alg2.mzML", "alg3.mzML", "alg7.mzML", "alg8.mzML", "alg9.mzML"], "dataset_count": 6, "context_summary": "You may already know that there are different types of *-omic* sciences; out of these, metabolomics is most closely related to phenotypes. Metabolomics involves the study of different types of matrices, such as blood, urine, tissues, in various organisms including plants. It  focuses on studying the very small molecules which are called *metabolites*, to better understand matters linked to the metabolism. However, studying metabolites is not a piece of cake since it requires several critical steps which still have some major bottlenecks. Metabolomics is still quite a young science, and has many kinds of specific challenges.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "gcms-q04", "tutorial_id": "topics/metabolomics/tutorials/gcms", "query": "How can I export the MSP file for further investigation after processing with metaMS?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: GC-MS analysis with the metaMS package", "datasets": ["peaktable.tsv", "W4M0004_database_small.msp"], "dataset_paths": ["peaktable.tsv", "W4M0004_database_small.msp"], "dataset_count": 2, "context_summary": "You may already know that there are different types of *-omic* sciences; out of these, metabolomics is most closely related to phenotypes. Metabolomics involves the study of different types of matrices, such as blood, urine, tissues, in various organisms including plants. It  focuses on studying the very small molecules which are called *metabolites*, to better understand matters linked to the metabolism. However, studying metabolites is not a piece of cake since it requires several critical steps which still have some major bottlenecks. Metabolomics is still quite a young science, and has many kinds of specific challenges.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "lcms-dataprocessing-q01", "tutorial_id": "topics/metabolomics/tutorials/lcms-dataprocessing", "query": "I have a dataset with ions and their intensities, want to exclude ions found at specific retention time ranges. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: LC-MS data processing", "datasets": ["Dataprocessing_dataMatrix.txt"], "dataset_paths": ["Dataprocessing_dataMatrix.txt"], "dataset_count": 1, "context_summary": "Metabolomics is a *-omic* science known for being one of the most closely related to phenotypes.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "lcms-dataprocessing-q02", "tutorial_id": "topics/metabolomics/tutorials/lcms-dataprocessing", "query": "Which Galaxy tool can be used to filter ions based on their mean contrast with blank samples?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: LC-MS data processing", "datasets": ["Dataprocessing_dataMatrix.txt"], "dataset_paths": ["Dataprocessing_dataMatrix.txt"], "dataset_count": 1, "context_summary": "Metabolomics is a *-omic* science known for being one of the most closely related to phenotypes.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "lcms-dataprocessing-q03", "tutorial_id": "topics/metabolomics/tutorials/lcms-dataprocessing", "query": "How can I correct my LC-MS data for signal drift and batch effects using Galaxy tools?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: LC-MS data processing", "datasets": ["Dataprocessing_dataMatrix.txt"], "dataset_paths": ["Dataprocessing_dataMatrix.txt"], "dataset_count": 1, "context_summary": "Metabolomics is a *-omic* science known for being one of the most closely related to phenotypes.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "lcms-dataprocessing-q04", "tutorial_id": "topics/metabolomics/tutorials/lcms-dataprocessing", "query": "I want to filter out ions with insufficient quality based on pool CV and pool CV/sample CV ratio. How can I do this in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: LC-MS data processing", "datasets": ["Dataprocessing_dataMatrix.txt"], "dataset_paths": ["Dataprocessing_dataMatrix.txt"], "dataset_count": 1, "context_summary": "Metabolomics is a *-omic* science known for being one of the most closely related to phenotypes.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "lcms-preprocessing-q01", "tutorial_id": "topics/metabolomics/tutorials/lcms-preprocessing", "query": "I have LC-MS data in mzXML format and want to assess the chromatograms before peak picking. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: LC-MS preprocessing with XCMS", "datasets": ["mzML"], "dataset_paths": ["mzML"], "dataset_count": 1, "context_summary": "Metabolomics is a *-omic* science known for being one of the most closely related to phenotypes.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "lcms-preprocessing-q02", "tutorial_id": "topics/metabolomics/tutorials/lcms-preprocessing", "query": "How can I perform peak picking on my LC-MS data using XCMS in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: LC-MS preprocessing with XCMS", "datasets": ["mzML"], "dataset_paths": ["mzML"], "dataset_count": 1, "context_summary": "Metabolomics is a *-omic* science known for being one of the most closely related to phenotypes.", "priority": 2, "version": "v0", "query_type": "science_first"}}
{"id": "lcms-preprocessing-q03", "tutorial_id": "topics/metabolomics/tutorials/lcms-preprocessing", "query": "Which Galaxy tool should I use to read my mzXML files and prepare them for XCMS analysis?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: LC-MS preprocessing with XCMS", "datasets": ["mzML"], "dataset_paths": ["mzML"], "dataset_count": 1, "context_summary": "Metabolomics is a *-omic* science known for being one of the most closely related to phenotypes.", "priority": 3, "version": "v0", "query_type": "tool_first"}}
{"id": "lcms-preprocessing-q04", "tutorial_id": "topics/metabolomics/tutorials/lcms-preprocessing", "query": "How can I use Galaxy to perform retention time correction on my LC-MS data after peak picking with XCMS?", "tools": [], "workflows": [], "metadata": {"topic": "metabolomics", "tutorial_title": "Mass spectrometry: LC-MS preprocessing with XCMS", "datasets": ["xset.merged.groupChromPeaks.RData"], "dataset_paths": ["xset.merged.groupChromPeaks.RData"], "dataset_count": 1, "context_summary": "Metabolomics is a *-omic* science known for being one of the most closely related to phenotypes.", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "metasbt-q01", "tutorial_id": "topics/microbiome/tutorials/metasbt", "query": "I have a set of viral genomes in FASTA format and their corresponding taxonomic labels in a table. What tool should I use to build a MetaSBT database from scratch?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "Indexing and profiling microbes with MetaSBT", "datasets": ["https://zenodo.org/records/15882806"], "dataset_paths": ["https://zenodo.org/records/15882806"], "dataset_count": 1, "context_summary": "## Introduction", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "metasbt-q02", "tutorial_id": "topics/microbiome/tutorials/metasbt", "query": "How can I update an existing MetaSBT database with new viral genomes?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "Indexing and profiling microbes with MetaSBT", "datasets": ["https://zenodo.org/records/15882806"], "dataset_paths": ["https://zenodo.org/records/15882806"], "dataset_count": 1, "context_summary": "## Introduction", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "metasbt-q03", "tutorial_id": "topics/microbiome/tutorials/metasbt", "query": "I have a new viral genome and a MetaSBT database. Which tool should I use to profile the query virus against the database?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "Indexing and profiling microbes with MetaSBT", "datasets": ["https://zenodo.org/records/15882806"], "dataset_paths": ["https://zenodo.org/records/15882806"], "dataset_count": 1, "context_summary": "## Introduction", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "metasbt-q04", "tutorial_id": "topics/microbiome/tutorials/metasbt", "query": "How can I interpret the results of a MetaSBT profiling report, specifically the ANI distance values and taxonomic classification?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "Indexing and profiling microbes with MetaSBT", "datasets": ["https://zenodo.org/records/15882806"], "dataset_paths": ["https://zenodo.org/records/15882806"], "dataset_count": 1, "context_summary": "## Introduction", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "qiime2-cancer-microbiome-intervention-q01", "tutorial_id": "topics/microbiome/tutorials/qiime2-cancer-microbiome-intervention", "query": "I have a set of microbiome samples and I want to analyze the composition of the microbiome. What tools should I use to process my data?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "QIIME 2 Cancer Microbiome Intervention", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "qiime2-cancer-microbiome-intervention-q02", "tutorial_id": "topics/microbiome/tutorials/qiime2-cancer-microbiome-intervention", "query": "How can I use Galaxy to identify differentially abundant features in my cancer microbiome data?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "QIIME 2 Cancer Microbiome Intervention", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "qiime2-cancer-microbiome-intervention-q03", "tutorial_id": "topics/microbiome/tutorials/qiime2-cancer-microbiome-intervention", "query": "Which tools can I use in Galaxy to perform quality control on my paired-end FASTQ files from a cancer microbiome study?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "QIIME 2 Cancer Microbiome Intervention", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "qiime2-cancer-microbiome-intervention-q04", "tutorial_id": "topics/microbiome/tutorials/qiime2-cancer-microbiome-intervention", "query": "How can I analyze the alpha diversity of my cancer microbiome samples in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "QIIME 2 Cancer Microbiome Intervention", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "qiime2-moving-pictures-q01", "tutorial_id": "topics/microbiome/tutorials/qiime2-moving-pictures", "query": "I have paired-end FASTQ files from a microbiome experiment and want to perform taxonomic profiling. What tools should I use to analyze the data?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "qiime2-moving-pictures", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "qiime2-moving-pictures-q02", "tutorial_id": "topics/microbiome/tutorials/qiime2-moving-pictures", "query": "How can I use Galaxy to identify and quantify the microbial communities in my sample using QIIME 2?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "qiime2-moving-pictures", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "qiime2-moving-pictures-q03", "tutorial_id": "topics/microbiome/tutorials/qiime2-moving-pictures", "query": "Which tools in Galaxy can I use to assess the diversity of microbial communities in my samples?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "qiime2-moving-pictures", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "qiime2-moving-pictures-q04", "tutorial_id": "topics/microbiome/tutorials/qiime2-moving-pictures", "query": "What steps should I take to perform metabarcoding analysis on my microbiome data using QIIME 2 in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "microbiome", "tutorial_title": "qiime2-moving-pictures", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bioconductor-scp-q01", "tutorial_id": "topics/proteomics/tutorials/bioconductor-scp", "query": "I have single-cell proteomics data and want to perform quality control filtering on the PSM level. What tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Single Cell Proteomics data analysis with bioconductor-scp", "datasets": ["14650887"], "dataset_paths": ["14650887"], "dataset_count": 1, "context_summary": "Single-cell proteomics (SCP) is a cutting-edge field that focuses on analyzing the protein composition of individual cells. Unlike bulk proteomics, which measures average protein levels across large cell populations, single-cell proteomics captures the unique protein expression of each cell. This approach reveals cellular heterogeneity, uncovers rare cell subpopulations, and provides deeper insights into complex biological processes, disease progression, and treatment responses. Advances in mass spectrometry and data analysis tools have made it possible to study proteins at single-cell resolution, opening new opportunities for discoveries in biomedicine {% cite Lin2024 %}, {% cite Gatto2023 %}, {% cite Ahmad2023 %}.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "bioconductor-scp-q02", "tutorial_id": "topics/proteomics/tutorials/bioconductor-scp", "query": "I need to aggregate my peptide data to the protein level and perform normalization. Which tool can I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Single Cell Proteomics data analysis with bioconductor-scp", "datasets": ["14650887"], "dataset_paths": ["14650887"], "dataset_count": 1, "context_summary": "Single-cell proteomics (SCP) is a cutting-edge field that focuses on analyzing the protein composition of individual cells. Unlike bulk proteomics, which measures average protein levels across large cell populations, single-cell proteomics captures the unique protein expression of each cell. This approach reveals cellular heterogeneity, uncovers rare cell subpopulations, and provides deeper insights into complex biological processes, disease progression, and treatment responses. Advances in mass spectrometry and data analysis tools have made it possible to study proteins at single-cell resolution, opening new opportunities for discoveries in biomedicine {% cite Lin2024 %}, {% cite Gatto2023 %}, {% cite Ahmad2023 %}.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "bioconductor-scp-q03", "tutorial_id": "topics/proteomics/tutorials/bioconductor-scp", "query": "How can I filter out peptides with high missing rates and perform log transformation on my single-cell proteomics data?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Single Cell Proteomics data analysis with bioconductor-scp", "datasets": ["14650887"], "dataset_paths": ["14650887"], "dataset_count": 1, "context_summary": "Single-cell proteomics (SCP) is a cutting-edge field that focuses on analyzing the protein composition of individual cells. Unlike bulk proteomics, which measures average protein levels across large cell populations, single-cell proteomics captures the unique protein expression of each cell. This approach reveals cellular heterogeneity, uncovers rare cell subpopulations, and provides deeper insights into complex biological processes, disease progression, and treatment responses. Advances in mass spectrometry and data analysis tools have made it possible to study proteins at single-cell resolution, opening new opportunities for discoveries in biomedicine {% cite Lin2024 %}, {% cite Gatto2023 %}, {% cite Ahmad2023 %}.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "bioconductor-scp-q04", "tutorial_id": "topics/proteomics/tutorials/bioconductor-scp", "query": "I want to perform batch effect correction and dimensionality reduction on my single-cell proteomics data. What steps should I take?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Single Cell Proteomics data analysis with bioconductor-scp", "datasets": ["14650887"], "dataset_paths": ["14650887"], "dataset_count": 1, "context_summary": "Single-cell proteomics (SCP) is a cutting-edge field that focuses on analyzing the protein composition of individual cells. Unlike bulk proteomics, which measures average protein levels across large cell populations, single-cell proteomics captures the unique protein expression of each cell. This approach reveals cellular heterogeneity, uncovers rare cell subpopulations, and provides deeper insights into complex biological processes, disease progression, and treatment responses. Advances in mass spectrometry and data analysis tools have made it possible to study proteins at single-cell resolution, opening new opportunities for discoveries in biomedicine {% cite Lin2024 %}, {% cite Gatto2023 %}, {% cite Ahmad2023 %}.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "labelfree-vs-labelled-q01", "tutorial_id": "topics/proteomics/tutorials/labelfree-vs-labelled", "query": "I want to compare the proteomic profiles of different samples using a label-free approach. What tools would I need to use in Galaxy to analyze the mass spectrometry data and identify differentially abundant proteins?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Label-free versus Labelled - How to Choose Your Quantitation Method", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Purpose", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "labelfree-vs-labelled-q02", "tutorial_id": "topics/proteomics/tutorials/labelfree-vs-labelled", "query": "I have limited access to a mass spectrometer and want to use a labelling approach for my proteomics experiment. How can I design a labelling experiment in Galaxy to minimize machine time while still achieving reliable results?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Label-free versus Labelled - How to Choose Your Quantitation Method", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Purpose", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "labelfree-vs-labelled-q03", "tutorial_id": "topics/proteomics/tutorials/labelfree-vs-labelled", "query": "I want to assess the comparability of samples in a label-free proteomics experiment. What steps can I take in Galaxy to ensure that the samples are comparable and that the results are reliable?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Label-free versus Labelled - How to Choose Your Quantitation Method", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Purpose", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "labelfree-vs-labelled-q04", "tutorial_id": "topics/proteomics/tutorials/labelfree-vs-labelled", "query": "I am planning a proteomics experiment and want to choose between a label-free and labelled quantitation method. How can I decide which approach is best for my study design and scientific question in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Label-free versus Labelled - How to Choose Your Quantitation Method", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Purpose", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-fragpipe-discovery-q01", "tutorial_id": "topics/proteomics/tutorials/neoantigen-fragpipe-discovery", "query": "I have a FASTA file containing protein sequences ([Arriba-Fusion-Database.fasta]), and I want to merge it with another FASTA file ([Human_cRAP_Non_normal_transcripts_dB.fasta]). What tool should I use to merge and filter for unique sequences?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 2: Database merge and FragPipe discovery", "datasets": ["Arriba-Fusion-Database.fasta", "Human_cRAP_Non_normal_transcripts_dB.fasta"], "dataset_paths": ["Arriba-Fusion-Database.fasta", "Human_cRAP_Non_normal_transcripts_dB.fasta"], "dataset_count": 2, "context_summary": "In this tutorial, we will guide you through a bioinformatics workflow aimed at merging neoantigen databases with known human protein sequences, preparing the data for proteomics analysis using FragPipe. This workflow involves processing FASTA files, filtering for unique sequences, and validating the FASTA databases before using FragPipe to perform peptide identification and validation of neoantigens.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-fragpipe-discovery-q02", "tutorial_id": "topics/proteomics/tutorials/neoantigen-fragpipe-discovery", "query": "I have a collection of peptide files from FragPipe ([output_peptide]), and I want to combine them into a single dataset. Which tool can I use to collapse this collection?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 2: Database merge and FragPipe discovery", "datasets": ["output_peptide"], "dataset_paths": ["output_peptide"], "dataset_count": 1, "context_summary": "In this tutorial, we will guide you through a bioinformatics workflow aimed at merging neoantigen databases with known human protein sequences, preparing the data for proteomics analysis using FragPipe. This workflow involves processing FASTA files, filtering for unique sequences, and validating the FASTA databases before using FragPipe to perform peptide identification and validation of neoantigens.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-fragpipe-discovery-q03", "tutorial_id": "topics/proteomics/tutorials/neoantigen-fragpipe-discovery", "query": "How can I validate a FASTA database ([goodFastaOut]) to ensure it is correctly formatted and usable for FragPipe analysis?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 2: Database merge and FragPipe discovery", "datasets": ["goodFastaOut"], "dataset_paths": ["goodFastaOut"], "dataset_count": 1, "context_summary": "In this tutorial, we will guide you through a bioinformatics workflow aimed at merging neoantigen databases with known human protein sequences, preparing the data for proteomics analysis using FragPipe. This workflow involves processing FASTA files, filtering for unique sequences, and validating the FASTA databases before using FragPipe to perform peptide identification and validation of neoantigens.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-fragpipe-discovery-q04", "tutorial_id": "topics/proteomics/tutorials/neoantigen-fragpipe-discovery", "query": "I want to perform a neoantigen discovery analysis using FragPipe with a validated FASTA database ([goodFastaOut]) and a manifest file ([Experimental-Design-Fragpipe.tabular]). How do I set up and run FragPipe for this analysis?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 2: Database merge and FragPipe discovery", "datasets": ["goodFastaOut", "Experimental-Design-Fragpipe.tabular"], "dataset_paths": ["goodFastaOut", "Experimental-Design-Fragpipe.tabular"], "dataset_count": 2, "context_summary": "In this tutorial, we will guide you through a bioinformatics workflow aimed at merging neoantigen databases with known human protein sequences, preparing the data for proteomics analysis using FragPipe. This workflow involves processing FASTA files, filtering for unique sequences, and validating the FASTA databases before using FragPipe to perform peptide identification and validation of neoantigens.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-fusion-database-generation-q01", "tutorial_id": "topics/proteomics/tutorials/neoantigen-fusion-database-generation", "query": "I have paired-end FASTQ reads from an RNA sequencing experiment (RNA-Seq_Reads_1.fastqsanger.gz and RNA-Seq_Reads_2.fastqsanger.gz), want to align them to a reference genome. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 1a: Fusion-Database-Generation", "datasets": ["RNA-Seq_Reads_1.fastqsanger.gz", "RNA-Seq_Reads_2.fastqsanger.gz"], "dataset_paths": ["RNA-Seq_Reads_1.fastqsanger.gz", "RNA-Seq_Reads_2.fastqsanger.gz"], "dataset_count": 2, "context_summary": "A neoantigen is a novel peptide (protein fragment) that is produced by cancer cells due to mutations, including gene fusions, that alter the DNA sequence in a way that generates unique proteins not found in normal cells. Because these mutated proteins are unique to the tumor, they are recognized as \"foreign\" by the immune system. Neoantigens are valuable in immunotherapy because they can serve as specific targets for the immune system, allowing treatments to selectively attack cancer cells while sparing normal tissue. By stimulating an immune response specifically against these neoantigens, therapies like cancer vaccines or T-cell-based treatments can be developed to enhance the body’s natural defense mechanisms, making neoantigens a promising avenue for personalized cancer treatment.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "neoantigen-fusion-database-generation-q02", "tutorial_id": "topics/proteomics/tutorials/neoantigen-fusion-database-generation", "query": "Which Galaxy tool should I use to detect gene fusions from RNA-Seq data aligned to a reference genome (mapped_reads)?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 1a: Fusion-Database-Generation", "datasets": ["mapped_reads"], "dataset_paths": ["mapped_reads"], "dataset_count": 1, "context_summary": "A neoantigen is a novel peptide (protein fragment) that is produced by cancer cells due to mutations, including gene fusions, that alter the DNA sequence in a way that generates unique proteins not found in normal cells. Because these mutated proteins are unique to the tumor, they are recognized as \"foreign\" by the immune system. Neoantigens are valuable in immunotherapy because they can serve as specific targets for the immune system, allowing treatments to selectively attack cancer cells while sparing normal tissue. By stimulating an immune response specifically against these neoantigens, therapies like cancer vaccines or T-cell-based treatments can be developed to enhance the body’s natural defense mechanisms, making neoantigens a promising avenue for personalized cancer treatment.", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "neoantigen-fusion-database-generation-q03", "tutorial_id": "topics/proteomics/tutorials/neoantigen-fusion-database-generation", "query": "I have a list of gene fusions from Arriba (fusions_tsv), how can I filter and format the data for neoantigen prediction?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 1a: Fusion-Database-Generation", "datasets": ["fusions_tsv"], "dataset_paths": ["fusions_tsv"], "dataset_count": 1, "context_summary": "A neoantigen is a novel peptide (protein fragment) that is produced by cancer cells due to mutations, including gene fusions, that alter the DNA sequence in a way that generates unique proteins not found in normal cells. Because these mutated proteins are unique to the tumor, they are recognized as \"foreign\" by the immune system. Neoantigens are valuable in immunotherapy because they can serve as specific targets for the immune system, allowing treatments to selectively attack cancer cells while sparing normal tissue. By stimulating an immune response specifically against these neoantigens, therapies like cancer vaccines or T-cell-based treatments can be developed to enhance the body’s natural defense mechanisms, making neoantigens a promising avenue for personalized cancer treatment.", "priority": 3, "version": "v0", "query_type": "science_first"}}
{"id": "neoantigen-fusion-database-generation-q04", "tutorial_id": "topics/proteomics/tutorials/neoantigen-fusion-database-generation", "query": "How can I convert a tabular file (output) to FASTA format for further analysis?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 1a: Fusion-Database-Generation", "datasets": ["output"], "dataset_paths": ["output"], "dataset_count": 1, "context_summary": "A neoantigen is a novel peptide (protein fragment) that is produced by cancer cells due to mutations, including gene fusions, that alter the DNA sequence in a way that generates unique proteins not found in normal cells. Because these mutated proteins are unique to the tumor, they are recognized as \"foreign\" by the immune system. Neoantigens are valuable in immunotherapy because they can serve as specific targets for the immune system, allowing treatments to selectively attack cancer cells while sparing normal tissue. By stimulating an immune response specifically against these neoantigens, therapies like cancer vaccines or T-cell-based treatments can be developed to enhance the body’s natural defense mechanisms, making neoantigens a promising avenue for personalized cancer treatment.", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "neoantigen-hla-binding-novel-peptides-q01", "tutorial_id": "topics/proteomics/tutorials/neoantigen-hla-binding-novel-peptides", "query": "I have a list of peptide sequences in FASTA format and I want to predict their binding affinity to MHC-I molecules using the IEDB tool in Galaxy. What tools would I need to use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 5b: IEDB binding Validated Neopeptides", "datasets": ["FASTA-IEDB.fasta"], "dataset_paths": ["FASTA-IEDB.fasta"], "dataset_count": 1, "context_summary": "Neoantigens are peptides derived from tumor-specific mutations, which are recognized by the immune system as foreign and can stimulate an immune response against cancer cells. Identifying these neoantigens is a crucial step in the development of personalized cancer immunotherapies, as they serve as targets for T-cell mediated immune responses. However, predicting which peptides from the tumor genome will bind effectively to major histocompatibility complex (MHC) molecules—key proteins that present antigens to immune cells—remains a significant challenge.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-hla-binding-novel-peptides-q02", "tutorial_id": "topics/proteomics/tutorials/neoantigen-hla-binding-novel-peptides", "query": "I have a tabular file containing peptide sequences and their corresponding HLA alleles, and I want to filter the results to only include peptides with a binding affinity of less than 0.5. How can I achieve this in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 5b: IEDB binding Validated Neopeptides", "datasets": ["IEDB Binding Affinity - Weak Peptides"], "dataset_paths": ["IEDB Binding Affinity - Weak Peptides"], "dataset_count": 1, "context_summary": "Neoantigens are peptides derived from tumor-specific mutations, which are recognized by the immune system as foreign and can stimulate an immune response against cancer cells. Identifying these neoantigens is a crucial step in the development of personalized cancer immunotherapies, as they serve as targets for T-cell mediated immune responses. However, predicting which peptides from the tumor genome will bind effectively to major histocompatibility complex (MHC) molecules—key proteins that present antigens to immune cells—remains a significant challenge.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-hla-binding-novel-peptides-q03", "tutorial_id": "topics/proteomics/tutorials/neoantigen-hla-binding-novel-peptides", "query": "Which Galaxy tool can I use to convert a FASTA file of peptide sequences into a tabular format for further analysis and annotation?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 5b: IEDB binding Validated Neopeptides", "datasets": ["FASTA-IEDB.fasta"], "dataset_paths": ["FASTA-IEDB.fasta"], "dataset_count": 1, "context_summary": "Neoantigens are peptides derived from tumor-specific mutations, which are recognized by the immune system as foreign and can stimulate an immune response against cancer cells. Identifying these neoantigens is a crucial step in the development of personalized cancer immunotherapies, as they serve as targets for T-cell mediated immune responses. However, predicting which peptides from the tumor genome will bind effectively to major histocompatibility complex (MHC) molecules—key proteins that present antigens to immune cells—remains a significant challenge.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-hla-binding-novel-peptides-q04", "tutorial_id": "topics/proteomics/tutorials/neoantigen-hla-binding-novel-peptides", "query": "I want to perform a pivot operation on a table of peptide binding results to aggregate affinity scores for each allele. How can I do this in Galaxy using the Table Compute tool?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 5b: IEDB binding Validated Neopeptides", "datasets": ["IEDB Binding Affinity - Weak Peptides"], "dataset_paths": ["IEDB Binding Affinity - Weak Peptides"], "dataset_count": 1, "context_summary": "Neoantigens are peptides derived from tumor-specific mutations, which are recognized by the immune system as foreign and can stimulate an immune response against cancer cells. Identifying these neoantigens is a crucial step in the development of personalized cancer immunotherapies, as they serve as targets for T-cell mediated immune responses. However, predicting which peptides from the tumor genome will bind effectively to major histocompatibility complex (MHC) molecules—key proteins that present antigens to immune cells—remains a significant challenge.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-non-reference-database-generation-q01", "tutorial_id": "topics/proteomics/tutorials/neoantigen-non-reference-database-generation", "query": "I have paired-end FASTQ reads from a RNA-Seq experiment (RNA-Seq_Reads_1.fastqsanger.gz and RNA-Seq_Reads_2.fastqsanger.gz), want to assess library quality before alignment. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 1b: Non-Reference-Database-Generation", "datasets": ["RNA-Seq_Reads_1.fastqsanger.gz", "RNA-Seq_Reads_2.fastqsanger.gz"], "dataset_paths": ["RNA-Seq_Reads_1.fastqsanger.gz", "RNA-Seq_Reads_2.fastqsanger.gz"], "dataset_count": 2, "context_summary": "Proteogenomics leverages mass spectrometry (MS)-based proteomics data alongside genomics and transcriptomics data to identify neoantigens—unique peptide sequences arising from tumor-specific mutations. In the initial section of this tutorial, we will construct a customized protein database (FASTA) using RNA-sequencing files (FASTQ) derived from tumor samples. Following this, we will conduct sequence database searches using the resultant FASTA file and MS data to identify peptides corresponding to novel proteoforms, specifically focusing on potential neoantigens. We will then assign genomic coordinates and annotations to these identified peptides and visualize the data, assessing both spectral quality and genomic localization.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "neoantigen-non-reference-database-generation-q02", "tutorial_id": "topics/proteomics/tutorials/neoantigen-non-reference-database-generation", "query": "Which Galaxy tool should I use to assess read quality for RNA-Seq_Reads_1.fastqsanger.gz and RNA-Seq_Reads_2.fastqsanger.gz?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 1b: Non-Reference-Database-Generation", "datasets": ["RNA-Seq_Reads_1.fastqsanger.gz", "RNA-Seq_Reads_2.fastqsanger.gz"], "dataset_paths": ["RNA-Seq_Reads_1.fastqsanger.gz", "RNA-Seq_Reads_2.fastqsanger.gz"], "dataset_count": 2, "context_summary": "Proteogenomics leverages mass spectrometry (MS)-based proteomics data alongside genomics and transcriptomics data to identify neoantigens—unique peptide sequences arising from tumor-specific mutations. In the initial section of this tutorial, we will construct a customized protein database (FASTA) using RNA-sequencing files (FASTQ) derived from tumor samples. Following this, we will conduct sequence database searches using the resultant FASTA file and MS data to identify peptides corresponding to novel proteoforms, specifically focusing on potential neoantigens. We will then assign genomic coordinates and annotations to these identified peptides and visualize the data, assessing both spectral quality and genomic localization.", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "neoantigen-non-reference-database-generation-q03", "tutorial_id": "topics/proteomics/tutorials/neoantigen-non-reference-database-generation", "query": "We have a merged and filtered FASTA file (non-reference_CustomProDB_FASTA) and want to merge it with a known human protein database (HUMAN_CRAP.fasta). How can I merge and filter these databases for further analysis?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 1b: Non-Reference-Database-Generation", "datasets": ["non-reference_CustomProDB_FASTA", "HUMAN_CRAP.fasta"], "dataset_paths": ["non-reference_CustomProDB_FASTA", "HUMAN_CRAP.fasta"], "dataset_count": 2, "context_summary": "Proteogenomics leverages mass spectrometry (MS)-based proteomics data alongside genomics and transcriptomics data to identify neoantigens—unique peptide sequences arising from tumor-specific mutations. In the initial section of this tutorial, we will construct a customized protein database (FASTA) using RNA-sequencing files (FASTQ) derived from tumor samples. Following this, we will conduct sequence database searches using the resultant FASTA file and MS data to identify peptides corresponding to novel proteoforms, specifically focusing on potential neoantigens. We will then assign genomic coordinates and annotations to these identified peptides and visualize the data, assessing both spectral quality and genomic localization.", "priority": 3, "version": "v0", "query_type": "science_first"}}
{"id": "neoantigen-non-reference-database-generation-q04", "tutorial_id": "topics/proteomics/tutorials/neoantigen-non-reference-database-generation", "query": "How can I merge and filter databases (non-reference_CustomProDB_FASTA and HUMAN_CRAP.fasta) in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 1b: Non-Reference-Database-Generation", "datasets": ["non-reference_CustomProDB_FASTA", "HUMAN_CRAP.fasta"], "dataset_paths": ["non-reference_CustomProDB_FASTA", "HUMAN_CRAP.fasta"], "dataset_count": 2, "context_summary": "Proteogenomics leverages mass spectrometry (MS)-based proteomics data alongside genomics and transcriptomics data to identify neoantigens—unique peptide sequences arising from tumor-specific mutations. In the initial section of this tutorial, we will construct a customized protein database (FASTA) using RNA-sequencing files (FASTQ) derived from tumor samples. Following this, we will conduct sequence database searches using the resultant FASTA file and MS data to identify peptides corresponding to novel proteoforms, specifically focusing on potential neoantigens. We will then assign genomic coordinates and annotations to these identified peptides and visualize the data, assessing both spectral quality and genomic localization.", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "neoantigen-peptide-verification-q01", "tutorial_id": "topics/proteomics/tutorials/neoantigen-peptide-verification", "query": "I have a list of peptides and a protein reference database, and I want to validate these peptides using a tool like PepQuery2 in Galaxy. What tools should I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 3: PepQuery2 Verification", "datasets": ["NeoAntigen-Candidates.tabular", "HUMAN_CRAP.fasta"], "dataset_paths": ["NeoAntigen-Candidates.tabular", "HUMAN_CRAP.fasta"], "dataset_count": 2, "context_summary": "Verification is an essential step in the process of analyzing neoantigens to ensure that the identified peptides or proteins are accurate and reliable. Neoantigens, which are novel antigens arising from tumor-specific mutations, are crucial for cancer immunotherapy. However, the prediction and identification of these neoantigens must be rigorously validated to ensure they are truly present and capable of eliciting an immune response. Without proper verification, the therapeutic potential of neoantigens cannot be realized, leading to wasted resources and failed treatments.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-peptide-verification-q02", "tutorial_id": "topics/proteomics/tutorials/neoantigen-peptide-verification", "query": "I need to convert my tabular data into FASTA format for BLASTP searching in Galaxy. Which tool can I use to achieve this conversion?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 3: PepQuery2 Verification", "datasets": ["output", "NeoAntigen-Candidates.tabular"], "dataset_paths": ["output", "NeoAntigen-Candidates.tabular"], "dataset_count": 2, "context_summary": "Verification is an essential step in the process of analyzing neoantigens to ensure that the identified peptides or proteins are accurate and reliable. Neoantigens, which are novel antigens arising from tumor-specific mutations, are crucial for cancer immunotherapy. However, the prediction and identification of these neoantigens must be rigorously validated to ensure they are truly present and capable of eliciting an immune response. Without proper verification, the therapeutic potential of neoantigens cannot be realized, leading to wasted resources and failed treatments.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-peptide-verification-q03", "tutorial_id": "topics/proteomics/tutorials/neoantigen-peptide-verification", "query": "How can I filter my peptide-spectrum matches (PSMs) to only include those that are validated with a 'Yes' condition using Query Tabular in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 3: PepQuery2 Verification", "datasets": ["psm_rank_txt"], "dataset_paths": ["psm_rank_txt"], "dataset_count": 1, "context_summary": "Verification is an essential step in the process of analyzing neoantigens to ensure that the identified peptides or proteins are accurate and reliable. Neoantigens, which are novel antigens arising from tumor-specific mutations, are crucial for cancer immunotherapy. However, the prediction and identification of these neoantigens must be rigorously validated to ensure they are truly present and capable of eliciting an immune response. Without proper verification, the therapeutic potential of neoantigens cannot be realized, leading to wasted resources and failed treatments.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-peptide-verification-q04", "tutorial_id": "topics/proteomics/tutorials/neoantigen-peptide-verification", "query": "I want to perform a BLASTP search using a protein query sequence in FASTA format against a locally installed BLAST database in Galaxy. What tool should I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 3: PepQuery2 Verification", "datasets": ["output", "NCBI NR (03 Sep 2023)"], "dataset_paths": ["output", "NCBI NR (03 Sep 2023)"], "dataset_count": 2, "context_summary": "Verification is an essential step in the process of analyzing neoantigens to ensure that the identified peptides or proteins are accurate and reliable. Neoantigens, which are novel antigens arising from tumor-specific mutations, are crucial for cancer immunotherapy. However, the prediction and identification of these neoantigens must be rigorously validated to ensure they are truly present and capable of eliciting an immune response. Without proper verification, the therapeutic potential of neoantigens cannot be realized, leading to wasted resources and failed treatments.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-predicting-hla-binding-q01", "tutorial_id": "topics/proteomics/tutorials/neoantigen-predicting-hla-binding", "query": "I have paired-end FASTQ reads from an RNA-Seq experiment (RNA-Seq_Reads_1.fastqsanger.gz and RNA-Seq_Reads_2.fastqsanger.gz), want to perform HLA typing. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 5a: Predicting HLA Binding", "datasets": ["RNA-Seq_Reads_1.fastqsanger.gz", "RNA-Seq_Reads_2.fastqsanger.gz"], "dataset_paths": ["RNA-Seq_Reads_1.fastqsanger.gz", "RNA-Seq_Reads_2.fastqsanger.gz"], "dataset_count": 2, "context_summary": "Neoantigen prediction for HLA binding is a critical component of personalized cancer immunotherapy. Neoantigens, which are tumor-specific antigens resulting from mutations in cancer cells, can be recognized by the immune system, making them promising targets for tailored immunotherapies. Human leukocyte antigen (HLA) molecules play a key role in presenting these neoantigens on the surface of cells, where they can be detected by T-cells, triggering an immune response.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-predicting-hla-binding-q02", "tutorial_id": "topics/proteomics/tutorials/neoantigen-predicting-hla-binding", "query": "How can I filter and reformat the HLA alleles output from OptiType for further analysis in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 5a: Predicting HLA Binding", "datasets": ["result (output of OptiType)"], "dataset_paths": ["result (output of OptiType)"], "dataset_count": 1, "context_summary": "Neoantigen prediction for HLA binding is a critical component of personalized cancer immunotherapy. Neoantigens, which are tumor-specific antigens resulting from mutations in cancer cells, can be recognized by the immune system, making them promising targets for tailored immunotherapies. Human leukocyte antigen (HLA) molecules play a key role in presenting these neoantigens on the surface of cells, where they can be detected by T-cells, triggering an immune response.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-predicting-hla-binding-q03", "tutorial_id": "topics/proteomics/tutorials/neoantigen-predicting-hla-binding", "query": "Which Galaxy tool should I use to perform HLA typing with paired-end reads (RNA-Seq_Reads_1.fastqsanger.gz and RNA-Seq_Reads_2.fastqsanger.gz)?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 5a: Predicting HLA Binding", "datasets": ["RNA-Seq_Reads_1.fastqsanger.gz", "RNA-Seq_Reads_2.fastqsanger.gz"], "dataset_paths": ["RNA-Seq_Reads_1.fastqsanger.gz", "RNA-Seq_Reads_2.fastqsanger.gz"], "dataset_count": 2, "context_summary": "Neoantigen prediction for HLA binding is a critical component of personalized cancer immunotherapy. Neoantigens, which are tumor-specific antigens resulting from mutations in cancer cells, can be recognized by the immune system, making them promising targets for tailored immunotherapies. Human leukocyte antigen (HLA) molecules play a key role in presenting these neoantigens on the surface of cells, where they can be detected by T-cells, triggering an immune response.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-predicting-hla-binding-q04", "tutorial_id": "topics/proteomics/tutorials/neoantigen-predicting-hla-binding", "query": "How can I validate and organize the HLA typing results from OptiType and seq2HLA outputs in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 5a: Predicting HLA Binding", "datasets": ["outfile (output of Text reformatting)", "c1_genotype4digits (output of seq2HLA)"], "dataset_paths": ["outfile (output of Text reformatting)", "c1_genotype4digits (output of seq2HLA)"], "dataset_count": 2, "context_summary": "Neoantigen prediction for HLA binding is a critical component of personalized cancer immunotherapy. Neoantigens, which are tumor-specific antigens resulting from mutations in cancer cells, can be recognized by the immune system, making them promising targets for tailored immunotherapies. Human leukocyte antigen (HLA) molecules play a key role in presenting these neoantigens on the surface of cells, where they can be detected by T-cells, triggering an immune response.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-variant-annotation-q01", "tutorial_id": "topics/proteomics/tutorials/neoantigen-variant-annotation", "query": "I have a VCF file containing somatic mutations and I want to map these mutations to peptide sequences. What tools should I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 4: Variant Annotation", "datasets": ["Novel_Peptides_from_PepQuery.tabular"], "dataset_paths": ["Novel_Peptides_from_PepQuery.tabular"], "dataset_count": 1, "context_summary": "Neoantigens are tumor-specific antigens that arise from somatic mutations in cancer cells. These mutations result in the generation of abnormal peptides that can be presented by the immune system’s Major Histocompatibility Complex (MHC) molecules. Neoantigens are gaining significant attention in cancer immunotherapy, as they hold the potential to be used in personalized vaccines and therapies aimed at stimulating the immune system to target and destroy tumor cells.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-variant-annotation-q02", "tutorial_id": "topics/proteomics/tutorials/neoantigen-variant-annotation", "query": "How can I convert a proteomic coordinate to a genomic coordinate for a peptide sequence in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 4: Variant Annotation", "datasets": ["Fragpipe-Peptide-Report.tabular"], "dataset_paths": ["Fragpipe-Peptide-Report.tabular"], "dataset_count": 1, "context_summary": "Neoantigens are tumor-specific antigens that arise from somatic mutations in cancer cells. These mutations result in the generation of abnormal peptides that can be presented by the immune system’s Major Histocompatibility Complex (MHC) molecules. Neoantigens are gaining significant attention in cancer immunotherapy, as they hold the potential to be used in personalized vaccines and therapies aimed at stimulating the immune system to target and destroy tumor cells.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-variant-annotation-q03", "tutorial_id": "topics/proteomics/tutorials/neoantigen-variant-annotation", "query": "I need to annotate peptide sequences with genomic information using a GTF file and a BED file. Which tool should I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 4: Variant Annotation", "datasets": ["GffCompare_Annotated_GTF_to_BED.bed"], "dataset_paths": ["GffCompare_Annotated_GTF_to_BED.bed"], "dataset_count": 1, "context_summary": "Neoantigens are tumor-specific antigens that arise from somatic mutations in cancer cells. These mutations result in the generation of abnormal peptides that can be presented by the immune system’s Major Histocompatibility Complex (MHC) molecules. Neoantigens are gaining significant attention in cancer immunotherapy, as they hold the potential to be used in personalized vaccines and therapies aimed at stimulating the immune system to target and destroy tumor cells.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "neoantigen-variant-annotation-q04", "tutorial_id": "topics/proteomics/tutorials/neoantigen-variant-annotation", "query": "How can I generate a BED file from a tabular dataset of peptide sequences and their genomic coordinates?", "tools": [], "workflows": [], "metadata": {"topic": "proteomics", "tutorial_title": "Neoantigen 4: Variant Annotation", "datasets": ["Novel_Peptides_from_PepQuery.tabular"], "dataset_paths": ["Novel_Peptides_from_PepQuery.tabular"], "dataset_count": 1, "context_summary": "Neoantigens are tumor-specific antigens that arise from somatic mutations in cancer cells. These mutations result in the generation of abnormal peptides that can be presented by the immune system’s Major Histocompatibility Complex (MHC) molecules. Neoantigens are gaining significant attention in cancer immunotherapy, as they hold the potential to be used in personalized vaccines and therapies aimed at stimulating the immune system to target and destroy tumor cells.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "ncbi-blast-against-the-madland-q01", "tutorial_id": "topics/sequence-analysis/tutorials/ncbi-blast-against-the-madland", "query": "I have a protein sequence in a FASTA file (query.faa) and I want to perform a similarity search against the MAdLandDB database. Which Galaxy tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "sequence-analysis", "tutorial_title": "NCBI BLAST+ against the MAdLand", "datasets": ["data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa"], "dataset_paths": ["data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa"], "dataset_count": 1, "context_summary": "MAdLandDB is a protein database comprising of a comprehensive collection of fully sequenced plant and algal genomes, with a particular emphasis on non-seed plants and streptophyte algae. Additionally, for comparative analysis, the database also includes genomes from various other organisms such as fungi, animals, the SAR group, bacteria, and archaea. The database is actively developed and maintained by the [Rensing lab](http://plantco.de) and released in the [MAdLand](https://madland.science/) setting. It employs a system of species abbreviation using a 5 letter code, which is constructed using the first three letters of the genus and the first two letters of the species name, for example, CHABR for *Chara braunii*. Furthermore, the database provides gene identification through the additio\n\nDataset files (1): data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "ncbi-blast-against-the-madland-q02", "tutorial_id": "topics/sequence-analysis/tutorials/ncbi-blast-against-the-madland", "query": "I want to perform a BLAST search against the MAdLandDB database using a protein query sequence. How can I set the expectation value cutoff to 0.001 in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "sequence-analysis", "tutorial_title": "NCBI BLAST+ against the MAdLand", "datasets": ["data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa"], "dataset_paths": ["data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa"], "dataset_count": 1, "context_summary": "MAdLandDB is a protein database comprising of a comprehensive collection of fully sequenced plant and algal genomes, with a particular emphasis on non-seed plants and streptophyte algae. Additionally, for comparative analysis, the database also includes genomes from various other organisms such as fungi, animals, the SAR group, bacteria, and archaea. The database is actively developed and maintained by the [Rensing lab](http://plantco.de) and released in the [MAdLand](https://madland.science/) setting. It employs a system of species abbreviation using a 5 letter code, which is constructed using the first three letters of the genus and the first two letters of the species name, for example, CHABR for *Chara braunii*. Furthermore, the database provides gene identification through the additio\n\nDataset files (1): data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "ncbi-blast-against-the-madland-q03", "tutorial_id": "topics/sequence-analysis/tutorials/ncbi-blast-against-the-madland", "query": "Which tool can I use to align my large-scale protein sequence data against the MAdLandDB database in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "sequence-analysis", "tutorial_title": "NCBI BLAST+ against the MAdLand", "datasets": ["data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa"], "dataset_paths": ["data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa"], "dataset_count": 1, "context_summary": "MAdLandDB is a protein database comprising of a comprehensive collection of fully sequenced plant and algal genomes, with a particular emphasis on non-seed plants and streptophyte algae. Additionally, for comparative analysis, the database also includes genomes from various other organisms such as fungi, animals, the SAR group, bacteria, and archaea. The database is actively developed and maintained by the [Rensing lab](http://plantco.de) and released in the [MAdLand](https://madland.science/) setting. It employs a system of species abbreviation using a 5 letter code, which is constructed using the first three letters of the genus and the first two letters of the species name, for example, CHABR for *Chara braunii*. Furthermore, the database provides gene identification through the additio\n\nDataset files (1): data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "ncbi-blast-against-the-madland-q04", "tutorial_id": "topics/sequence-analysis/tutorials/ncbi-blast-against-the-madland", "query": "I have a translated nucleotide sequence and I want to perform a BLAST search against the MAdLandDB database. How can I do this in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "sequence-analysis", "tutorial_title": "NCBI BLAST+ against the MAdLand", "datasets": ["data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa"], "dataset_paths": ["data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa"], "dataset_count": 1, "context_summary": "MAdLandDB is a protein database comprising of a comprehensive collection of fully sequenced plant and algal genomes, with a particular emphasis on non-seed plants and streptophyte algae. Additionally, for comparative analysis, the database also includes genomes from various other organisms such as fungi, animals, the SAR group, bacteria, and archaea. The database is actively developed and maintained by the [Rensing lab](http://plantco.de) and released in the [MAdLand](https://madland.science/) setting. It employs a system of species abbreviation using a 5 letter code, which is constructed using the first three letters of the genus and the first two letters of the species name, for example, CHABR for *Chara braunii*. Furthermore, the database provides gene identification through the additio\n\nDataset files (1): data/datasets/sequence-analysis/ncbi-blast-against-the-madland/query.faa", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "sars-with-galaxy-on-anvil-q01", "tutorial_id": "topics/sequence-analysis/tutorials/sars-with-galaxy-on-anvil", "query": "I have paired-end FASTQ reads from a sequencing experiment, want to assess library quality before alignment. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "sequence-analysis", "tutorial_title": "SARS-CoV-2 Viral Sample Alignment and Variant Visualization", "datasets": ["VA_sample_forward_reads.fastq", "VA_sample_reverse_reads.fastq"], "dataset_paths": ["VA_sample_forward_reads.fastq", "VA_sample_reverse_reads.fastq"], "dataset_count": 2, "context_summary": "There is a growing need for undergraduate students to learn cutting-edge concepts in genomics data science, including performing analysis on the cloud instead of a personal computer.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "sars-with-galaxy-on-anvil-q02", "tutorial_id": "topics/sequence-analysis/tutorials/sars-with-galaxy-on-anvil", "query": "Which Galaxy tool should I use to assess read quality for VA_sample_forward_reads.fastq?", "tools": [], "workflows": [], "metadata": {"topic": "sequence-analysis", "tutorial_title": "SARS-CoV-2 Viral Sample Alignment and Variant Visualization", "datasets": ["VA_sample_forward_reads.fastq"], "dataset_paths": ["VA_sample_forward_reads.fastq"], "dataset_count": 1, "context_summary": "There is a growing need for undergraduate students to learn cutting-edge concepts in genomics data science, including performing analysis on the cloud instead of a personal computer.", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "sars-with-galaxy-on-anvil-q03", "tutorial_id": "topics/sequence-analysis/tutorials/sars-with-galaxy-on-anvil", "query": "How can I align paired-end FASTQ reads (VA_sample_forward_reads.fastq and VA_sample_reverse_reads.fastq) to a reference genome (SARS-CoV-2_reference_genome.fasta) in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "sequence-analysis", "tutorial_title": "SARS-CoV-2 Viral Sample Alignment and Variant Visualization", "datasets": ["VA_sample_forward_reads.fastq", "VA_sample_reverse_reads.fastq", "SARS-CoV-2_reference_genome.fasta"], "dataset_paths": ["VA_sample_forward_reads.fastq", "VA_sample_reverse_reads.fastq", "SARS-CoV-2_reference_genome.fasta"], "dataset_count": 3, "context_summary": "There is a growing need for undergraduate students to learn cutting-edge concepts in genomics data science, including performing analysis on the cloud instead of a personal computer.", "priority": 3, "version": "v0", "query_type": "science_first"}}
{"id": "sars-with-galaxy-on-anvil-q04", "tutorial_id": "topics/sequence-analysis/tutorials/sars-with-galaxy-on-anvil", "query": "What tool can I use to visualize the aligned reads (BAM file) generated from aligning VA_sample_forward_reads.fastq and VA_sample_reverse_reads.fastq to SARS-CoV-2_reference_genome.fasta?", "tools": [], "workflows": [], "metadata": {"topic": "sequence-analysis", "tutorial_title": "SARS-CoV-2 Viral Sample Alignment and Variant Visualization", "datasets": ["Map with BWA-MEM on data 9, data 8, and data 7 (mapped reads in BAM format)"], "dataset_paths": ["Map with BWA-MEM on data 9, data 8, and data 7 (mapped reads in BAM format)"], "dataset_count": 1, "context_summary": "There is a growing need for undergraduate students to learn cutting-edge concepts in genomics data science, including performing analysis on the cloud instead of a personal computer.", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "EBI-retrieval-q01", "tutorial_id": "topics/single-cell/tutorials/EBI-retrieval", "query": "I have downloaded a single-cell expression matrix from the Single Cell Expression Atlas and want to convert it into an AnnData object for downstream analysis. What should I do?", "tools": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2"], "workflows": ["EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object"], "metadata": {"topic": "single-cell", "tutorial_title": "Importing files from public atlases", "datasets": ["EBI SCXA Data Retrieval on E-MTAB-6945 matrix.mtx (Raw filtered counts)", "EBI SCXA Data Retrieval on E-MTAB-6945 genes.tsv (Raw filtered counts)", "EBI SCXA Data Retrieval on E-MTAB-6945 barcodes.tsv (Raw filtered counts)"], "dataset_paths": ["EBI SCXA Data Retrieval on E-MTAB-6945 matrix.mtx (Raw filtered counts)", "EBI SCXA Data Retrieval on E-MTAB-6945 genes.tsv (Raw filtered counts)", "EBI SCXA Data Retrieval on E-MTAB-6945 barcodes.tsv (Raw filtered counts)"], "dataset_count": 3, "context_summary": "Public single cell datasets seem to accumulate by the second. Well annotated, quality datasets are slightly trickier to find, which is why projects like the [Single Cell Expression Atlas](https://www.ebi.ac.uk/gxa/sc/home) (SCXA) exist - to curate datasets for public use. Here, we will guide you through transforming data imported from the SCXA repository into the input file required for the [Filter, Plot, Explore tutorial]({% link topics/single-cell/tutorials/scrna-case_basic-pipeline/tutorial.md %}) and we will also show how to use the public atlases for your own research.", "priority": 1, "version": "v0", "workflow_steps": {"EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2", "toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_grep_tool/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_find_and_replace/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/scanpy_read_10x/scanpy_read_10x/1.9.3+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/seurat_read10x/seurat_read10x/4.0.4+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/anndata_ops/anndata_ops/1.9.3+galaxy0"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2"}}
{"id": "EBI-retrieval-q02", "tutorial_id": "topics/single-cell/tutorials/EBI-retrieval", "query": "Which Galaxy tool can I use to convert a Matrix Market-formatted expression matrix into an AnnData object?", "tools": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2"], "workflows": ["EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object"], "metadata": {"topic": "single-cell", "tutorial_title": "Importing files from public atlases", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Public single cell datasets seem to accumulate by the second. Well annotated, quality datasets are slightly trickier to find, which is why projects like the [Single Cell Expression Atlas](https://www.ebi.ac.uk/gxa/sc/home) (SCXA) exist - to curate datasets for public use. Here, we will guide you through transforming data imported from the SCXA repository into the input file required for the [Filter, Plot, Explore tutorial]({% link topics/single-cell/tutorials/scrna-case_basic-pipeline/tutorial.md %}) and we will also show how to use the public atlases for your own research.", "priority": 2, "version": "v0", "workflow_steps": {"EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2", "toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_grep_tool/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_find_and_replace/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/scanpy_read_10x/scanpy_read_10x/1.9.3+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/seurat_read10x/seurat_read10x/4.0.4+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/anndata_ops/anndata_ops/1.9.3+galaxy0"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2"}}
{"id": "EBI-retrieval-q03", "tutorial_id": "topics/single-cell/tutorials/EBI-retrieval", "query": "My single-cell expression matrix from the Single Cell Expression Atlas has some genes with non-standard names. How can I flag mitochondrial genes in my AnnData object?", "tools": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2"], "workflows": ["EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object"], "metadata": {"topic": "single-cell", "tutorial_title": "Importing files from public atlases", "datasets": ["AnnData object"], "dataset_paths": ["AnnData object"], "dataset_count": 1, "context_summary": "Public single cell datasets seem to accumulate by the second. Well annotated, quality datasets are slightly trickier to find, which is why projects like the [Single Cell Expression Atlas](https://www.ebi.ac.uk/gxa/sc/home) (SCXA) exist - to curate datasets for public use. Here, we will guide you through transforming data imported from the SCXA repository into the input file required for the [Filter, Plot, Explore tutorial]({% link topics/single-cell/tutorials/scrna-case_basic-pipeline/tutorial.md %}) and we will also show how to use the public atlases for your own research.", "priority": 3, "version": "v0", "workflow_steps": {"EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2", "toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_grep_tool/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_find_and_replace/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/scanpy_read_10x/scanpy_read_10x/1.9.3+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/seurat_read10x/seurat_read10x/4.0.4+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/anndata_ops/anndata_ops/1.9.3+galaxy0"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2"}}
{"id": "EBI-retrieval-q04", "tutorial_id": "topics/single-cell/tutorials/EBI-retrieval", "query": "Which Galaxy tool can I use to flag mitochondrial genes in my AnnData object?", "tools": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2"], "workflows": ["EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object"], "metadata": {"topic": "single-cell", "tutorial_title": "Importing files from public atlases", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Public single cell datasets seem to accumulate by the second. Well annotated, quality datasets are slightly trickier to find, which is why projects like the [Single Cell Expression Atlas](https://www.ebi.ac.uk/gxa/sc/home) (SCXA) exist - to curate datasets for public use. Here, we will guide you through transforming data imported from the SCXA repository into the input file required for the [Filter, Plot, Explore tutorial]({% link topics/single-cell/tutorials/scrna-case_basic-pipeline/tutorial.md %}) and we will also show how to use the public atlases for your own research.", "priority": 4, "version": "v0", "workflow_steps": {"EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2", "toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_grep_tool/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_find_and_replace/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/scanpy_read_10x/scanpy_read_10x/1.9.3+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/seurat_read10x/seurat_read10x/4.0.4+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/anndata_ops/anndata_ops/1.9.3+galaxy0"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2"}}
{"id": "EBI-retrieval-q05", "tutorial_id": "topics/single-cell/tutorials/EBI-retrieval", "query": "I have a single-cell expression matrix in Matrix Market format and want to create a Seurat object. What tool can I use?", "tools": ["toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3"], "workflows": ["EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object"], "metadata": {"topic": "single-cell", "tutorial_title": "Importing files from public atlases", "datasets": ["EBI SCXA Data Retrieval on E-MTAB-6945 matrix.mtx (Raw filtered counts)", "EBI SCXA Data Retrieval on E-MTAB-6945 genes.tsv (Raw filtered counts)", "EBI SCXA Data Retrieval on E-MTAB-6945 barcodes.tsv (Raw filtered counts)"], "dataset_paths": ["EBI SCXA Data Retrieval on E-MTAB-6945 matrix.mtx (Raw filtered counts)", "EBI SCXA Data Retrieval on E-MTAB-6945 genes.tsv (Raw filtered counts)", "EBI SCXA Data Retrieval on E-MTAB-6945 barcodes.tsv (Raw filtered counts)"], "dataset_count": 3, "context_summary": "Public single cell datasets seem to accumulate by the second. Well annotated, quality datasets are slightly trickier to find, which is why projects like the [Single Cell Expression Atlas](https://www.ebi.ac.uk/gxa/sc/home) (SCXA) exist - to curate datasets for public use. Here, we will guide you through transforming data imported from the SCXA repository into the input file required for the [Filter, Plot, Explore tutorial]({% link topics/single-cell/tutorials/scrna-case_basic-pipeline/tutorial.md %}) and we will also show how to use the public atlases for your own research.", "priority": 5, "version": "v0", "workflow_steps": {"EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2", "toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_grep_tool/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_find_and_replace/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/scanpy_read_10x/scanpy_read_10x/1.9.3+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/seurat_read10x/seurat_read10x/4.0.4+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/anndata_ops/anndata_ops/1.9.3+galaxy0"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3"}}
{"id": "EBI-retrieval-q06", "tutorial_id": "topics/single-cell/tutorials/EBI-retrieval", "query": "How can I create a Seurat object from my single-cell expression matrix in Galaxy?", "tools": ["toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3"], "workflows": ["EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object"], "metadata": {"topic": "single-cell", "tutorial_title": "Importing files from public atlases", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Public single cell datasets seem to accumulate by the second. Well annotated, quality datasets are slightly trickier to find, which is why projects like the [Single Cell Expression Atlas](https://www.ebi.ac.uk/gxa/sc/home) (SCXA) exist - to curate datasets for public use. Here, we will guide you through transforming data imported from the SCXA repository into the input file required for the [Filter, Plot, Explore tutorial]({% link topics/single-cell/tutorials/scrna-case_basic-pipeline/tutorial.md %}) and we will also show how to use the public atlases for your own research.", "priority": 6, "version": "v0", "workflow_steps": {"EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2", "toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_grep_tool/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_find_and_replace/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/scanpy_read_10x/scanpy_read_10x/1.9.3+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/seurat_read10x/seurat_read10x/4.0.4+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/anndata_ops/anndata_ops/1.9.3+galaxy0"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3"}}
{"id": "EBI-retrieval-q07", "tutorial_id": "topics/single-cell/tutorials/EBI-retrieval", "query": "I have downloaded a single-cell expression matrix from the Human Cell Atlas and want to convert it into an AnnData object for downstream analysis. What should I do?", "tools": ["toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3"], "workflows": ["EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object"], "metadata": {"topic": "single-cell", "tutorial_title": "Importing files from public atlases", "datasets": ["Human Cell Atlas Matrix Downloader on matrix.mtx", "Human Cell Atlas Matrix Downloader on genes.tsv", "Human Cell Atlas Matrix Downloader on barcodes.tsv"], "dataset_paths": ["Human Cell Atlas Matrix Downloader on matrix.mtx", "Human Cell Atlas Matrix Downloader on genes.tsv", "Human Cell Atlas Matrix Downloader on barcodes.tsv"], "dataset_count": 3, "context_summary": "Public single cell datasets seem to accumulate by the second. Well annotated, quality datasets are slightly trickier to find, which is why projects like the [Single Cell Expression Atlas](https://www.ebi.ac.uk/gxa/sc/home) (SCXA) exist - to curate datasets for public use. Here, we will guide you through transforming data imported from the SCXA repository into the input file required for the [Filter, Plot, Explore tutorial]({% link topics/single-cell/tutorials/scrna-case_basic-pipeline/tutorial.md %}) and we will also show how to use the public atlases for your own research.", "priority": 7, "version": "v0", "workflow_steps": {"EBI-SCXA-to-AnnData-(Scanpy)-or-Seurat-Object": ["toolshed.g2.bx.psu.edu/repos/ebi-gxa/retrieve_scxa/retrieve_scxa/v0.0.2+galaxy2", "toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_grep_tool/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/bgruening/text_processing/tp_find_and_replace/9.3+galaxy1", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/scanpy_read_10x/scanpy_read_10x/1.9.3+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/seurat_read10x/seurat_read10x/4.0.4+galaxy0", "toolshed.g2.bx.psu.edu/repos/ebi-gxa/anndata_ops/anndata_ops/1.9.3+galaxy0"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/galaxyp/regex_find_replace/regexColumn1/1.0.3"}}
{"id": "alevin-commandline-q01", "tutorial_id": "topics/single-cell/tutorials/alevin-commandline", "query": "I have paired-end FASTQ reads from a single-cell RNA-seq experiment and want to quantify gene expression using Alevin. What tools are required for this task?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Generating a single cell matrix using Alevin and combining datasets (bash + R)", "datasets": ["transcript_701.fastq", "barcodes_701.fastq"], "dataset_paths": ["transcript_701.fastq", "barcodes_701.fastq"], "dataset_count": 2, "context_summary": "# Setting up the environment", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "alevin-commandline-q02", "tutorial_id": "topics/single-cell/tutorials/alevin-commandline", "query": "How can I build a Salmon index for my transcriptome in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Generating a single cell matrix using Alevin and combining datasets (bash + R)", "datasets": ["filtered_fasta"], "dataset_paths": ["filtered_fasta"], "dataset_count": 1, "context_summary": "# Setting up the environment", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "alevin-commandline-q03", "tutorial_id": "topics/single-cell/tutorials/alevin-commandline", "query": "I have a SummarizedExperiment object and want to convert it to a SingleCellExperiment object. What tool or function should I use?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Generating a single cell matrix using Alevin and combining datasets (bash + R)", "datasets": ["alevin_combined"], "dataset_paths": ["alevin_combined"], "dataset_count": 1, "context_summary": "# Setting up the environment", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "alevin-commandline-q04", "tutorial_id": "topics/single-cell/tutorials/alevin-commandline", "query": "How can I filter out empty droplets from my single-cell data using Alevin in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Generating a single cell matrix using Alevin and combining datasets (bash + R)", "datasets": ["matrix_alevin"], "dataset_paths": ["matrix_alevin"], "dataset_count": 1, "context_summary": "# Setting up the environment", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "bulk-music-4-compare-q01", "tutorial_id": "topics/single-cell/tutorials/bulk-music-4-compare", "query": "I have a single-cell RNA reference dataset (ESet_object_sc_combined.rdata) and bulk RNA-seq samples (ESet_object_bulk_healthy.rdata, ESet_object_bulk_T2D.rdata) from a diabetes study. How can I compare the inferred cell compositions between healthy and diseased samples using bulk RNA deconvolution techniques?", "tools": ["toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"], "workflows": ["compare"], "metadata": {"topic": "single-cell", "tutorial_title": "Comparing inferred cell compositions using MuSiC deconvolution", "datasets": ["ESet_object_sc_combined.rdata", "ESet_object_bulk_healthy.rdata", "ESet_object_bulk_T2D.rdata"], "dataset_paths": ["ESet_object_sc_combined.rdata", "ESet_object_bulk_healthy.rdata", "ESet_object_bulk_T2D.rdata"], "dataset_count": 3, "context_summary": "The goal of this tutorial is to apply bulk RNA deconvolution techniques to a problem with multiple variables - in this case, a model of diabetes is compared with its healthy counterparts. All you need to compare inferred cell compositions are well-annotated, high quality reference scRNA-seq datasets, transformed into MuSiC-friendly Expression Set objects, and your bulk RNA-samples of choice (also transformed into MuSiC-friendly Expression Set objects). For more information on how MuSiC works, you can check out their github site [MuSiC](https://xuranw.github.io/MuSiC/articles/MuSiC.html) or published article ({% cite wang2019bulk %}).", "priority": 1, "version": "v0", "workflow_steps": {"compare": ["toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4", "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4", "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"}}
{"id": "bulk-music-4-compare-q02", "tutorial_id": "topics/single-cell/tutorials/bulk-music-4-compare", "query": "What are the differences in inferred cell compositions when using a combined single-cell reference (ESet_object_sc_combined.rdata) versus separate healthy and diseased references (ESet_object_sc_healthy.rdata, ESet_object_sc_T2D.rdata) for bulk RNA deconvolution?", "tools": ["toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"], "workflows": ["compare"], "metadata": {"topic": "single-cell", "tutorial_title": "Comparing inferred cell compositions using MuSiC deconvolution", "datasets": ["ESet_object_sc_combined.rdata", "ESet_object_sc_healthy.rdata", "ESet_object_sc_T2D.rdata", "ESet_object_bulk_healthy.rdata"], "dataset_paths": ["ESet_object_sc_combined.rdata", "ESet_object_sc_healthy.rdata", "ESet_object_sc_T2D.rdata", "ESet_object_bulk_healthy.rdata"], "dataset_count": 4, "context_summary": "The goal of this tutorial is to apply bulk RNA deconvolution techniques to a problem with multiple variables - in this case, a model of diabetes is compared with its healthy counterparts. All you need to compare inferred cell compositions are well-annotated, high quality reference scRNA-seq datasets, transformed into MuSiC-friendly Expression Set objects, and your bulk RNA-samples of choice (also transformed into MuSiC-friendly Expression Set objects). For more information on how MuSiC works, you can check out their github site [MuSiC](https://xuranw.github.io/MuSiC/articles/MuSiC.html) or published article ({% cite wang2019bulk %}).", "priority": 2, "version": "v0", "workflow_steps": {"compare": ["toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4", "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4", "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"}}
{"id": "bulk-music-4-compare-q03", "tutorial_id": "topics/single-cell/tutorials/bulk-music-4-compare", "query": "Which Galaxy tool can I use to perform bulk RNA deconvolution with a combined single-cell reference (ESet_object_sc_combined.rdata) and bulk RNA-seq samples (ESet_object_bulk_healthy.rdata, ESet_object_bulk_T2D.rdata)?", "tools": ["toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"], "workflows": ["compare"], "metadata": {"topic": "single-cell", "tutorial_title": "Comparing inferred cell compositions using MuSiC deconvolution", "datasets": ["ESet_object_sc_combined.rdata", "ESet_object_bulk_healthy.rdata", "ESet_object_bulk_T2D.rdata"], "dataset_paths": ["ESet_object_sc_combined.rdata", "ESet_object_bulk_healthy.rdata", "ESet_object_bulk_T2D.rdata"], "dataset_count": 3, "context_summary": "The goal of this tutorial is to apply bulk RNA deconvolution techniques to a problem with multiple variables - in this case, a model of diabetes is compared with its healthy counterparts. All you need to compare inferred cell compositions are well-annotated, high quality reference scRNA-seq datasets, transformed into MuSiC-friendly Expression Set objects, and your bulk RNA-samples of choice (also transformed into MuSiC-friendly Expression Set objects). For more information on how MuSiC works, you can check out their github site [MuSiC](https://xuranw.github.io/MuSiC/articles/MuSiC.html) or published article ({% cite wang2019bulk %}).", "priority": 3, "version": "v0", "workflow_steps": {"compare": ["toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4", "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4", "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"}}
{"id": "bulk-music-4-compare-q04", "tutorial_id": "topics/single-cell/tutorials/bulk-music-4-compare", "query": "How do I set up a MuSiC Compare analysis with separate healthy and diseased single-cell references (ESet_object_sc_healthy.rdata, ESet_object_sc_T2D.rdata) and bulk RNA-seq samples (ESet_object_bulk_healthy.rdata, ESet_object_bulk_T2D.rdata) in Galaxy?", "tools": ["toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"], "workflows": ["compare"], "metadata": {"topic": "single-cell", "tutorial_title": "Comparing inferred cell compositions using MuSiC deconvolution", "datasets": ["ESet_object_sc_healthy.rdata", "ESet_object_sc_T2D.rdata", "ESet_object_bulk_healthy.rdata", "ESet_object_bulk_T2D.rdata"], "dataset_paths": ["ESet_object_sc_healthy.rdata", "ESet_object_sc_T2D.rdata", "ESet_object_bulk_healthy.rdata", "ESet_object_bulk_T2D.rdata"], "dataset_count": 4, "context_summary": "The goal of this tutorial is to apply bulk RNA deconvolution techniques to a problem with multiple variables - in this case, a model of diabetes is compared with its healthy counterparts. All you need to compare inferred cell compositions are well-annotated, high quality reference scRNA-seq datasets, transformed into MuSiC-friendly Expression Set objects, and your bulk RNA-samples of choice (also transformed into MuSiC-friendly Expression Set objects). For more information on how MuSiC works, you can check out their github site [MuSiC](https://xuranw.github.io/MuSiC/articles/MuSiC.html) or published article ({% cite wang2019bulk %}).", "priority": 4, "version": "v0", "workflow_steps": {"compare": ["toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4", "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4", "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/bgruening/music_compare/music_compare/0.1.1+galaxy4"}}
{"id": "scrna-case-jupyter_basic-pipeline-q01", "tutorial_id": "topics/single-cell/tutorials/scrna-case-jupyter_basic-pipeline", "query": "I have single-cell RNA-seq data and want to perform quality control and filtering. Which tools should I use to assess the quality of my data and remove low-quality cells?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Filter, plot and explore single-cell RNA-seq data with Scanpy (Python)", "datasets": ["7053673"], "dataset_paths": ["7053673"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "scrna-case-jupyter_basic-pipeline-q02", "tutorial_id": "topics/single-cell/tutorials/scrna-case-jupyter_basic-pipeline", "query": "I want to perform dimensionality reduction on my single-cell RNA-seq data using principal components. How can I select the optimal number of principal components to use for further analysis?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Filter, plot and explore single-cell RNA-seq data with Scanpy (Python)", "datasets": ["7053673"], "dataset_paths": ["7053673"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "scrna-case-jupyter_basic-pipeline-q03", "tutorial_id": "topics/single-cell/tutorials/scrna-case-jupyter_basic-pipeline", "query": "Which tool can I use to calculate highly variable genes in my single-cell RNA-seq data?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Filter, plot and explore single-cell RNA-seq data with Scanpy (Python)", "datasets": ["7053673"], "dataset_paths": ["7053673"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "scrna-case-jupyter_basic-pipeline-q04", "tutorial_id": "topics/single-cell/tutorials/scrna-case-jupyter_basic-pipeline", "query": "How can I visualize my single-cell RNA-seq data using a UMAP plot to identify clusters and patterns in the data?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Filter, plot and explore single-cell RNA-seq data with Scanpy (Python)", "datasets": ["7053673"], "dataset_paths": ["7053673"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_FilterPlotandExploreRStudio-q01", "tutorial_id": "topics/single-cell/tutorials/scrna-case_FilterPlotandExploreRStudio", "query": "I have single-cell RNA-seq data and want to perform quality control (QC) plots to assess the data quality. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Filter, plot, and explore single cell RNA-seq data with Seurat (R)", "datasets": ["7053673"], "dataset_paths": ["7053673"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_FilterPlotandExploreRStudio-q02", "tutorial_id": "topics/single-cell/tutorials/scrna-case_FilterPlotandExploreRStudio", "query": "Which Galaxy tool should I use to perform SCTransform on my single-cell RNA-seq data?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Filter, plot, and explore single cell RNA-seq data with Seurat (R)", "datasets": ["7053673"], "dataset_paths": ["7053673"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_FilterPlotandExploreRStudio-q03", "tutorial_id": "topics/single-cell/tutorials/scrna-case_FilterPlotandExploreRStudio", "query": "How can I identify and label cell types in my single-cell RNA-seq data after clustering?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Filter, plot, and explore single cell RNA-seq data with Seurat (R)", "datasets": ["7053673"], "dataset_paths": ["7053673"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_FilterPlotandExploreRStudio-q04", "tutorial_id": "topics/single-cell/tutorials/scrna-case_FilterPlotandExploreRStudio", "query": "I have performed differential expression testing on my single-cell RNA-seq data and obtained a list of marker genes. How can I visualize the expression of these markers on a UMAP plot?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Filter, plot, and explore single cell RNA-seq data with Seurat (R)", "datasets": ["7053673"], "dataset_paths": ["7053673"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_JUPYTER-trajectories-q01", "tutorial_id": "topics/single-cell/tutorials/scrna-case_JUPYTER-trajectories", "query": "I have a single-cell RNA-seq dataset and I want to perform a trajectory analysis. What tools should I use to preprocess the data and prepare it for trajectory analysis?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Inferring single cell trajectories with Scanpy (Python)", "datasets": ["data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad"], "dataset_paths": ["data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad"], "dataset_count": 1, "context_summary": "# Run the tutorial!\n\nDataset files (3): data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad, data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Trajectories_Answer_Key.ipynb, data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Trajectories_Instructions.ipynb", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_JUPYTER-trajectories-q02", "tutorial_id": "topics/single-cell/tutorials/scrna-case_JUPYTER-trajectories", "query": "I want to use diffusion maps for dimensionality reduction in my single-cell RNA-seq data. Which tool can I use for this purpose in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Inferring single cell trajectories with Scanpy (Python)", "datasets": ["data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad"], "dataset_paths": ["data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad"], "dataset_count": 1, "context_summary": "# Run the tutorial!\n\nDataset files (3): data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad, data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Trajectories_Answer_Key.ipynb, data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Trajectories_Instructions.ipynb", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_JUPYTER-trajectories-q03", "tutorial_id": "topics/single-cell/tutorials/scrna-case_JUPYTER-trajectories", "query": "How can I use Galaxy to perform a PAGA analysis on my single-cell RNA-seq data and visualize the results?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Inferring single cell trajectories with Scanpy (Python)", "datasets": ["data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad"], "dataset_paths": ["data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad"], "dataset_count": 1, "context_summary": "# Run the tutorial!\n\nDataset files (3): data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad, data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Trajectories_Answer_Key.ipynb, data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Trajectories_Instructions.ipynb", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_JUPYTER-trajectories-q04", "tutorial_id": "topics/single-cell/tutorials/scrna-case_JUPYTER-trajectories", "query": "I want to identify the root cell for my single-cell RNA-seq data to use in diffusion pseudotime analysis. How can I do this in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Inferring single cell trajectories with Scanpy (Python)", "datasets": ["data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad"], "dataset_paths": ["data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad"], "dataset_count": 1, "context_summary": "# Run the tutorial!\n\nDataset files (3): data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Final_cell_annotated_object.h5ad, data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Trajectories_Answer_Key.ipynb, data/datasets/single-cell/scrna-case_JUPYTER-trajectories/Trajectories_Instructions.ipynb", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_monocle3-rstudio-q01", "tutorial_id": "topics/single-cell/tutorials/scrna-case_monocle3-rstudio", "query": "I have single-cell RNA-seq data and want to perform batch correction. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Inferring single cell trajectories with Monocle3 (R)", "datasets": ["7455590"], "dataset_paths": ["7455590"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_monocle3-rstudio-q02", "tutorial_id": "topics/single-cell/tutorials/scrna-case_monocle3-rstudio", "query": "How can I annotate cell types in my single-cell RNA-seq data using marker genes?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Inferring single cell trajectories with Monocle3 (R)", "datasets": ["7455590"], "dataset_paths": ["7455590"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_monocle3-rstudio-q03", "tutorial_id": "topics/single-cell/tutorials/scrna-case_monocle3-rstudio", "query": "Which tool can I use to perform differential expression analysis on my single-cell RNA-seq data?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Inferring single cell trajectories with Monocle3 (R)", "datasets": ["7455590"], "dataset_paths": ["7455590"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "scrna-case_monocle3-rstudio-q04", "tutorial_id": "topics/single-cell/tutorials/scrna-case_monocle3-rstudio", "query": "How can I visualize my single-cell RNA-seq data in 3D using dimensionality reduction?", "tools": [], "workflows": [], "metadata": {"topic": "single-cell", "tutorial_title": "Inferring single cell trajectories with Monocle3 (R)", "datasets": ["7455590"], "dataset_paths": ["7455590"], "dataset_count": 1, "context_summary": "{% snippet topics/single-cell/faqs/notebook_warning.md %}", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "deep-learning-without-gai-with-python-q01", "tutorial_id": "topics/statistics/tutorials/deep-learning-without-gai-with-python", "query": "I want to implement a model with convolutional layers using Python. What tools or libraries should I use?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "deep-learning-without-gai-with-python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "deep-learning-without-gai-with-python-q02", "tutorial_id": "topics/statistics/tutorials/deep-learning-without-gai-with-python", "query": "How can I implement a recurrent neural network (RNN) in Python for my time series data?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "deep-learning-without-gai-with-python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "deep-learning-without-gai-with-python-q03", "tutorial_id": "topics/statistics/tutorials/deep-learning-without-gai-with-python", "query": "What tools or libraries are required to implement an attention mechanism in a deep learning model using Python?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "deep-learning-without-gai-with-python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "deep-learning-without-gai-with-python-q04", "tutorial_id": "topics/statistics/tutorials/deep-learning-without-gai-with-python", "query": "How can I fine-tune a pre-trained model for my specific task using Python?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "deep-learning-without-gai-with-python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "dome-q01", "tutorial_id": "topics/statistics/tutorials/dome", "query": "I have a machine learning model and want to evaluate its performance using cross-validation. What tools should I use to assess its accuracy and reliability?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Regulations/standards for AI using DOME", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "With the significant drop in the cost of many high-throughput technologies, vast amounts of biological data are being generated and made available to researchers. Machine learning (ML) has emerged as a **powerful tool for analyzing data** related to cellular processes, genomics, proteomics, post-translational modifications, metabolism, and drug discovery, offering the potential for transformative medical advancements.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "dome-q02", "tutorial_id": "topics/statistics/tutorials/dome", "query": "I need to compare the performance of my machine learning model with a simpler baseline model. How can I do this in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Regulations/standards for AI using DOME", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "With the significant drop in the cost of many high-throughput technologies, vast amounts of biological data are being generated and made available to researchers. Machine learning (ML) has emerged as a **powerful tool for analyzing data** related to cellular processes, genomics, proteomics, post-translational modifications, metabolism, and drug discovery, offering the potential for transformative medical advancements.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "dome-q03", "tutorial_id": "topics/statistics/tutorials/dome", "query": "Which Galaxy tool can I use to release the source code and trained models of my machine learning algorithm?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Regulations/standards for AI using DOME", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "With the significant drop in the cost of many high-throughput technologies, vast amounts of biological data are being generated and made available to researchers. Machine learning (ML) has emerged as a **powerful tool for analyzing data** related to cellular processes, genomics, proteomics, post-translational modifications, metabolism, and drug discovery, offering the potential for transformative medical advancements.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "dome-q04", "tutorial_id": "topics/statistics/tutorials/dome", "query": "How can I report the execution time of my machine learning model averaged across repeats in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Regulations/standards for AI using DOME", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "With the significant drop in the cost of many high-throughput technologies, vast amounts of biological data are being generated and made available to researchers. Machine learning (ML) has emerged as a **powerful tool for analyzing data** related to cellular processes, genomics, proteomics, post-translational modifications, metabolism, and drug discovery, offering the potential for transformative medical advancements.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "fine_tuning_protTrans-q01", "tutorial_id": "topics/statistics/tutorials/fine_tuning_protTrans", "query": "I have a large protein sequence dataset and want to fine-tune a pre-trained language model like ProtT5 for a specific task. What tools do I need to access a GPU-enabled Jupyter Notebook for machine learning?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Fine tune large protein model (ProtTrans) using HuggingFace", "datasets": ["https://zenodo.org/records/10986248"], "dataset_paths": ["https://zenodo.org/records/10986248"], "dataset_count": 1, "context_summary": "The advent of [large language models](https://en.wikipedia.org/wiki/Large_language_model) has transformed the field of natural language processing, enabling machines to comprehend and generate human-like language with unprecedented accuracy. Pre-trained language models, such as [BERT](https://arxiv.org/abs/1810.04805), [RoBERTa](https://arxiv.org/abs/1907.11692), and their variants, have achieved state-of-the-art results on various tasks, from sentiment analysis and question answering to language translation and text classification. Moreover, the emergence of transformer-based models, such as Generative Pre-trained Transformer ([GPT](https://openai.com/index/gpt-2-1-5b-release/)) and its variants, has enabled the creation of highly advanced language models to generate coherent and context-", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "fine_tuning_protTrans-q02", "tutorial_id": "topics/statistics/tutorials/fine_tuning_protTrans", "query": "I want to classify protein sequences using a fine-tuned ProtT5 model. How can I install the necessary Python packages such as Pytorch, Transformers, and SentencePiece in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Fine tune large protein model (ProtTrans) using HuggingFace", "datasets": ["https://zenodo.org/records/10986248"], "dataset_paths": ["https://zenodo.org/records/10986248"], "dataset_count": 1, "context_summary": "The advent of [large language models](https://en.wikipedia.org/wiki/Large_language_model) has transformed the field of natural language processing, enabling machines to comprehend and generate human-like language with unprecedented accuracy. Pre-trained language models, such as [BERT](https://arxiv.org/abs/1810.04805), [RoBERTa](https://arxiv.org/abs/1907.11692), and their variants, have achieved state-of-the-art results on various tasks, from sentiment analysis and question answering to language translation and text classification. Moreover, the emergence of transformer-based models, such as Generative Pre-trained Transformer ([GPT](https://openai.com/index/gpt-2-1-5b-release/)) and its variants, has enabled the creation of highly advanced language models to generate coherent and context-", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "fine_tuning_protTrans-q03", "tutorial_id": "topics/statistics/tutorials/fine_tuning_protTrans", "query": "I have a protein sequence dataset and want to fine-tune a ProtT5 model using low-ranking adaptation technique. How can I configure the model to reduce the number of trainable parameters to 3.5 million?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Fine tune large protein model (ProtTrans) using HuggingFace", "datasets": ["https://zenodo.org/records/10986248"], "dataset_paths": ["https://zenodo.org/records/10986248"], "dataset_count": 1, "context_summary": "The advent of [large language models](https://en.wikipedia.org/wiki/Large_language_model) has transformed the field of natural language processing, enabling machines to comprehend and generate human-like language with unprecedented accuracy. Pre-trained language models, such as [BERT](https://arxiv.org/abs/1810.04805), [RoBERTa](https://arxiv.org/abs/1907.11692), and their variants, have achieved state-of-the-art results on various tasks, from sentiment analysis and question answering to language translation and text classification. Moreover, the emergence of transformer-based models, such as Generative Pre-trained Transformer ([GPT](https://openai.com/index/gpt-2-1-5b-release/)) and its variants, has enabled the creation of highly advanced language models to generate coherent and context-", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "fine_tuning_protTrans-q04", "tutorial_id": "topics/statistics/tutorials/fine_tuning_protTrans", "query": "I have fine-tuned a ProtT5 model on a protein sequence dataset and want to evaluate its performance. What metrics should I use to assess the model's performance, such as accuracy, specificity, and sensitivity?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Fine tune large protein model (ProtTrans) using HuggingFace", "datasets": ["https://zenodo.org/records/10986248"], "dataset_paths": ["https://zenodo.org/records/10986248"], "dataset_count": 1, "context_summary": "The advent of [large language models](https://en.wikipedia.org/wiki/Large_language_model) has transformed the field of natural language processing, enabling machines to comprehend and generate human-like language with unprecedented accuracy. Pre-trained language models, such as [BERT](https://arxiv.org/abs/1810.04805), [RoBERTa](https://arxiv.org/abs/1907.11692), and their variants, have achieved state-of-the-art results on various tasks, from sentiment analysis and question answering to language translation and text classification. Moreover, the emergence of transformer-based models, such as Generative Pre-trained Transformer ([GPT](https://openai.com/index/gpt-2-1-5b-release/)) and its variants, has enabled the creation of highly advanced language models to generate coherent and context-", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "galaxy-ludwig-q01", "tutorial_id": "topics/statistics/tutorials/galaxy-ludwig", "query": "I have images of handwritten digits and their corresponding labels, and I want to build an image recognition model to classify them. What should I do?", "tools": ["toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"], "workflows": ["main_workflow"], "metadata": {"topic": "statistics", "tutorial_title": "Train and Test a Deep learning image classifier with Galaxy-Ludwig", "datasets": ["mnist_images.zip", "mnist_dataset.csv", "config.yaml"], "dataset_paths": ["mnist_images.zip", "mnist_dataset.csv", "config.yaml"], "dataset_count": 3, "context_summary": "> <comment-title>Galaxy-Ludwig Tool</comment-title>", "priority": 1, "version": "v0", "workflow_steps": {"main_workflow": ["toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"}}
{"id": "galaxy-ludwig-q02", "tutorial_id": "topics/statistics/tutorials/galaxy-ludwig", "query": "My image classification model using a stacked CNN is not performing well on the test set. How can I improve its performance?", "tools": ["toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"], "workflows": ["main_workflow"], "metadata": {"topic": "statistics", "tutorial_title": "Train and Test a Deep learning image classifier with Galaxy-Ludwig", "datasets": ["mnist_images.zip", "mnist_dataset.csv", "config.yaml"], "dataset_paths": ["mnist_images.zip", "mnist_dataset.csv", "config.yaml"], "dataset_count": 3, "context_summary": "> <comment-title>Galaxy-Ludwig Tool</comment-title>", "priority": 2, "version": "v0", "workflow_steps": {"main_workflow": ["toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"}}
{"id": "galaxy-ludwig-q03", "tutorial_id": "topics/statistics/tutorials/galaxy-ludwig", "query": "Which Galaxy tool should I use to run a Ludwig experiment with a stacked CNN model on my image classification task?", "tools": ["toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"], "workflows": ["main_workflow"], "metadata": {"topic": "statistics", "tutorial_title": "Train and Test a Deep learning image classifier with Galaxy-Ludwig", "datasets": ["mnist_images.zip", "mnist_dataset.csv", "config.yaml"], "dataset_paths": ["mnist_images.zip", "mnist_dataset.csv", "config.yaml"], "dataset_count": 3, "context_summary": "> <comment-title>Galaxy-Ludwig Tool</comment-title>", "priority": 3, "version": "v0", "workflow_steps": {"main_workflow": ["toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"}}
{"id": "galaxy-ludwig-q04", "tutorial_id": "topics/statistics/tutorials/galaxy-ludwig", "query": "How can I configure the Ludwig experiment tool to use a different number of epochs for my image classification model?", "tools": ["toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"], "workflows": ["main_workflow"], "metadata": {"topic": "statistics", "tutorial_title": "Train and Test a Deep learning image classifier with Galaxy-Ludwig", "datasets": ["mnist_images.zip", "mnist_dataset.csv", "config.yaml"], "dataset_paths": ["mnist_images.zip", "mnist_dataset.csv", "config.yaml"], "dataset_count": 3, "context_summary": "> <comment-title>Galaxy-Ludwig Tool</comment-title>", "priority": 4, "version": "v0", "workflow_steps": {"main_workflow": ["toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/paulo_lyra_jr/ludwig_applications/ludwig_experiment/2024.0.10.3"}}
{"id": "genomic-llm-finetuning-q01", "tutorial_id": "topics/statistics/tutorials/genomic-llm-finetuning", "query": "What tools would I need to use to assess library quality for paired-end FASTQ reads from a ChIP-seq experiment?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Fine-tuning a LLM for DNA Sequence Classification", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "After preparing, training, and utilizing a language model for DNA sequences, we can now fine-tune a pre-trained Large Language Model (LLM) for specific DNA sequence classification tasks. Here, we will use a pre-trained model from Hugging Face, specifically the [Mistral-DNA-v1-17M-hg38](https://huggingface.co/RaphaelMourad/Mistral-DNA-v1-17M-hg38), and adapt it to classify DNA sequences based on their biological functions. Our objective is to classify sequences according to whether they bind to transcription factors.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-finetuning-q02", "tutorial_id": "topics/statistics/tutorials/genomic-llm-finetuning", "query": "How can I clean single-cell FASTQ files showing variable read quality for downstream analysis?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Fine-tuning a LLM for DNA Sequence Classification", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "After preparing, training, and utilizing a language model for DNA sequences, we can now fine-tune a pre-trained Large Language Model (LLM) for specific DNA sequence classification tasks. Here, we will use a pre-trained model from Hugging Face, specifically the [Mistral-DNA-v1-17M-hg38](https://huggingface.co/RaphaelMourad/Mistral-DNA-v1-17M-hg38), and adapt it to classify DNA sequences based on their biological functions. Our objective is to classify sequences according to whether they bind to transcription factors.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-finetuning-q03", "tutorial_id": "topics/statistics/tutorials/genomic-llm-finetuning", "query": "What tools would I need to use to check for adapter contamination and trim low-quality bases in tumor samples?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Fine-tuning a LLM for DNA Sequence Classification", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "After preparing, training, and utilizing a language model for DNA sequences, we can now fine-tune a pre-trained Large Language Model (LLM) for specific DNA sequence classification tasks. Here, we will use a pre-trained model from Hugging Face, specifically the [Mistral-DNA-v1-17M-hg38](https://huggingface.co/RaphaelMourad/Mistral-DNA-v1-17M-hg38), and adapt it to classify DNA sequences based on their biological functions. Our objective is to classify sequences according to whether they bind to transcription factors.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-finetuning-q04", "tutorial_id": "topics/statistics/tutorials/genomic-llm-finetuning", "query": "How do I fine-tune a large language model for DNA sequence classification tasks?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Fine-tuning a LLM for DNA Sequence Classification", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "After preparing, training, and utilizing a language model for DNA sequences, we can now fine-tune a pre-trained Large Language Model (LLM) for specific DNA sequence classification tasks. Here, we will use a pre-trained model from Hugging Face, specifically the [Mistral-DNA-v1-17M-hg38](https://huggingface.co/RaphaelMourad/Mistral-DNA-v1-17M-hg38), and adapt it to classify DNA sequences based on their biological functions. Our objective is to classify sequences according to whether they bind to transcription factors.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-pretraining-q01", "tutorial_id": "topics/statistics/tutorials/genomic-llm-pretraining", "query": "What tools are needed to install dependencies for pretraining a Large Language Model (LLM) from scratch on DNA sequences?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Pretraining a Large Language Model (LLM) from Scratch on DNA Sequences", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "**Generative Artificial Intelligence** (AI) represents a cutting-edge domain within machine learning, focused on creating new, synthetic yet realistic data. This includes generating text, images, music, and even biological sequences. At the heart of many generative AI applications are **Large Language Models** (LLMs), which have revolutionized natural language processing and beyond.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-pretraining-q02", "tutorial_id": "topics/statistics/tutorials/genomic-llm-pretraining", "query": "How can I configure PyTorch and the CUDA environment to optimize GPU memory usage and performance for pretraining a Large Language Model (LLM) from scratch on DNA sequences?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Pretraining a Large Language Model (LLM) from Scratch on DNA Sequences", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "**Generative Artificial Intelligence** (AI) represents a cutting-edge domain within machine learning, focused on creating new, synthetic yet realistic data. This includes generating text, images, music, and even biological sequences. At the heart of many generative AI applications are **Large Language Models** (LLMs), which have revolutionized natural language processing and beyond.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-pretraining-q03", "tutorial_id": "topics/statistics/tutorials/genomic-llm-pretraining", "query": "What tools are required to load and configure a pre-trained tokenizer for processing DNA sequences?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Pretraining a Large Language Model (LLM) from Scratch on DNA Sequences", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "**Generative Artificial Intelligence** (AI) represents a cutting-edge domain within machine learning, focused on creating new, synthetic yet realistic data. This includes generating text, images, music, and even biological sequences. At the heart of many generative AI applications are **Large Language Models** (LLMs), which have revolutionized natural language processing and beyond.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-pretraining-q04", "tutorial_id": "topics/statistics/tutorials/genomic-llm-pretraining", "query": "How can I use a pre-trained LLM to compute the embedding of a DNA sequence?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Pretraining a Large Language Model (LLM) from Scratch on DNA Sequences", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "**Generative Artificial Intelligence** (AI) represents a cutting-edge domain within machine learning, focused on creating new, synthetic yet realistic data. This includes generating text, images, music, and even biological sequences. At the heart of many generative AI applications are **Large Language Models** (LLMs), which have revolutionized natural language processing and beyond.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-sequence-generation-q01", "tutorial_id": "topics/statistics/tutorials/genomic-llm-sequence-generation", "query": "I have a DNA sequence and I want to detect Open Reading Frames (ORFs) in it. Which Galaxy tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Generating Artificial Yeast DNA Sequences using a DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Generating synthetic DNA sequences using pre-trained language models  bridges the fields of synthetic biology and artificial intelligence, enabling the creation of novel DNA sequences that closely mimic natural genomes. By leveraging the power of advanced language models, we can generate biologically relevant sequences that have the potential to revolutionize genetic engineering, drug discovery, and our understanding of genomic function.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-sequence-generation-q02", "tutorial_id": "topics/statistics/tutorials/genomic-llm-sequence-generation", "query": "How can I translate a DNA sequence into a protein sequence in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Generating Artificial Yeast DNA Sequences using a DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Generating synthetic DNA sequences using pre-trained language models  bridges the fields of synthetic biology and artificial intelligence, enabling the creation of novel DNA sequences that closely mimic natural genomes. By leveraging the power of advanced language models, we can generate biologically relevant sequences that have the potential to revolutionize genetic engineering, drug discovery, and our understanding of genomic function.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-sequence-generation-q03", "tutorial_id": "topics/statistics/tutorials/genomic-llm-sequence-generation", "query": "I have a list of DNA sequences and I want to count the occurrences of specific k-mers in each sequence. Which Galaxy tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Generating Artificial Yeast DNA Sequences using a DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Generating synthetic DNA sequences using pre-trained language models  bridges the fields of synthetic biology and artificial intelligence, enabling the creation of novel DNA sequences that closely mimic natural genomes. By leveraging the power of advanced language models, we can generate biologically relevant sequences that have the potential to revolutionize genetic engineering, drug discovery, and our understanding of genomic function.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-sequence-generation-q04", "tutorial_id": "topics/statistics/tutorials/genomic-llm-sequence-generation", "query": "How can I perform a BLAST search for a DNA sequence in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Generating Artificial Yeast DNA Sequences using a DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Generating synthetic DNA sequences using pre-trained language models  bridges the fields of synthetic biology and artificial intelligence, enabling the creation of novel DNA sequences that closely mimic natural genomes. By leveraging the power of advanced language models, we can generate biologically relevant sequences that have the potential to revolutionize genetic engineering, drug discovery, and our understanding of genomic function.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-sequence-optimization-q01", "tutorial_id": "topics/statistics/tutorials/genomic-llm-sequence-optimization", "query": "I want to check the versions of numpy, transformers, and flash_attn. Which tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Optimizing DNA Sequences for Biological Functions using a DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Prepare resources", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-sequence-optimization-q02", "tutorial_id": "topics/statistics/tutorials/genomic-llm-sequence-optimization", "query": "How can I install the required dependencies like datasets, torch, and transformers?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Optimizing DNA Sequences for Biological Functions using a DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Prepare resources", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-sequence-optimization-q03", "tutorial_id": "topics/statistics/tutorials/genomic-llm-sequence-optimization", "query": "I need to prepare a GPU for running the Mistral-DNA model. What steps should I take?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Optimizing DNA Sequences for Biological Functions using a DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Prepare resources", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-sequence-optimization-q04", "tutorial_id": "topics/statistics/tutorials/genomic-llm-sequence-optimization", "query": "How do I set the directory for the Mistral-DNA model and check the current working directory?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Optimizing DNA Sequences for Biological Functions using a DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# Prepare resources", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-zeroshot-prediction-q01", "tutorial_id": "topics/statistics/tutorials/genomic-llm-zeroshot-prediction", "query": "I have a DNA sequence and I want to tokenize it for analysis with a pre-trained DNA language model. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Predicting Mutation Impact with Zero-shot Learning using a pretrained DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Predicting the impact of mutations is a critical task in genomics, as it provides insights into how genetic variations influence biological functions and contribute to diseases. Traditional methods for assessing mutation impact often rely on extensive experimental data or computationally intensive simulations. However, with the advent of large language models (LLMs) and zero-shot learning, we can now predict mutation impacts more efficiently and effectively.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-zeroshot-prediction-q02", "tutorial_id": "topics/statistics/tutorials/genomic-llm-zeroshot-prediction", "query": "I want to load and configure a pre-trained DNA language model for predicting the impact of mutations. How can I do that?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Predicting Mutation Impact with Zero-shot Learning using a pretrained DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Predicting the impact of mutations is a critical task in genomics, as it provides insights into how genetic variations influence biological functions and contribute to diseases. Traditional methods for assessing mutation impact often rely on extensive experimental data or computationally intensive simulations. However, with the advent of large language models (LLMs) and zero-shot learning, we can now predict mutation impacts more efficiently and effectively.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-zeroshot-prediction-q03", "tutorial_id": "topics/statistics/tutorials/genomic-llm-zeroshot-prediction", "query": "Which tool can I use to compute the L2 distance between embeddings of wild-type and mutated DNA sequences?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Predicting Mutation Impact with Zero-shot Learning using a pretrained DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Predicting the impact of mutations is a critical task in genomics, as it provides insights into how genetic variations influence biological functions and contribute to diseases. Traditional methods for assessing mutation impact often rely on extensive experimental data or computationally intensive simulations. However, with the advent of large language models (LLMs) and zero-shot learning, we can now predict mutation impacts more efficiently and effectively.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "genomic-llm-zeroshot-prediction-q04", "tutorial_id": "topics/statistics/tutorials/genomic-llm-zeroshot-prediction", "query": "How can I visualize and compare the predicted effects of SNPs in exons and introns using a boxplot?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Predicting Mutation Impact with Zero-shot Learning using a pretrained DNA LLM", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "Predicting the impact of mutations is a critical task in genomics, as it provides insights into how genetic variations influence biological functions and contribute to diseases. Traditional methods for assessing mutation impact often rely on extensive experimental data or computationally intensive simulations. However, with the advent of large language models (LLMs) and zero-shot learning, we can now predict mutation impacts more efficiently and effectively.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "hyperdimensional_computing-q01", "tutorial_id": "topics/statistics/tutorials/hyperdimensional_computing", "query": "I have a dataset with microbial relative abundance profiles computed with MetaPhlAn3, want to assess if there is a difference in the accuracy of the classification models built on the relative abundance profiles and the binary presence/absence profiles. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Supervised Learning with Hyperdimensional Computing", "datasets": ["RA__ThomasAM__species.csv", "BIN__ThomasAM__species.csv"], "dataset_paths": ["RA__ThomasAM__species.csv", "BIN__ThomasAM__species.csv"], "dataset_count": 2, "context_summary": "`chopin2` ({% cite Cumbo2020 %}) implements a domain-agnostic supervised classification method based on the hyperdimensional (HD) computing paradigm. It is an open-source tool and its code is available on GitHub at [https://github.com/cumbof/chopin2](https://github.com/cumbof/chopin2).", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "hyperdimensional_computing-q02", "tutorial_id": "topics/statistics/tutorials/hyperdimensional_computing", "query": "I have paired datasets with microbial relative abundance profiles and presence/absence information, how can I build a supervised classification model to discriminate case and control samples with a high accuracy using hyperdimensional computing?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Supervised Learning with Hyperdimensional Computing", "datasets": ["RA__ThomasAM__species.csv", "BIN__ThomasAM__species.csv"], "dataset_paths": ["RA__ThomasAM__species.csv", "BIN__ThomasAM__species.csv"], "dataset_count": 2, "context_summary": "`chopin2` ({% cite Cumbo2020 %}) implements a domain-agnostic supervised classification method based on the hyperdimensional (HD) computing paradigm. It is an open-source tool and its code is available on GitHub at [https://github.com/cumbof/chopin2](https://github.com/cumbof/chopin2).", "priority": 2, "version": "v0", "query_type": "science_first"}}
{"id": "hyperdimensional_computing-q03", "tutorial_id": "topics/statistics/tutorials/hyperdimensional_computing", "query": "Which Galaxy tool should I use to build a classification model with hyperdimensional computing for [RA__ThomasAM__species.csv]?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Supervised Learning with Hyperdimensional Computing", "datasets": ["RA__ThomasAM__species.csv"], "dataset_paths": ["RA__ThomasAM__species.csv"], "dataset_count": 1, "context_summary": "`chopin2` ({% cite Cumbo2020 %}) implements a domain-agnostic supervised classification method based on the hyperdimensional (HD) computing paradigm. It is an open-source tool and its code is available on GitHub at [https://github.com/cumbof/chopin2](https://github.com/cumbof/chopin2).", "priority": 3, "version": "v0", "query_type": "tool_first"}}
{"id": "hyperdimensional_computing-q04", "tutorial_id": "topics/statistics/tutorials/hyperdimensional_computing", "query": "How can I identify the best features for building a classification model with hyperdimensional computing for [BIN__ThomasAM__species.csv] in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Supervised Learning with Hyperdimensional Computing", "datasets": ["BIN__ThomasAM__species.csv"], "dataset_paths": ["BIN__ThomasAM__species.csv"], "dataset_count": 1, "context_summary": "`chopin2` ({% cite Cumbo2020 %}) implements a domain-agnostic supervised classification method based on the hyperdimensional (HD) computing paradigm. It is an open-source tool and its code is available on GitHub at [https://github.com/cumbof/chopin2](https://github.com/cumbof/chopin2).", "priority": 4, "version": "v0", "query_type": "tool_first"}}
{"id": "intro-to-ml-with-python-q01", "tutorial_id": "topics/statistics/tutorials/intro-to-ml-with-python", "query": "What tools would I need to use to assess library quality before alignment for paired-end FASTQ reads from a ChIP-seq experiment?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Foundational Aspects of Machine Learning using Python", "datasets": ["ChIP-seq experiment"], "dataset_paths": ["ChIP-seq experiment"], "dataset_count": 1, "context_summary": "Machine Learning is a subset of artificial intelligence that involves training algorithms to learn patterns from data and make predictions or decisions without being explicitly programmed. It has revolutionized various fields, from healthcare and finance to autonomous vehicles and natural language processing.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "intro-to-ml-with-python-q02", "tutorial_id": "topics/statistics/tutorials/intro-to-ml-with-python", "query": "How can I clean single-cell FASTQ files showing variable read quality for downstream analysis?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Foundational Aspects of Machine Learning using Python", "datasets": ["single-cell FASTQ files"], "dataset_paths": ["single-cell FASTQ files"], "dataset_count": 1, "context_summary": "Machine Learning is a subset of artificial intelligence that involves training algorithms to learn patterns from data and make predictions or decisions without being explicitly programmed. It has revolutionized various fields, from healthcare and finance to autonomous vehicles and natural language processing.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "intro-to-ml-with-python-q03", "tutorial_id": "topics/statistics/tutorials/intro-to-ml-with-python", "query": "Which tools can I use to check for adapter contamination and trim low-quality bases for tumor samples?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Foundational Aspects of Machine Learning using Python", "datasets": ["tumor samples"], "dataset_paths": ["tumor samples"], "dataset_count": 1, "context_summary": "Machine Learning is a subset of artificial intelligence that involves training algorithms to learn patterns from data and make predictions or decisions without being explicitly programmed. It has revolutionized various fields, from healthcare and finance to autonomous vehicles and natural language processing.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "intro-to-ml-with-python-q04", "tutorial_id": "topics/statistics/tutorials/intro-to-ml-with-python", "query": "What tools would I need to use to assess read quality and trim adapters and low-quality bases for ChIP-seq experiment?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Foundational Aspects of Machine Learning using Python", "datasets": ["ChIP-seq experiment"], "dataset_paths": ["ChIP-seq experiment"], "dataset_count": 1, "context_summary": "Machine Learning is a subset of artificial intelligence that involves training algorithms to learn patterns from data and make predictions or decisions without being explicitly programmed. It has revolutionized various fields, from healthcare and finance to autonomous vehicles and natural language processing.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "intro-to-ml-with-r-q01", "tutorial_id": "topics/statistics/tutorials/intro-to-ml-with-r", "query": "I want to perform Exploratory Data Analysis (EDA) on my dataset. What tools would I need to use in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Introduction to Machine Learning using R", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is an Introduction to Machine Learning in R, in which you'll learn the basics of unsupervised learning for pattern recognition and supervised learning for prediction. At the end of this workshop, we hope that you will:", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "intro-to-ml-with-r-q02", "tutorial_id": "topics/statistics/tutorials/intro-to-ml-with-r", "query": "How can I cluster my data points using k-means algorithm in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Introduction to Machine Learning using R", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is an Introduction to Machine Learning in R, in which you'll learn the basics of unsupervised learning for pattern recognition and supervised learning for prediction. At the end of this workshop, we hope that you will:", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "intro-to-ml-with-r-q03", "tutorial_id": "topics/statistics/tutorials/intro-to-ml-with-r", "query": "I want to build a decision tree model to predict labels in my dataset. What tools would I need to use in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Introduction to Machine Learning using R", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is an Introduction to Machine Learning in R, in which you'll learn the basics of unsupervised learning for pattern recognition and supervised learning for prediction. At the end of this workshop, we hope that you will:", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "intro-to-ml-with-r-q04", "tutorial_id": "topics/statistics/tutorials/intro-to-ml-with-r", "query": "How can I evaluate the performance of my linear regression model in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Introduction to Machine Learning using R", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "This is an Introduction to Machine Learning in R, in which you'll learn the basics of unsupervised learning for pattern recognition and supervised learning for prediction. At the end of this workshop, we hope that you will:", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "loris_model-q01", "tutorial_id": "topics/statistics/tutorials/loris_model", "query": "I have a dataset (Chowell_train_Response.tsv) and I want to build a machine learning model for ICB treatment patient selection using clinical data. Which Galaxy tool should I use to start the process?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Building the LORIS LLR6 PanCancer Model Using PyCaret", "datasets": ["Chowell_train_Response.tsv"], "dataset_paths": ["Chowell_train_Response.tsv"], "dataset_count": 1, "context_summary": "> <comment-title>PyCaret Model Comparison Tool</comment-title>", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "loris_model-q02", "tutorial_id": "topics/statistics/tutorials/loris_model", "query": "How can I evaluate the performance of a machine learning model built using the PyCaret Comparison Tool in Galaxy, using the metrics published by Chang et al. (2024) as the gold standard?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Building the LORIS LLR6 PanCancer Model Using PyCaret", "datasets": ["Chowell_test_Response.tsv"], "dataset_paths": ["Chowell_test_Response.tsv"], "dataset_count": 1, "context_summary": "> <comment-title>PyCaret Model Comparison Tool</comment-title>", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "loris_model-q03", "tutorial_id": "topics/statistics/tutorials/loris_model", "query": "I want to compare the performance of different machine learning models for ICB treatment patient selection. Which tool in Galaxy can I use to train and compare multiple models with minimal code?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Building the LORIS LLR6 PanCancer Model Using PyCaret", "datasets": ["Chowell_train_Response.tsv"], "dataset_paths": ["Chowell_train_Response.tsv"], "dataset_count": 1, "context_summary": "> <comment-title>PyCaret Model Comparison Tool</comment-title>", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "loris_model-q04", "tutorial_id": "topics/statistics/tutorials/loris_model", "query": "How can I interpret the results of the PyCaret Model Comparison Tool in Galaxy, specifically the PyCaret Model Report, to understand the performance of my machine learning model?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Building the LORIS LLR6 PanCancer Model Using PyCaret", "datasets": ["PyCaret Model Report"], "dataset_paths": ["PyCaret Model Report"], "dataset_count": 1, "context_summary": "> <comment-title>PyCaret Model Comparison Tool</comment-title>", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "machinelearning-q01", "tutorial_id": "topics/statistics/tutorials/machinelearning", "query": "I have a dataset of breast cancer features and want to train a classifier to predict cancer presence. What should I do?", "tools": ["toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"], "workflows": ["machine_learning.eu", "machine_learning"], "metadata": {"topic": "statistics", "tutorial_title": "Basics of machine learning", "datasets": ["data/datasets/statistics/machinelearning/breast-w_train.tsv"], "dataset_paths": ["data/datasets/statistics/machinelearning/breast-w_train.tsv"], "dataset_count": 1, "context_summary": "[Machine learning](https://en.wikipedia.org/wiki/Machine_learning) uses techniques from statistics, mathematics and computer science to make computer programs learn from data. It is one of the most popular fields of computer science and finds applications in multiple streams of data analysis such as [classification](https://en.wikipedia.org/wiki/Statistical_classification), [regression](https://en.wikipedia.org/wiki/Regression_analysis), [clustering](https://en.wikipedia.org/wiki/Cluster_analysis), [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction), [density estimation](https://en.wikipedia.org/wiki/Density_estimation) and many more. Some real-life applications are spam filtering, medical diagnosis, autonomous driving, recommendation systems, facial recognit\n\nDataset files (2): data/datasets/statistics/machinelearning/breast-w_test.tsv, data/datasets/statistics/machinelearning/breast-w_train.tsv", "priority": 1, "version": "v0", "workflow_steps": {"machine_learning": ["toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1", "toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"}}
{"id": "machinelearning-q02", "tutorial_id": "topics/statistics/tutorials/machinelearning", "query": "My dataset of breast cancer features has 9 features and a target variable; how can I use machine learning to classify new samples?", "tools": ["toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"], "workflows": ["machine_learning.eu", "machine_learning"], "metadata": {"topic": "statistics", "tutorial_title": "Basics of machine learning", "datasets": ["data/datasets/statistics/machinelearning/breast-w_train.tsv", "data/datasets/statistics/machinelearning/breast-w_test.tsv"], "dataset_paths": ["data/datasets/statistics/machinelearning/breast-w_train.tsv", "data/datasets/statistics/machinelearning/breast-w_test.tsv"], "dataset_count": 2, "context_summary": "[Machine learning](https://en.wikipedia.org/wiki/Machine_learning) uses techniques from statistics, mathematics and computer science to make computer programs learn from data. It is one of the most popular fields of computer science and finds applications in multiple streams of data analysis such as [classification](https://en.wikipedia.org/wiki/Statistical_classification), [regression](https://en.wikipedia.org/wiki/Regression_analysis), [clustering](https://en.wikipedia.org/wiki/Cluster_analysis), [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction), [density estimation](https://en.wikipedia.org/wiki/Density_estimation) and many more. Some real-life applications are spam filtering, medical diagnosis, autonomous driving, recommendation systems, facial recognit\n\nDataset files (2): data/datasets/statistics/machinelearning/breast-w_test.tsv, data/datasets/statistics/machinelearning/breast-w_train.tsv", "priority": 2, "version": "v0", "workflow_steps": {"machine_learning": ["toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1", "toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"}}
{"id": "machinelearning-q03", "tutorial_id": "topics/statistics/tutorials/machinelearning", "query": "Which Galaxy tool should I use to train a support vector machine classifier on my breast cancer dataset?", "tools": ["toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"], "workflows": ["machine_learning.eu", "machine_learning"], "metadata": {"topic": "statistics", "tutorial_title": "Basics of machine learning", "datasets": ["data/datasets/statistics/machinelearning/breast-w_train.tsv"], "dataset_paths": ["data/datasets/statistics/machinelearning/breast-w_train.tsv"], "dataset_count": 1, "context_summary": "[Machine learning](https://en.wikipedia.org/wiki/Machine_learning) uses techniques from statistics, mathematics and computer science to make computer programs learn from data. It is one of the most popular fields of computer science and finds applications in multiple streams of data analysis such as [classification](https://en.wikipedia.org/wiki/Statistical_classification), [regression](https://en.wikipedia.org/wiki/Regression_analysis), [clustering](https://en.wikipedia.org/wiki/Cluster_analysis), [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction), [density estimation](https://en.wikipedia.org/wiki/Density_estimation) and many more. Some real-life applications are spam filtering, medical diagnosis, autonomous driving, recommendation systems, facial recognit\n\nDataset files (2): data/datasets/statistics/machinelearning/breast-w_test.tsv, data/datasets/statistics/machinelearning/breast-w_train.tsv", "priority": 3, "version": "v0", "workflow_steps": {"machine_learning": ["toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1", "toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"}}
{"id": "machinelearning-q04", "tutorial_id": "topics/statistics/tutorials/machinelearning", "query": "How can I use a trained model to predict cancer presence for new breast cancer feature data in Galaxy?", "tools": ["toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"], "workflows": ["machine_learning.eu", "machine_learning"], "metadata": {"topic": "statistics", "tutorial_title": "Basics of machine learning", "datasets": ["data/datasets/statistics/machinelearning/breast-w_test.tsv"], "dataset_paths": ["data/datasets/statistics/machinelearning/breast-w_test.tsv"], "dataset_count": 1, "context_summary": "[Machine learning](https://en.wikipedia.org/wiki/Machine_learning) uses techniques from statistics, mathematics and computer science to make computer programs learn from data. It is one of the most popular fields of computer science and finds applications in multiple streams of data analysis such as [classification](https://en.wikipedia.org/wiki/Statistical_classification), [regression](https://en.wikipedia.org/wiki/Regression_analysis), [clustering](https://en.wikipedia.org/wiki/Cluster_analysis), [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction), [density estimation](https://en.wikipedia.org/wiki/Density_estimation) and many more. Some real-life applications are spam filtering, medical diagnosis, autonomous driving, recommendation systems, facial recognit\n\nDataset files (2): data/datasets/statistics/machinelearning/breast-w_test.tsv, data/datasets/statistics/machinelearning/breast-w_train.tsv", "priority": 4, "version": "v0", "workflow_steps": {"machine_learning": ["toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1", "toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/bgruening/sklearn_svm_classifier/sklearn_svm_classifier/1.0.8.1"}}
{"id": "neural-networks-with-python-q01", "tutorial_id": "topics/statistics/tutorials/neural-networks-with-python", "query": "I want to initialize a model with a single layer using Python, what tools do I need to make it work?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "neural-networks-with-python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "neural-networks-with-python-q02", "tutorial_id": "topics/statistics/tutorials/neural-networks-with-python", "query": "How can I train a neural network model with multiple layers using Python?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "neural-networks-with-python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "neural-networks-with-python-q03", "tutorial_id": "topics/statistics/tutorials/neural-networks-with-python", "query": "What tools are required to implement the forward step in a neural network using Python?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "neural-networks-with-python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "neural-networks-with-python-q04", "tutorial_id": "topics/statistics/tutorials/neural-networks-with-python", "query": "How do I save and load trained neural network models in Python?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "neural-networks-with-python", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "---", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "text-mining_simtext-q01", "tutorial_id": "topics/statistics/tutorials/text-mining_simtext", "query": "I have a list of genes and their pre-existing grouping, and I want to collect PubMed data for each of the genes. What tool should I use to download a defined number of PMIDs from PubMed for each gene?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Text-mining with the SimText toolset", "datasets": ["clingen_data"], "dataset_paths": ["clingen_data"], "dataset_count": 1, "context_summary": "Literature exploration in [PubMed](https://pubmed.ncbi.nlm.nih.gov/) on a large number of biomedical entities (e.g., genes, diseases, or experiments) can be time-consuming and challenging, especially when assessing associations between entities. Here, we use SimText, a toolset for literature research that allows you to collect text from PubMed for any given set of biomedical entities, extract associated terms, and analyze similarities among them and their key characteristics in an interactive tool.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "text-mining_simtext-q02", "tutorial_id": "topics/statistics/tutorials/text-mining_simtext", "query": "How can I extract the 100 most frequent 'Disease' and 'Gene' terms from PubMed abstracts for a list of genes, and combine them in one large binary matrix?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Text-mining with the SimText toolset", "datasets": ["clingen_data"], "dataset_paths": ["clingen_data"], "dataset_count": 1, "context_summary": "Literature exploration in [PubMed](https://pubmed.ncbi.nlm.nih.gov/) on a large number of biomedical entities (e.g., genes, diseases, or experiments) can be time-consuming and challenging, especially when assessing associations between entities. Here, we use SimText, a toolset for literature research that allows you to collect text from PubMed for any given set of biomedical entities, extract associated terms, and analyze similarities among them and their key characteristics in an interactive tool.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "text-mining_simtext-q03", "tutorial_id": "topics/statistics/tutorials/text-mining_simtext", "query": "Which tool can I use to explore the similarities and grouping among genes based on their extracted terms from the literature, and compare it to their pre-existing disorder categories?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Text-mining with the SimText toolset", "datasets": ["clingen_data"], "dataset_paths": ["clingen_data"], "dataset_count": 1, "context_summary": "Literature exploration in [PubMed](https://pubmed.ncbi.nlm.nih.gov/) on a large number of biomedical entities (e.g., genes, diseases, or experiments) can be time-consuming and challenging, especially when assessing associations between entities. Here, we use SimText, a toolset for literature research that allows you to collect text from PubMed for any given set of biomedical entities, extract associated terms, and analyze similarities among them and their key characteristics in an interactive tool.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "text-mining_simtext-q04", "tutorial_id": "topics/statistics/tutorials/text-mining_simtext", "query": "I have a large binary matrix of genes and their associated terms, and I want to perform dimension reduction and hierarchical clustering on it. How can I do this in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "statistics", "tutorial_title": "Text-mining with the SimText toolset", "datasets": ["clingen_data"], "dataset_paths": ["clingen_data"], "dataset_count": 1, "context_summary": "Literature exploration in [PubMed](https://pubmed.ncbi.nlm.nih.gov/) on a large number of biomedical entities (e.g., genes, diseases, or experiments) can be time-consuming and challenging, especially when assessing associations between entities. Here, we use SimText, a toolset for literature research that allows you to collect text from PubMed for any given set of biomedical entities, extract associated terms, and analyze similarities among them and their key characteristics in an interactive tool.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "rb-rnaseq-q01", "tutorial_id": "topics/transcriptomics/tutorials/rb-rnaseq", "query": "I have paired-end RNA-seq reads from a Drosophila melanogaster experiment and I want to map them to the dm3 genome. Which Galaxy tool should I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Reference-based RNAseq data analysis (long)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# RNAseq: Reference-based", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "rb-rnaseq-q02", "tutorial_id": "topics/transcriptomics/tutorials/rb-rnaseq", "query": "How can I perform differential expression analysis on my RNA-seq data using Galaxy tools?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Reference-based RNAseq data analysis (long)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# RNAseq: Reference-based", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "rb-rnaseq-q03", "tutorial_id": "topics/transcriptomics/tutorials/rb-rnaseq", "query": "I have a GTF file containing gene annotations for Drosophila melanogaster and I want to use it with HTseq-count in Galaxy. Which tool should I use to filter out unstranded features from the GTF file?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Reference-based RNAseq data analysis (long)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# RNAseq: Reference-based", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "rb-rnaseq-q04", "tutorial_id": "topics/transcriptomics/tutorials/rb-rnaseq", "query": "How can I normalize my read counts and compute differential expression using DESeq2 in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Reference-based RNAseq data analysis (long)", "datasets": [], "dataset_paths": [], "dataset_count": 0, "context_summary": "# RNAseq: Reference-based", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-analysis-with-askomics-it-q01", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-analysis-with-askomics-it", "query": "I have a GFF file and a tabular file, how can I integrate them into RDF triples using AskOmics?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA-Seq analysis with AskOmics Interactive Tool", "datasets": ["Mus musculus.GRCm38.98.subset.gff3", "Symbol.tsv"], "dataset_paths": ["Mus musculus.GRCm38.98.subset.gff3", "Symbol.tsv"], "dataset_count": 2, "context_summary": "AskOmics is a web application for data integration and querying using the Semantic Web technologies. It helps users to convert multiple data sources (CSV/TSV files, GFF and BED annotation) into \"RDF triples\" and store them in a specific kind of database: an \"RDF triplestore\". Under this form, data can then be queried using a specific language: \"SPARQL\". AskOmics hides the complexity of these technologies and allows to perform complex queries using a user-friendly interface.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-analysis-with-askomics-it-q02", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-analysis-with-askomics-it", "query": "I have a list of differentially expressed genes, how can I use AskOmics to find their human homologs and the location of the proteins coded by these genes?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA-Seq analysis with AskOmics Interactive Tool", "datasets": ["limma-voom_luminalpregnant-luminallactate", "HOM_MouseHumanSequence.rpt"], "dataset_paths": ["limma-voom_luminalpregnant-luminallactate", "HOM_MouseHumanSequence.rpt"], "dataset_count": 2, "context_summary": "AskOmics is a web application for data integration and querying using the Semantic Web technologies. It helps users to convert multiple data sources (CSV/TSV files, GFF and BED annotation) into \"RDF triples\" and store them in a specific kind of database: an \"RDF triplestore\". Under this form, data can then be queried using a specific language: \"SPARQL\". AskOmics hides the complexity of these technologies and allows to perform complex queries using a user-friendly interface.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-analysis-with-askomics-it-q03", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-analysis-with-askomics-it", "query": "Which tool can I use to convert a GFF file into RDF triples?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA-Seq analysis with AskOmics Interactive Tool", "datasets": ["Mus musculus.GRCm38.98.subset.gff3"], "dataset_paths": ["Mus musculus.GRCm38.98.subset.gff3"], "dataset_count": 1, "context_summary": "AskOmics is a web application for data integration and querying using the Semantic Web technologies. It helps users to convert multiple data sources (CSV/TSV files, GFF and BED annotation) into \"RDF triples\" and store them in a specific kind of database: an \"RDF triplestore\". Under this form, data can then be queried using a specific language: \"SPARQL\". AskOmics hides the complexity of these technologies and allows to perform complex queries using a user-friendly interface.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-analysis-with-askomics-it-q04", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-analysis-with-askomics-it", "query": "How can I use AskOmics to filter genes based on their location on a specific chromosome and strand?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA-Seq analysis with AskOmics Interactive Tool", "datasets": ["limma-voom_luminalpregnant-luminallactate", "Mus musculus.GRCm38.98.subset.gff3"], "dataset_paths": ["limma-voom_luminalpregnant-luminallactate", "Mus musculus.GRCm38.98.subset.gff3"], "dataset_count": 2, "context_summary": "AskOmics is a web application for data integration and querying using the Semantic Web technologies. It helps users to convert multiple data sources (CSV/TSV files, GFF and BED annotation) into \"RDF triples\" and store them in a specific kind of database: an \"RDF triplestore\". Under this form, data can then be queried using a specific language: \"SPARQL\". AskOmics hides the complexity of these technologies and allows to perform complex queries using a user-friendly interface.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-bash-star-align-q01", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-bash-star-align", "query": "I have paired-end FASTQ reads from an RNA-seq experiment (GSM461177_1 and GSM461177_2), want to assess library quality before alignment. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA-seq Alignment with STAR", "datasets": ["GSM461177_1", "GSM461177_2"], "dataset_paths": ["GSM461177_1", "GSM461177_2"], "dataset_count": 2, "context_summary": "In recent years, RNA sequencing (in short RNA-Seq) has become a very widely used technology to analyze the continuously changing cellular transcriptome, i.e. the set of all RNA molecules in one cell or a population of cells. One of the most common aims of RNA-Seq is the profiling of gene expression by identifying genes or molecular pathways that are differentially expressed (DE) between two or more biological conditions. This tutorial demonstrates a computational workflow for counting and locating the genes in RNA sequences. The first and most critical step in an RNA-seq analysis.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "rna-seq-bash-star-align-q02", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-bash-star-align", "query": "Which Galaxy tool should I use to assess read quality for GSM461177_1?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA-seq Alignment with STAR", "datasets": ["GSM461177_1"], "dataset_paths": ["GSM461177_1"], "dataset_count": 1, "context_summary": "In recent years, RNA sequencing (in short RNA-Seq) has become a very widely used technology to analyze the continuously changing cellular transcriptome, i.e. the set of all RNA molecules in one cell or a population of cells. One of the most common aims of RNA-Seq is the profiling of gene expression by identifying genes or molecular pathways that are differentially expressed (DE) between two or more biological conditions. This tutorial demonstrates a computational workflow for counting and locating the genes in RNA sequences. The first and most critical step in an RNA-seq analysis.", "priority": 2, "version": "v0", "query_type": "tool_first"}}
{"id": "rna-seq-bash-star-align-q03", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-bash-star-align", "query": "How can I trim adapters and low-quality bases on GSM461177_1 and GSM461177_2 in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA-seq Alignment with STAR", "datasets": ["GSM461177_1", "GSM461177_2"], "dataset_paths": ["GSM461177_1", "GSM461177_2"], "dataset_count": 2, "context_summary": "In recent years, RNA sequencing (in short RNA-Seq) has become a very widely used technology to analyze the continuously changing cellular transcriptome, i.e. the set of all RNA molecules in one cell or a population of cells. One of the most common aims of RNA-Seq is the profiling of gene expression by identifying genes or molecular pathways that are differentially expressed (DE) between two or more biological conditions. This tutorial demonstrates a computational workflow for counting and locating the genes in RNA sequences. The first and most critical step in an RNA-seq analysis.", "priority": 3, "version": "v0", "query_type": "science_first"}}
{"id": "rna-seq-bash-star-align-q04", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-bash-star-align", "query": "I want to align my RNA-seq reads (GSM461177_1 and GSM461177_2) to a reference genome using STAR. What are the necessary steps?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA-seq Alignment with STAR", "datasets": ["GSM461177_1", "GSM461177_2"], "dataset_paths": ["GSM461177_1", "GSM461177_2"], "dataset_count": 2, "context_summary": "In recent years, RNA sequencing (in short RNA-Seq) has become a very widely used technology to analyze the continuously changing cellular transcriptome, i.e. the set of all RNA molecules in one cell or a population of cells. One of the most common aims of RNA-Seq is the profiling of gene expression by identifying genes or molecular pathways that are differentially expressed (DE) between two or more biological conditions. This tutorial demonstrates a computational workflow for counting and locating the genes in RNA sequences. The first and most critical step in an RNA-seq analysis.", "priority": 4, "version": "v0", "query_type": "science_first"}}
{"id": "rna-seq-counts-to-viz-in-r-q01", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-counts-to-viz-in-r", "query": "I have a list of differentially expressed genes from a RNA-seq experiment and I want to create a volcano plot. What tools or programming languages should I use to achieve this?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA Seq Counts to Viz in R", "datasets": ["annotatedDEgenes.tabular"], "dataset_paths": ["annotatedDEgenes.tabular"], "dataset_count": 1, "context_summary": "This tutorial will show you how to visualise RNA Sequencing Counts with R", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-counts-to-viz-in-r-q02", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-counts-to-viz-in-r", "query": "How can I use Galaxy to load a table of differentially expressed genes and then create a volcano plot with a specific color scheme and axis labels?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA Seq Counts to Viz in R", "datasets": ["annotatedDEgenes.tabular"], "dataset_paths": ["annotatedDEgenes.tabular"], "dataset_count": 1, "context_summary": "This tutorial will show you how to visualise RNA Sequencing Counts with R", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-counts-to-viz-in-r-q03", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-counts-to-viz-in-r", "query": "What tool can I use in Galaxy to split my volcano plot into multiple panels based on a specific factor in my dataset?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA Seq Counts to Viz in R", "datasets": ["annotatedDEgenes.tabular"], "dataset_paths": ["annotatedDEgenes.tabular"], "dataset_count": 1, "context_summary": "This tutorial will show you how to visualise RNA Sequencing Counts with R", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-counts-to-viz-in-r-q04", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-counts-to-viz-in-r", "query": "How can I create a barplot showing the number of differentially expressed genes for each feature with one plot per chromosome using Galaxy tools?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "RNA Seq Counts to Viz in R", "datasets": ["annotatedDEgenes.tabular"], "dataset_paths": ["annotatedDEgenes.tabular"], "dataset_count": 1, "context_summary": "This tutorial will show you how to visualise RNA Sequencing Counts with R", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-viz-with-cummerbund-q01", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-cummerbund", "query": "I have a SQLite database file from CuffDiff and want to extract the transcript differential expression testing results. Which Galaxy tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with CummeRbund", "datasets": ["CuffDiff SQLite database"], "dataset_paths": ["CuffDiff SQLite database"], "dataset_count": 1, "context_summary": "RNA-Seq analysis helps researchers annotate new genes and splice variants, and provides cell- and context-specific quantification of gene expression. RNA-Seq data, however, are complex and require both computer science and mathematical knowledge to be managed and interpreted.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-viz-with-cummerbund-q02", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-cummerbund", "query": "How can I filter the CuffDiff results to only include significant differentially expressed genes in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with CummeRbund", "datasets": ["CuffDiff SQLite database"], "dataset_paths": ["CuffDiff SQLite database"], "dataset_count": 1, "context_summary": "RNA-Seq analysis helps researchers annotate new genes and splice variants, and provides cell- and context-specific quantification of gene expression. RNA-Seq data, however, are complex and require both computer science and mathematical knowledge to be managed and interpreted.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-viz-with-cummerbund-q03", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-cummerbund", "query": "I want to visualize the expression levels of specific genes across different conditions using CummeRbund. What tool can I use to generate an expression plot?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with CummeRbund", "datasets": ["CuffDiff SQLite database"], "dataset_paths": ["CuffDiff SQLite database"], "dataset_count": 1, "context_summary": "RNA-Seq analysis helps researchers annotate new genes and splice variants, and provides cell- and context-specific quantification of gene expression. RNA-Seq data, however, are complex and require both computer science and mathematical knowledge to be managed and interpreted.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-viz-with-cummerbund-q04", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-cummerbund", "query": "How can I sort the CuffDiff results by Q-score and log2 fold change in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with CummeRbund", "datasets": ["CuffDiff SQLite database"], "dataset_paths": ["CuffDiff SQLite database"], "dataset_count": 1, "context_summary": "RNA-Seq analysis helps researchers annotate new genes and splice variants, and provides cell- and context-specific quantification of gene expression. RNA-Seq data, however, are complex and require both computer science and mathematical knowledge to be managed and interpreted.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-viz-with-volcanoplot-q01", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot", "query": "I have RNA-seq data and want to visualize the results to identify statistically significant genes with large fold changes. What type of plot should I use?", "tools": ["toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"], "workflows": ["Visualization-Of-RNA-Seq-Results-With-Volcano-Plot"], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with Volcano Plot", "datasets": ["limma-voom_luminalpregnant-luminallactate", "volcano_genes"], "dataset_paths": ["limma-voom_luminalpregnant-luminallactate", "volcano_genes"], "dataset_count": 2, "context_summary": "![Volcano plot highlighting significant genes](../../images/rna-seq-viz-with-volcanoplot/volcanoplot.png){: style=\"float:right;width:60%\" }", "priority": 1, "version": "v0", "workflow_steps": {"Visualization-Of-RNA-Seq-Results-With-Volcano-Plot": ["toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7", "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7", "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"}}
{"id": "rna-seq-viz-with-volcanoplot-q02", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot", "query": "My RNA-seq data shows a list of differentially expressed genes; how can I create a volcano plot to visualize the results and highlight significant genes?", "tools": ["toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"], "workflows": ["Visualization-Of-RNA-Seq-Results-With-Volcano-Plot"], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with Volcano Plot", "datasets": ["limma-voom_luminalpregnant-luminallactate", "volcano_genes"], "dataset_paths": ["limma-voom_luminalpregnant-luminallactate", "volcano_genes"], "dataset_count": 2, "context_summary": "![Volcano plot highlighting significant genes](../../images/rna-seq-viz-with-volcanoplot/volcanoplot.png){: style=\"float:right;width:60%\" }", "priority": 2, "version": "v0", "workflow_steps": {"Visualization-Of-RNA-Seq-Results-With-Volcano-Plot": ["toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7", "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7", "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"]}, "query_type": "science_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"}}
{"id": "rna-seq-viz-with-volcanoplot-q03", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot", "query": "Which Galaxy tool can I use to create a volcano plot from my RNA-seq data?", "tools": ["toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"], "workflows": ["Visualization-Of-RNA-Seq-Results-With-Volcano-Plot"], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with Volcano Plot", "datasets": ["limma-voom_luminalpregnant-luminallactate"], "dataset_paths": ["limma-voom_luminalpregnant-luminallactate"], "dataset_count": 1, "context_summary": "![Volcano plot highlighting significant genes](../../images/rna-seq-viz-with-volcanoplot/volcanoplot.png){: style=\"float:right;width:60%\" }", "priority": 3, "version": "v0", "workflow_steps": {"Visualization-Of-RNA-Seq-Results-With-Volcano-Plot": ["toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7", "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7", "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"}}
{"id": "rna-seq-viz-with-volcanoplot-q04", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot", "query": "I have a list of differentially expressed genes and want to label specific genes of interest on a volcano plot; how can I do this in Galaxy?", "tools": ["toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"], "workflows": ["Visualization-Of-RNA-Seq-Results-With-Volcano-Plot"], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with Volcano Plot", "datasets": ["limma-voom_luminalpregnant-luminallactate", "volcano_genes"], "dataset_paths": ["limma-voom_luminalpregnant-luminallactate", "volcano_genes"], "dataset_count": 2, "context_summary": "![Volcano plot highlighting significant genes](../../images/rna-seq-viz-with-volcanoplot/volcanoplot.png){: style=\"float:right;width:60%\" }", "priority": 4, "version": "v0", "workflow_steps": {"Visualization-Of-RNA-Seq-Results-With-Volcano-Plot": ["toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7", "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7", "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"]}, "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/iuc/volcanoplot/volcanoplot/0.0.7"}}
{"id": "rna-seq-viz-with-volcanoplot-r-q01", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot-r", "query": "I have a differential expression results file and I want to create a volcano plot with it. Which Galaxy tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with Volcano Plot in R", "datasets": ["limma-voom_luminalpregnant-luminallactate"], "dataset_paths": ["limma-voom_luminalpregnant-luminallactate"], "dataset_count": 1, "context_summary": "The [Volcano plot]({% link topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot/tutorial.md %}) tutorial, introduced volcano plots and showed how they can be generated with the Galaxy Volcano plot tool. In this tutorial we show how you can customise a plot using the R script output from the tool.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-viz-with-volcanoplot-r-q02", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot-r", "query": "How can I customize the colors of points in a volcano plot generated by a Galaxy tool?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with Volcano Plot in R", "datasets": ["limma-voom_luminalpregnant-luminallactate"], "dataset_paths": ["limma-voom_luminalpregnant-luminallactate"], "dataset_count": 1, "context_summary": "The [Volcano plot]({% link topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot/tutorial.md %}) tutorial, introduced volcano plots and showed how they can be generated with the Galaxy Volcano plot tool. In this tutorial we show how you can customise a plot using the R script output from the tool.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-viz-with-volcanoplot-r-q03", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot-r", "query": "I have a volcano plot generated by a Galaxy tool and I want to change the font size of the labels. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with Volcano Plot in R", "datasets": ["limma-voom_luminalpregnant-luminallactate"], "dataset_paths": ["limma-voom_luminalpregnant-luminallactate"], "dataset_count": 1, "context_summary": "The [Volcano plot]({% link topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot/tutorial.md %}) tutorial, introduced volcano plots and showed how they can be generated with the Galaxy Volcano plot tool. In this tutorial we show how you can customise a plot using the R script output from the tool.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "rna-seq-viz-with-volcanoplot-r-q04", "tutorial_id": "topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot-r", "query": "Which tool can I use to edit the R script output from the Galaxy Volcano plot tool?", "tools": [], "workflows": [], "metadata": {"topic": "transcriptomics", "tutorial_title": "Visualization of RNA-Seq results with Volcano Plot in R", "datasets": ["limma-voom_luminalpregnant-luminallactate"], "dataset_paths": ["limma-voom_luminalpregnant-luminallactate"], "dataset_count": 1, "context_summary": "The [Volcano plot]({% link topics/transcriptomics/tutorials/rna-seq-viz-with-volcanoplot/tutorial.md %}) tutorial, introduced volcano plots and showed how they can be generated with the Galaxy Volcano plot tool. In this tutorial we show how you can customise a plot using the R script output from the tool.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "aiv-analysis-q01", "tutorial_id": "topics/variant-analysis/tutorials/aiv-analysis", "query": "I have paired-end FASTQ reads from an avian influenza sequencing experiment and want to assess library quality before analysis. What should I do?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Avian influenza viral strain analysis from gene segment sequencing data", "datasets": ["Sequencing data"], "dataset_paths": ["Sequencing data"], "dataset_count": 1, "context_summary": "Of the four species of influenza viruses (Influenza A-D), *Influenza A* is the most virulent in human hosts and subtypes of it have been responsible for all historic flu pandemics.", "priority": 1, "version": "v0", "query_type": "science_first"}}
{"id": "aiv-analysis-q02", "tutorial_id": "topics/variant-analysis/tutorials/aiv-analysis", "query": "My reads from an avian influenza sample show variable quality; how can I trim low-quality bases and adapters in Galaxy?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Avian influenza viral strain analysis from gene segment sequencing data", "datasets": ["Sequencing data"], "dataset_paths": ["Sequencing data"], "dataset_count": 1, "context_summary": "Of the four species of influenza viruses (Influenza A-D), *Influenza A* is the most virulent in human hosts and subtypes of it have been responsible for all historic flu pandemics.", "priority": 2, "version": "v0", "query_type": "science_first"}}
{"id": "aiv-analysis-q03", "tutorial_id": "topics/variant-analysis/tutorials/aiv-analysis", "query": "Which Galaxy tool should I use to assess read quality for the quality-trimmed reads?", "tools": ["toolshed.g2.bx.psu.edu/repos/iuc/fastp/fastp/0.23.4+galaxy1"], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Avian influenza viral strain analysis from gene segment sequencing data", "datasets": ["quality-trimmed reads"], "dataset_paths": ["quality-trimmed reads"], "dataset_count": 1, "context_summary": "Of the four species of influenza viruses (Influenza A-D), *Influenza A* is the most virulent in human hosts and subtypes of it have been responsible for all historic flu pandemics.", "priority": 3, "version": "v0", "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/iuc/fastp/fastp/0.23.4+galaxy1"}}
{"id": "aiv-analysis-q04", "tutorial_id": "topics/variant-analysis/tutorials/aiv-analysis", "query": "How can I map the quality-trimmed reads to a hybrid reference genome in Galaxy?", "tools": ["toolshed.g2.bx.psu.edu/repos/devteam/bwa/bwa_mem/0.7.18"], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Avian influenza viral strain analysis from gene segment sequencing data", "datasets": ["hybrid reference genome with shortened names", "quality-trimmed reads"], "dataset_paths": ["hybrid reference genome with shortened names", "quality-trimmed reads"], "dataset_count": 2, "context_summary": "Of the four species of influenza viruses (Influenza A-D), *Influenza A* is the most virulent in human hosts and subtypes of it have been responsible for all historic flu pandemics.", "priority": 4, "version": "v0", "query_type": "tool_first", "tool_focus": "toolshed.g2.bx.psu.edu/repos/devteam/bwa/bwa_mem/0.7.18"}}
{"id": "beacon_cnv_query-q01", "tutorial_id": "topics/variant-analysis/tutorials/beacon_cnv_query", "query": "I want to query the Beacon database to retrieve CNV records for a specific genomic location. What tool should I use?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Querying the University of Bradford GDC Beacon Database for Copy Number Variants (CNVs)", "datasets": ["https://zenodo.org/records/10658688"], "dataset_paths": ["https://zenodo.org/records/10658688"], "dataset_count": 1, "context_summary": "The concept of a genomics \"Beacon\" refers to facilitating connection between genomic data suppliers, developers, and researchers interested in acquiring genetic variation data. The Beacon system was intended to be simple: an API that allows users to query genomic data collections for the presence of specified genetic variations and receive a simple \"Yes\" or \"No\" response. The term \"Beacon\" was chosen to represent the goal of illuminating the hitherto opaque world of genetic data sharing through widespread engagement. The Beacon Project, which became one of the initial Global Alliance for Genomics and Health (GA4GH) Driver Projects, was warmly welcomed by both members of the GA4GH developer community and genomic resource providers {% cite Rambla2022 %}.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "beacon_cnv_query-q02", "tutorial_id": "topics/variant-analysis/tutorials/beacon_cnv_query", "query": "How can I filter CNV records by variant state, gene name, and primary site in the Beacon database?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Querying the University of Bradford GDC Beacon Database for Copy Number Variants (CNVs)", "datasets": ["https://zenodo.org/records/10658688"], "dataset_paths": ["https://zenodo.org/records/10658688"], "dataset_count": 1, "context_summary": "The concept of a genomics \"Beacon\" refers to facilitating connection between genomic data suppliers, developers, and researchers interested in acquiring genetic variation data. The Beacon system was intended to be simple: an API that allows users to query genomic data collections for the presence of specified genetic variations and receive a simple \"Yes\" or \"No\" response. The term \"Beacon\" was chosen to represent the goal of illuminating the hitherto opaque world of genetic data sharing through widespread engagement. The Beacon Project, which became one of the initial Global Alliance for Genomics and Health (GA4GH) Driver Projects, was warmly welcomed by both members of the GA4GH developer community and genomic resource providers {% cite Rambla2022 %}.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "beacon_cnv_query-q03", "tutorial_id": "topics/variant-analysis/tutorials/beacon_cnv_query", "query": "I need to query the Beacon database to retrieve CNV records for a specific gene. Which tool can I use for this task?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Querying the University of Bradford GDC Beacon Database for Copy Number Variants (CNVs)", "datasets": ["https://zenodo.org/records/10658688"], "dataset_paths": ["https://zenodo.org/records/10658688"], "dataset_count": 1, "context_summary": "The concept of a genomics \"Beacon\" refers to facilitating connection between genomic data suppliers, developers, and researchers interested in acquiring genetic variation data. The Beacon system was intended to be simple: an API that allows users to query genomic data collections for the presence of specified genetic variations and receive a simple \"Yes\" or \"No\" response. The term \"Beacon\" was chosen to represent the goal of illuminating the hitherto opaque world of genetic data sharing through widespread engagement. The Beacon Project, which became one of the initial Global Alliance for Genomics and Health (GA4GH) Driver Projects, was warmly welcomed by both members of the GA4GH developer community and genomic resource providers {% cite Rambla2022 %}.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "beacon_cnv_query-q04", "tutorial_id": "topics/variant-analysis/tutorials/beacon_cnv_query", "query": "What steps do I need to take to query the Beacon database and retrieve CNV records for a specific disease type?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Querying the University of Bradford GDC Beacon Database for Copy Number Variants (CNVs)", "datasets": ["https://zenodo.org/records/10658688"], "dataset_paths": ["https://zenodo.org/records/10658688"], "dataset_count": 1, "context_summary": "The concept of a genomics \"Beacon\" refers to facilitating connection between genomic data suppliers, developers, and researchers interested in acquiring genetic variation data. The Beacon system was intended to be simple: an API that allows users to query genomic data collections for the presence of specified genetic variations and receive a simple \"Yes\" or \"No\" response. The term \"Beacon\" was chosen to represent the goal of illuminating the hitherto opaque world of genetic data sharing through widespread engagement. The Beacon Project, which became one of the initial Global Alliance for Genomics and Health (GA4GH) Driver Projects, was warmly welcomed by both members of the GA4GH developer community and genomic resource providers {% cite Rambla2022 %}.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "beaconise_1000hg-q01", "tutorial_id": "topics/variant-analysis/tutorials/beaconise_1000hg", "query": "I have a VCF file containing structural variants and a metadata file in TSV format. What tools should I use to convert the VCF file into JSON and create a Phenopacket schema JSON file?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Working with Beacon V2: A Comprehensive Guide to Creating, Uploading, and Searching for Variants with Beacons", "datasets": ["HG00096.cnv.vcf", "igsr-1000-genomes-30x-on-grch38.tsv"], "dataset_paths": ["HG00096.cnv.vcf", "igsr-1000-genomes-30x-on-grch38.tsv"], "dataset_count": 2, "context_summary": "Beacon v2 is a data query protocol and API that allows the researcher to seek information about specific genomic variants of biomedical research and clinical applications from the data providers (Beacon provider) without", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "beaconise_1000hg-q02", "tutorial_id": "topics/variant-analysis/tutorials/beaconise_1000hg", "query": "How can I import the JSON files generated from the VCF file and Phenopacket schema into a Beacon database using Galaxy tools?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Working with Beacon V2: A Comprehensive Guide to Creating, Uploading, and Searching for Variants with Beacons", "datasets": ["HG00096.cnv.vcf", "igsr-1000-genomes-30x-on-grch38.tsv"], "dataset_paths": ["HG00096.cnv.vcf", "igsr-1000-genomes-30x-on-grch38.tsv"], "dataset_count": 2, "context_summary": "Beacon v2 is a data query protocol and API that allows the researcher to seek information about specific genomic variants of biomedical research and clinical applications from the data providers (Beacon provider) without", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "beaconise_1000hg-q03", "tutorial_id": "topics/variant-analysis/tutorials/beaconise_1000hg", "query": "Which Galaxy tool can I use to perform a range query on a Beacon database's genomicVariations collection to find samples with a specific deletion mutation?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Working with Beacon V2: A Comprehensive Guide to Creating, Uploading, and Searching for Variants with Beacons", "datasets": ["genomicVariations"], "dataset_paths": ["genomicVariations"], "dataset_count": 1, "context_summary": "Beacon v2 is a data query protocol and API that allows the researcher to seek information about specific genomic variants of biomedical research and clinical applications from the data providers (Beacon provider) without", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "beaconise_1000hg-q04", "tutorial_id": "topics/variant-analysis/tutorials/beaconise_1000hg", "query": "How do I create a read-only user account for a Beacon database to allow users to query the database without modifying it?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Working with Beacon V2: A Comprehensive Guide to Creating, Uploading, and Searching for Variants with Beacons", "datasets": ["https://zenodo.org/records/10658688"], "dataset_paths": ["https://zenodo.org/records/10658688"], "dataset_count": 1, "context_summary": "Beacon v2 is a data query protocol and API that allows the researcher to seek information about specific genomic variants of biomedical research and clinical applications from the data providers (Beacon provider) without", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "sars-cov-2-variant-discovery-q01", "tutorial_id": "topics/variant-analysis/tutorials/sars-cov-2-variant-discovery", "query": "I have a collection of SARS-CoV-2 sequencing data in paired-end FASTQ format, how can I assess the quality of the reads and filter out low-quality reads?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Mutation calling, viral genome reconstruction and lineage/clade assignment from SARS-CoV-2 sequencing data", "datasets": ["Sequencing data"], "dataset_paths": ["Sequencing data"], "dataset_count": 1, "context_summary": "Sequence-based monitoring of global infectious disease crises, such as the COVID-19 pandemic, requires capacity to generate and analyze large volumes of sequencing data in near real time. These data have proven essential for surveilling the emergence and spread of new viral variants, and for understanding the evolutionary dynamics of the virus.", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "sars-cov-2-variant-discovery-q02", "tutorial_id": "topics/variant-analysis/tutorials/sars-cov-2-variant-discovery", "query": "Which Galaxy tool can I use to perform variant calling on my SARS-CoV-2 sequencing data?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Mutation calling, viral genome reconstruction and lineage/clade assignment from SARS-CoV-2 sequencing data", "datasets": ["SARS-CoV-2 reference"], "dataset_paths": ["SARS-CoV-2 reference"], "dataset_count": 1, "context_summary": "Sequence-based monitoring of global infectious disease crises, such as the COVID-19 pandemic, requires capacity to generate and analyze large volumes of sequencing data in near real time. These data have proven essential for surveilling the emergence and spread of new viral variants, and for understanding the evolutionary dynamics of the virus.", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "sars-cov-2-variant-discovery-q03", "tutorial_id": "topics/variant-analysis/tutorials/sars-cov-2-variant-discovery", "query": "I have a collection of SARS-CoV-2 consensus sequences in FASTA format, how can I assign lineages to them using Pangolin?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Mutation calling, viral genome reconstruction and lineage/clade assignment from SARS-CoV-2 sequencing data", "datasets": ["Multisample consensus FASTA"], "dataset_paths": ["Multisample consensus FASTA"], "dataset_count": 1, "context_summary": "Sequence-based monitoring of global infectious disease crises, such as the COVID-19 pandemic, requires capacity to generate and analyze large volumes of sequencing data in near real time. These data have proven essential for surveilling the emergence and spread of new viral variants, and for understanding the evolutionary dynamics of the virus.", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "sars-cov-2-variant-discovery-q04", "tutorial_id": "topics/variant-analysis/tutorials/sars-cov-2-variant-discovery", "query": "Can I use Nextclade to assign clades and call mutations on my SARS-CoV-2 consensus sequences?", "tools": [], "workflows": [], "metadata": {"topic": "variant-analysis", "tutorial_title": "Mutation calling, viral genome reconstruction and lineage/clade assignment from SARS-CoV-2 sequencing data", "datasets": ["Multisample consensus FASTA"], "dataset_paths": ["Multisample consensus FASTA"], "dataset_count": 1, "context_summary": "Sequence-based monitoring of global infectious disease crises, such as the COVID-19 pandemic, requires capacity to generate and analyze large volumes of sequencing data in near real time. These data have proven essential for surveilling the emergence and spread of new viral variants, and for understanding the evolutionary dynamics of the virus.", "priority": 4, "version": "v0", "query_type": "general"}}
{"id": "jbrowse-q01", "tutorial_id": "topics/visualisation/tutorials/jbrowse", "query": "I have a BAM file ([dna sequencing.bam]) and want to visualize it along with its coverage and SNP tracks in JBrowse. What tools should I use?", "tools": [], "workflows": [], "metadata": {"topic": "visualisation", "tutorial_title": "Genomic Data Visualisation with JBrowse", "datasets": ["dna sequencing.bam"], "dataset_paths": ["dna sequencing.bam"], "dataset_count": 1, "context_summary": "> JBrowse ({% cite Buels_2016 %}) is a fast, embeddable genome browser built completely with JavaScript", "priority": 1, "version": "v0", "query_type": "general"}}
{"id": "jbrowse-q02", "tutorial_id": "topics/visualisation/tutorials/jbrowse", "query": "I have a VCF file ([variants.vcf]) and a BAM file ([dna sequencing.bam]), how can I visualize them together with gene tracks in JBrowse?", "tools": [], "workflows": [], "metadata": {"topic": "visualisation", "tutorial_title": "Genomic Data Visualisation with JBrowse", "datasets": ["variants.vcf", "dna sequencing.bam"], "dataset_paths": ["variants.vcf", "dna sequencing.bam"], "dataset_count": 2, "context_summary": "> JBrowse ({% cite Buels_2016 %}) is a fast, embeddable genome browser built completely with JavaScript", "priority": 2, "version": "v0", "query_type": "general"}}
{"id": "jbrowse-q03", "tutorial_id": "topics/visualisation/tutorials/jbrowse", "query": "What tool can I use to generate a SNP track from a BAM file ([dna sequencing.bam]) for visualization in JBrowse?", "tools": [], "workflows": [], "metadata": {"topic": "visualisation", "tutorial_title": "Genomic Data Visualisation with JBrowse", "datasets": ["dna sequencing.bam"], "dataset_paths": ["dna sequencing.bam"], "dataset_count": 1, "context_summary": "> JBrowse ({% cite Buels_2016 %}) is a fast, embeddable genome browser built completely with JavaScript", "priority": 3, "version": "v0", "query_type": "general"}}
{"id": "jbrowse-q04", "tutorial_id": "topics/visualisation/tutorials/jbrowse", "query": "How can I customize the display of gene tracks in JBrowse to show different colors based on the score, using a GFF3 file ([genes (de novo).gff3])?", "tools": [], "workflows": [], "metadata": {"topic": "visualisation", "tutorial_title": "Genomic Data Visualisation with JBrowse", "datasets": ["genes (de novo).gff3"], "dataset_paths": ["genes (de novo).gff3"], "dataset_count": 1, "context_summary": "> JBrowse ({% cite Buels_2016 %}) is a fast, embeddable genome browser built completely with JavaScript", "priority": 4, "version": "v0", "query_type": "general"}}
